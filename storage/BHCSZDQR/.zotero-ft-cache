O’Reilly精品图书系列
机器学习实战:基于Scikit-Learn、Keras和
TensorFlow:原书第2版
Hands-On Machine Learning with Scikit
Learn,Keras,and TensorFlow:Concepts,
Tools,and Techniques to Build Intelligent
Systems,Second Edition
(法)奥雷利安·杰龙 著
宋能辉 李娴 译
ISBN:978-7-111-66597-7
本书纸版由机械工业出版社于2020年出版,电子版由华章分社(北京
华章图文信息有限公司,北京奥维博世图书发行有限公司)在中华人
民共和国境内(不包括中国香港、澳门特别行政区及中国台湾地区)
制作与发行。
版权所有,侵权必究
客服热线:+ 86-10-68995265
客服信箱:service@bbbvip.com
官方网址:www.hzmedia.com.cn
新浪微博 @华章数媒


微信公众号 华章电子书(微信号:hzebook)


目录
O'Reilly Media,Inc.介绍
推荐序
译者序
前言
第一部分 机器学习的基础知识
第1章 机器学习概览
1.1 什么是机器学习
1.2 为什么使用机器学习
1.3 机器学习的应用示例
1.4 机器学习系统的类型
1.5 机器学习的主要挑战
1.6 测试与验证
1.7 练习题
第2章 端到端的机器学习项目
2.1 使用真实数据
2.2 观察大局
2.3 获取数据
2.4 从数据探索和可视化中获得洞见
2.5 机器学习算法的数据准备
2.6 选择和训练模型
2.7 微调模型
2.8 启动、监控和维护你的系统
2.9 试试看
2.10 练习题
第3章 分类
3.1 MNIST
3.2 训练二元分类器
3.3 性能测量
3.4 多类分类器
3.5 误差分析


3.6 多标签分类
3.7 多输出分类
3.8 练习题
第4章 训练模型
4.1 线性回归
4.2 梯度下降
4.3 多项式回归
4.4 学习曲线
4.5 正则化线性模型
4.6 逻辑回归
4.7 练习题
第5章 支持向量机
5.1 线性SVM分类
5.2 非线性SVM分类
5.3 SVM回归
5.4 工作原理
5.5 练习题
第6章 决策树
6.1 训练和可视化决策树
6.2 做出预测
6.3 估计类概率
6.4 CART训练算法
6.5 计算复杂度
6.6 基尼不纯度或熵
6.7 正则化超参数
6.8 回归
6.9 不稳定性
6.10 练习题
第7章 集成学习和随机森林
7.1 投票分类器
7.2 bagging和pasting


7.3 随机补丁和随机子空间
7.4 随机森林
7.5 提升法
7.6 堆叠法
7.7 练习题
第8章 降维
8.1 维度的诅咒
8.2 降维的主要方法
8.3 PCA
8.4 内核PCA
8.5 LLE
8.6 其他降维技术
8.7 练习题
第9章 无监督学习技术
9.1 聚类
9.2 高斯混合模型
9.3 练习题
第二部分 神经网络与深度学习
第10章 Keras人工神经网络简介
10.1 从生物神经元到人工神经元
10.2 使用Keras实现MLP
10.3 微调神经网络超参数
10.4 练习题
第11章 训练深度神经网络
11.1 梯度消失与梯度爆炸问题
11.2 重用预训练层
11.3 更快的优化器
11.4 通过正则化避免过拟合
11.5 总结和实用指南
11.6 练习题
第12章 使用TensorFlow自定义模型和训练


12.1 TensorFlow快速浏览
12.2 像NumPy一样使用TensorFlow
12.3 定制模型和训练算法
12.4 TensorFlow函数和图
12.5 练习题
第13章 使用TensorFlow加载和预处理数据
13.1 数据API
13.2 TFRecord格式
13.3 预处理输入特征
13.4 TF Transform
13.5 TensorFlow数据集项目
13.6 练习题
第14章 使用卷积神经网络的深度计算机视觉
14.1 视觉皮层的架构
14.2 卷积层
14.3 池化层
14.4 CNN架构
14.5 使用Keras实现ResNet-34 CNN
14.6 使用Keras的预训练模型
14.7 迁移学习的预训练模型
14.8 分类和定位
14.9 物体检测
14.10 语义分割
14.11 练习题
第15章 使用RNN和CNN处理序列
15.1 循环神经元和层
15.2 训练RNN
15.3 预测时间序列
15.4 处理长序列
15.5 练习题
第16章 使用RNN和注意力机制进行自然语言处理


16.1 使用字符RNN生成莎士比亚文本
16.2 情感分析
16.3 神经机器翻译的编码器-解码器网络
16.4 注意力机制
16.5 最近语言模型的创新
16.6 练习题
第17章 使用自动编码器和GAN的表征学习和生成学习
17.1 有效的数据表征
17.2 使用不完整的线性自动编码器执行PCA
17.3 堆叠式自动编码器
17.4 卷积自动编码器
17.5 循环自动编码器
17.6 去噪自动编码器
17.7 稀疏自动编码器
17.8 变分自动编码器
17.9 生成式对抗网络
17.10 练习题
第18章 强化学习
18.1 学习优化奖励
18.2 策略搜索
18.3 OpenAI Gym介绍
18.4 神经网络策略
18.5 评估动作:信用分配问题
18.6 策略梯度
18.7 马尔可夫决策过程
18.8 时序差分学习
18.9 Q学习
18.10 实现深度Q学习
18.11 深度Q学习的变体
18.12 TF-Agents库
18.13 一些流行的RL算法概述


18.14 练习题
第19章 大规模训练和部署TensorFlow模型
19.1 为TensorFlow模型提供服务
19.2 将模型部署到移动端或嵌入式设备
19.3 使用GPU加速计算86
19.4 跨多个设备的训练模型
19.5 练习题
19.6 致谢
附录A 课后练习题解答
附录B 机器学习项目清单
附录C SVM对偶问题
附录D 自动微分
附录E 其他流行的人工神经网络架构
附录F 特殊数据结构
附录G TensorFlow图


O’Reilly Media,Inc.介绍
O’Reilly以“分享创新知识、改变世界”为己任。40多年来我们
一直向企业、个人提供成功所必需之技能及思想,激励他们创新并做
得更好。
O’Reilly业务的核心是独特的专家及创新者网络,众多专家及创
新者通过我们分享知识。我们的在线学习(Online Learning)平台提
供独家的直播培训、图书及视频,使客户更容易获取业务成功所需的
专业知识。几十年来O’Reilly图书一直被视为学习开创未来之技术的
权威资料。我们每年举办的诸多会议是活跃的技术聚会场所,来自各
领域的专业人士在此建立联系,讨论最佳实践并发现可能影响技术行
业未来的新趋势。
我们的客户渴望做出推动世界前进的创新之举,我们希望能助他
们一臂之力。
业界评论
“O’Reilly Radar博客有口皆碑。”
——Wired
“O’Reilly凭借一系列非凡想法(真希望当初我也想到了)建立
了数百万美元的业务。”
——Business 2.0
“O’ReillyConference是聚集关键思想领袖的绝对典范。”


——CRN
“一本O’Reilly的书就代表一个有用、有前途、需要学习的主
题。”
——Irish Times
“Tim是位特立独行的商人,他不光放眼于最长远、最广阔的领
域,并且切实地按照Yogi Berra的建议去做了:‘如果你在路上遇到
岔路口,那就走小路。’回顾过去,Tim似乎每一次都选择了小路,而
且有几次都是一闪即逝的机会,尽管大路也不错。”
——Linux Journal


推荐序
最近几年人工智能技术的突破性进展,比如AlphaGo战胜围棋世界
冠军柯洁,Waymo开始部署自动驾驶出租车,都表明深度学习极大地推
动了整个机器学习的发展。现在,即使对深度学习技术几乎一无所知
的工程师和程序员,也可以使用简单而有效的工具来实现从数据中学
习的复杂应用程序。本书就向你展示了具体应该如何来实现各种人工
智能的应用,如计算机视觉、自然语言处理等。
本书作者是一位出色的机器学习顾问和培训师,前Google资深工
程师,从2013年至2016年领导YouTube的视频分类团队,不仅具有深厚
的理论功底,还有最前沿的工业界实战操作经验。作者通过使用简洁
的理论和细致具体的示例,运用两个Python框架(Scikit-Learn和
TensorFlow/Keras),帮助你直观地了解构建智能系统的相关概念和
工具。你将从本书中学到各种机器学习技术(从简单的线性回归到各
种神经网络结构)。每章都附有练习题,可以帮助你应用所学的知
识,你所需要的只是编程练习。
本书内容广博,覆盖了机器学习的各个领域,不仅介绍了传统的
机器学习模型,包括支持向量机、决策树、随机森林和集成方法,还
提供了使用Scikit-Learn进行机器学习的端到端训练示例。作者尤其
对深度神经网络进行了深入的探讨,包括各种神经网络架构(如卷积
神经网络、递归神经网络等)、强化学习,以及如何使用
TensorFlow/Keras库来构建和训练神经网络。
本书英文版在Amazon上的评分是4.7分(满分5分),近90%的读者
给予了5星好评,在国内豆瓣读书上也得到91.5%的读者的5星好评,国
内外同时有这么高的好评率,足以证明本书的价值及其良好可读性。


如果你正打算学习机器学习和深度学习,正在寻求一个切入点,
那么我强烈建议你把本书当作入门教材。需要使用机器学习或者深度
学习算法解决实际问题的工程师可将本书当作实战手册,它可以让你
了解很多深度学习的最新研究成果和实用技巧。
张明清
布朗大学计算机系博士,
纽约州立大学阿尔巴尼分校计算机科学系副教授,
计算机视觉和机器学习实验室(CVML Lab)主任,
前通用电气公司全球研发中心计算机视觉实验室首席计算机科学家


译者序
随着AlphaGo在人机大战中一举成名,关于人工智能的研究开始广
受关注,人工智能科学家也一跃成为“21世纪热门的人才”。人工智
能,特别是机器学习和深度神经网络的广泛应用虽然兴起不久,但是
对这两个密切关联的领域的研究其实已经持续了好几十年,早已形成
了系统化的知识体系。对于想要踏入机器学习和深度学习领域的初学
者和工程师而言,一本理论和实践相结合的书籍是必不可少的,本书
就是这样一本书。
本书分为两部分:第一部分介绍机器学习的基础知识;第二部分
介绍神经网络与深度学习。附录部分的内容也非常丰富。本书兼顾理
论与实战,既适合在校学生,又适合有经验的工程师。
从理论上讲,本书最大的特色就是有深度,覆盖面广,但是书中
并没有太多复杂的数学公式推导,很容易看懂。这在现在很多机器学
习书籍中是不多见的。
从实战来说,本书使用了当前热门的机器学习框架Scikit-Learn
及深度学习框架TensorFlow和Keras,每一章都配备相应的项目示例,
代码的实操性和可读性非常好。本书也是为有经验的工程师而写的,
是一本实用指南。特别是附录B给出的机器学习项目清单,如果工业界
想做一套机器学习的解决方案,完全可以按照这个清单去做。
读者朋友可能非常关心第2版相比第1版有何区别,作者在第2版中
不仅重写了大部分章节,还增加了很多机器学习的前沿知识,代码示
例采用了Keras深度学习框架。
作者将本书所有章节的详细代码都发布在GitHub上。项目地址
为:https://github.com/ageron/handson-ml2。


译者现在在比利时某科研机构从事深度学习处理器、嵌入式实时
人工智能、计算机视觉和深度学习异构平台上的编程框架等研究工
作,虽有多年的机器学习和计算机视觉研究和开发经验,但本书中所
涉及的专业术语与概念较多,部分概念及术语尚无公认的中文译法,
因此我们参考了一些网络上和研究论文中常用的译法。在翻译过程中
虽然力求准确地反映原著内容,但由于译者水平有限,可能有错误或
者遗漏之处,恳请读者批评指正。读者可以通过电子邮件
songnh@outlook.com和译者取得联系。
感谢机械工业出版社华章公司的编辑们,特别是刘锋编辑,他们
为保证本书的质量做了大量的编辑和审校工作,在此深表谢意。
还要感谢Ivannie,她在我翻译本书的过程中,给了我最大的快
乐。
宋能辉


前言
机器学习海啸
2006年,Geoffrey Hinton等人发表了一篇论文[1],展示了如何训
练能够以最先进的精度(>98%)识别手写数字的深度神经网络。他们
将这种技术称为“深度学习”。深度神经网络是(非常)简化的大脑
皮层的模型,由一堆人工神经元层组成。当时人们普遍认为,训练深
度神经网络是不可能的:Yann LeCun的深度卷积神经网络自20世纪90
年代以来就一直很好地用于图像识别,尽管它们并不是通用的。,并
且大多数研究人员在20世纪90年代后期就放弃了这一想法。该论文重
新激发了科学界的兴趣,不久之后,许多新论文证明了(在强大的计
算能力和大量数据的帮助下)深度学习不仅是可能的,而且还具有令
人难以置信的成就,这是其他机器学习(ML)技术无法企及的。这种
热情很快扩展到了机器学习的许多其他领域。
大约十年后,机器学习征服了整个工业界:它是当今高科技产品
诸多魔力的核心,可以为你的网络搜索结果排名,为智能手机的语音
识别提供支持,可以推荐视频,并在围棋比赛中击败世界冠军。在不
知不觉中,它将驾驶你的汽车。
你的项目中的机器学习
因此,你自然会对机器学习感到兴奋,并很乐意加入这场盛宴!
也许你想让你的自制机器人拥有自己的大脑,使它能够识别人
脸,或者学会走路。
也许你的公司拥有大量数据(用户日志、财务数据、生产数据、
机器传感器数据、热线统计信息、人力资源报告等),如果你知道在


哪里看,很有可能会发现一些隐藏的宝石。借助机器学习,你可以完
成以下和更多任务:
·细分客户并为每个群体找到最佳的营销策略。
·根据类似客户的购买记录,为每个客户推荐产品。
·检测哪些交易可能是欺诈性的。
·预测明年的收入。
无论出于何种原因,你都决定学习机器学习并将其实现在你的项
目中。好主意!
目标与方法
本书假设你对机器学习一无所知,其目标是为你提供实现能够从
数据中学习的程序所需的概念、工具和直觉。
我们将介绍大量技术,从最简单和最常用的技术(例如线性回
归)到一些经常赢得比赛的深度学习技术。
本书不是实现每种算法的玩具版本,而是使用可用于生产环境的
Python框架:
·Scikit-Learn非常易于使用,它有效地实现了许多机器学习算
法,因此成为学习机器学习的重要切入点。Scikit-Learn由David
Cournapeau于2007年创建,现在由法国计算机科学和自动化研究所的
一个研究小组领导。
·TensorFlow是用于分布式数值计算的更复杂的库。通过将计算
分布在数百个GPU(图形处理单元)服务器上,它可以有效地训练和运


行大型神经网络。TensorFlow(TF)是由Google创建的,并支持许多
大型机器学习应用程序。它于2015年11月开源,2.0版本于2019年11月
发布。
·Keras是高层深度学习API,使训练和运行神经网络变得非常简
单。它可以在TensorFlow、Theano或微软Cognitive Toolkit(以前称
为CNTK)之上运行。TensorFlow附带了该API自己的实现,称为
tf.keras,支持某些高级TensorFlow功能(例如有效加载数据的能
力)。
本书主张动手实践,通过具体的示例和一点点理论就可以对机器
学习有一个直观的了解。虽然你无须拿起笔记本电脑就可以阅读本
书,但我强烈建议你尝试用Jupyter notebook试验在
https://github.com/ageron/handson-ml2上在线获得的代码示例。
先决条件
本书假定你具有一些Python编程经验,并且熟悉Python的主要科
学库,尤其是NumPy、pandas和Matplotlib。
另外,如果你关心一些比较深入的内容,那么你应该对大学水平
的数学知识(如微积分、线性代数、概率和统计)有一定的了解。
如果你还不了解Python,那么http://learnpython.org/是一个不
错的起点。Python.org上的官方教程也相当不错。
如果你从未使用过Jupyter,则第2章将指导你完成安装并学习基
础知识。它是工具箱中的一个强大工具。
如果你不熟悉Python的科学库,Jupyter notebook里面有一些教
程。还有一个关于线性代数的快速数学教程。


路线图
本书分为两部分。第一部分涵盖以下主题:
·什么是机器学习,它试图解决什么问题,以及其系统的主要类
别和基本概念
·典型机器学习项目中的步骤
·通过将数据与模型进行拟合来学习
·优化成本函数
·处理、清洁和准备数据
·选择和工程化特征
·选择模型并使用交叉验证调整超参数
·机器学习的挑战,特别是欠拟合和过拟合(偏差/方差的权衡)
·最常见的学习算法:线性和多项式回归、逻辑回归、k-近邻算
法、支持向量机、决策树、随机森林和集成方法
·降低训练数据的维度以应对“维度的诅咒”
·其他无监督学习技术,包括聚类、密度估计和异常检测
第二部分涵盖以下主题:
·什么是神经网络以及它们的作用


·使用TensorFlow和Keras构建和训练神经网络
·最重要的神经网络架构,包括用于表格数据的前馈神经网络、
用于计算机视觉的卷积网络、用于序列处理的递归网络和长短期记忆
(LSTM)网络、用于自然语言处理的编码器/解码器和Transformer、
自动编码器和用于生成学习的生成式对抗网络(GAN)
·训练深度神经网络的技术
·如何使用强化学习构建可以通过反复试错学习好的策略的代理
程序(例如游戏中的机器人)
·有效地加载和预处理大量数据
·大规模训练和部署TensorFlow模型
第一部分主要基于Scikit-Learn,而第二部分则使用TensorFlow
和Keras。
不要草率地跳入深水:尽管深度学习无疑是机器学习中最令
人兴奋的领域之一,但你应该首先掌握基础知识。而且,大多数问题
可以使用更简单的技术(如第一部分中讨论的随机森林和集成学习方
法)来很好地解决。如果你有足够的数据、计算能力和耐心,则深度
学习最适合诸如图像识别、语音识别或自然语言处理之类的复杂问
题。
第2版的变化
第2版有6个主要变化:


1.涵盖其他ML主题:更多的无监督学习技术(包括聚类、异常检
测、密度估计和混合模型);训练深度网络(包括自归一化网络)的
更多技术;其他计算机视觉技术(包括Xception、SENet、使用YOLO进
行物体检测,以及使用R-CNN进行语义分割);使用卷积神经网络
(CNN,包括WaveNet)处理序列;使用递归神经网络(RNN)、CNN和
Transformer进行自然语言处理;GAN。
2.涵盖其他库和API(Keras、Data API、用于强化学习的TF
Agents),以及使用分布式策略API、TF-Serving和Google Cloud AI
Platform大规模训练和部署TF模型;还简要介绍TF Transform、
TFLite、TF Addons/Seq2Seq和TensorFlow.js。
3.讨论深度学习研究的一些最新重要成果。
4.将所有TensorFlow章节迁移到TensorFlow 2,并尽可能使用
TensorFlow的Keras API(tf.keras)实现。
5.更新代码示例,使用最新版本的Scikit-Learn、NumPy、
pandas、Matplotlib和其他库。
6.得益于读者的大量反馈,一些章节更加明晰,并修正了一些错
误。
添加了一些章节,有些章节被重写,有些则被重新排序。有关第2
版更新的更多详细信息请参见https://homl.info/changes2。
其他资源
许多优秀的资源可用于学习机器学习。例如,吴恩达(Andrew
Ng)在Coursera上的机器学习课程虽然很好,但它需要投入大量的时
间(数月)。


还有许多有趣的关于机器学习的网站,当然包括Scikit-Learn出
色的用户指南。你可能还喜欢Dataquest(它提供了非常不错的交互式
教程),以及机器学习博客(例如Quora上列出的那些博客)。最后,
深度学习网站上有不错的资源清单,可供你了解更多信息。
关于机器学习,还有许多其他入门书籍。特别是:
·Joel Grus的Data Science from Scratch(O’Reilly)介绍了
机器学习的基础知识,并在纯Python中实现了一些主要算法(顾名思
义,从头开始)。
·Stephen Marsland的Machine Learning:An Algorithmic
Perspective(Chapman&Hall)是对机器学习的出色介绍,它使用
Python代码示例(也从零开始,但使用NumPy),涵盖广泛的主题。
·Sebastian Raschka的Python Machine Learning(Packt
Publishing)也对机器学习进行了很好的介绍,并利用了Python开源
库(Pylearn 2和Theano)。
·François Chollet的Deep Learning with Python(Manning)
是一本非常实用的书,以清晰、简洁的方式涵盖了广泛的主题,书中
涉及Keras库的很多内容。它偏爱代码示例甚于数学理论。
·Andriy Burkov的The Hundred-Page Machine Learning Book非
常简短,涵盖了一系列令人印象深刻的主题,不仅以平易近人的方式
介绍这些主题,同时也没有回避数学方程式。
·Yaser S.Abu-Mostafa、Malik Magdon-Ismail和Hsuan-Tien
Lin的Learning from Data(AMLBook)介绍颇为理论化的机器学习方
法,它提供了深刻的见解,尤其是在偏差/方差权衡方面(见第4
章)。


·Stuart Russell和Peter Norvig的Artificial Intelligence:
A Modern Approach,3rd Edition(Pearson)是一本非常出色的书,
涵盖了机器学习等众多主题。它有助于正确理解机器学习。
最后,加入像Kaggle.com这样的机器学习竞赛网站,将使你在一
些实际的问题上获得实践技能,并获得一些顶尖机器学习专业人员的
帮助和见解。
排版约定
本书中使用以下排版约定:
斜体(Italic)
表示新的术语、URL、电子邮件地址、文件名和文件扩展名。
等宽字体(Constant width)
用于程序清单,以及段落中的程序元素,例如变量名、函数名、
数据库、数据类型、环境变量、语句以及关键字。
等宽粗体(Constant width bold)
表示应由用户直接输入的命令或其他文本。
等宽斜体(Constant width italic)
表示应由用户提供的值或由上下文确定的值替换的文本。
该图示表示提示或建议。


该图示表示一般性说明。
该图示表示警告或注意。
代码示例
一系列Jupyter notebook里面有很多补充材料,例如代码示例和
练习,可从https://github.com/ageron/handson-ml2下载。
本书中的某些代码示例省略了与机器学习无关的重复部分或细
节,这样可以把重点放在代码的重要部分上,节省空间以便覆盖更多
的主题。如果需要完整的代码示例,可以在Jupyter notebook中找到
它们。
请注意,当代码示例显示某些输出时,这些代码示例将在Python
提示符(>>>和...)下显示,就像在Python shell中一样,可以清楚
地区分代码与输出。例如,如下代码定义square()函数,然后计算
并显示3的平方:
>>> def square(x): ... return x ** 2 ... >>> result = square(3) >>> result 9
当代码不显示任何输出内容时,不使用提示符。但是有时结果可
能会显示为注释,如下所示:
def square(x): return x ** 2


result = square(3) # result is 9
示例代码
这里的代码是为了帮助你更好地理解本书的内容。通常,可以在
程序或文档中使用本书中的代码,而不需要联系O’Reilly获得许可,
除非需要大段地复制代码。例如,使用本书中所提供的几个代码片段
来编写一个程序不需要得到我们的许可,但销售或发布O’Reilly的配
套CD-ROM则需要O’Reilly出版社的许可。引用本书的示例代码来回答
问题也不需要许可,将本书中的示例代码的很大一部分放到自己的产
品文档中则需要获得许可。
非常欢迎读者使用本书中的代码,希望(但不强制)注明出处。
注明出处的形式包含书名、作者、出版社和ISBN,例如:
Hands-On Machine Learning with Scikit-Learn,Keras,and
TensorFlow,2nd Edition,作者Aurélien Géron,由O’Reilly出
版,书号978-1-492-03264-9。
如果读者觉得对示例代码的使用超出了上面所给出的许可范围,
欢迎通过permission@oreilly.com联系我们。
O’Reilly在线学习平台(O’Reilly Online Learning)
近40年来,O’Reilly Media致力于提供技术和商
业培训、知识和卓越见解,来帮助众多公司取得成功。
我们拥有独一无二的专家和革新者组成的庞大网络,他们通过图
书、文章、会议和我们的在线学习平台分享他们的知识和经验。
O’Reilly的在线学习平台允许你按需访问现场培训课程、深入的学习


路径、交互式编程环境,以及O’Reilly和200多家其他出版商提供的
大量文本和视频资源。有关的更多信息,请访问
http://oreilly.com。
如何联系我们
对于本书,如果有任何意见或疑问,请按照以下地址联系本书出
版商。美国:
O’Reilly Media,Inc.
1005 Gravenstein Highway North Sebastopol,CA 95472
中国:
北京市西城区西直门南大街2号成铭大厦C座807室(100035)
奥莱利技术咨询(北京)有限公司
要询问技术问题或对本书提出建议,请发送电子邮件至
bookquestions@oreilly.com。本书配套网站
https://homl.info/oreilly2上列出了勘误表、示例以及其他信息。
关于书籍、课程、会议和新闻的更多信息,请访问我们的网站
http://www.oreilly.com。
我们在Facebook上的地址:http://facebook.com/oreilly
我们在Twitter上的地址:http://twitter.com/oreillymedia
我们在YouTube上的地址:
http://www.youtube.com/oreillymedia


致谢
我从未想象过我的第一本书会吸引如此众多的读者。我收到了读
者的大量反馈,很多人提出了许多问题,有些人指出了书中的差错,
大多数人给了我鼓励。我对所有读者的大力支持表示感谢。非常感谢
大家!如果你在代码示例中发现错误(或只是提出问题),请毫不犹
豫地在GitHub上提交问题。如果在文本中发现错误,请提交勘误。一
些读者还分享了本书如何帮助他们获得了第一份工作,或者它如何帮
助他们解决了正在处理的具体问题。这种反馈极大地激励了我。如果
你认为本书对你有所帮助,可以与我分享你的故事,无论是私下(例
如,通过LinkedIn)还是公开地(例如,通过推文或通过亚马逊评
论)与我分享。
我也非常感谢那些百忙之中抽出时间审阅本书的专家。特别要感
谢François Chollet审阅了所有基于Keras和TensorFlow的章节,并给
了我一些深入的反馈。由于Keras是第2版的主要新增内容之一,因此
请Keras的作者审阅本书是非常值得的。我强烈推荐François的书Deep
Learning with Python(Manning),它具有Keras库本身的简洁性、
清晰度和深度。还要特别感谢Ankur Patel,他审阅了第2版的每一
章,并给了我很好的反馈,特别是第9章(涵盖了无监督学习技术)。
关于该主题,他可以写一本书,请查看Hands-On
UnsupervisedLearning Using Python:How to Build Applied
Machine Learning Solutions from Unlabeled Data(O’Reilly)。
还要感谢Olzhas Akpambetov,他审阅了本书第二部分的所有章节,测
试了许多代码,并提出了许多很好的建议。我非常感谢Mark Daoust、
Jon Krohn、Dominic Monn和Josh Patterson如此全面地审阅了本书的
第二部分,并用他们的专业知识提供了非常有用的反馈。
在撰写本书时,我很幸运地从TensorFlow团队成员那里得到了很
多帮助,尤其是Martin Wicke,他不懈地回答了我的许多问题,并将
其余的问题分发给了合适的人,包括Karmel Allison、Paige
Bailey、Eugene Brevdo、William Chargin、Daniel“Wolff”


Dobson、Nick Felt、Bruce Fontaine、Goldie Gadde、Sandeep
Gupta、Priya Gupta、KevinHaas、Konstantinos Katsiapis、
Viacheslav Kovalevskyi、Allen Lavoie、Clemens Mewald、Dan
Moldovan、Sean Morgan、Tom O’Malley、Alexandre Passos、
AndréSusano Pinto、Anthony Platanios、Oscar Ramirez、Anna
Revinskaya、Saurabh Saxena、Ryan Sepassi、Jiri Simsa、Xiaodan
Song、Christina Sorokin、Dustin Tran、Todd Wang、Pete
Warden(他审阅了第1版)、Edd Wilder-James和Yuefeng Zhou,他们
都为我提供了帮助。非常感谢大家以及TensorFlow团队的所有其他成
员,不仅是你们的帮助,而且也感谢你们做出如此出色的库!特别感
谢TFX小组的Irene Giannoumis和Robert Crowe对第13章和第19章进行
的深入审阅。
也要感谢O’Reilly出色的工作人员,尤其是Nicole Taché,他给
了我颇有见地的反馈,并且总是开朗、鼓舞人心和乐于助人——我无
法想象能有比他更好的编辑了。还要感谢在第2版开始时提供帮助(和
耐心)的Michele Cronin,以及第2版的制作编辑Kristen Brown,她
见证了本书的诞生(她还协调了第1版每次重印时的修订和更新工
作)。还要感谢Rachel Monaghan和Amanda Kersey分别对第1版和第2
版进行了详细编辑,也要感谢Johnny O’Toole,他管理与亚马逊的公
共关系并回答了我的许多问题。感谢Marie Beaugureau、Ben
Lorica、Mike Loukides和Laurel Ruma信任这个项目并帮助我确定了
本书的范围。感谢Matt Hacker和所有Atlas团队回答了我有关格式、
AsciiDoc和LaTeX的所有技术问题,并感谢Nick Adams、Rebecca
Demarest、Rachel Head、JudithMcConville、Helen Monroe、Karen
Montgomery、Rachel Roumeliotis和O’Reilly所有其他为本书做出贡
献的人。
我还要感谢我以前的Google同事,特别是YouTube视频分类团队,
他们教会了我很多关于机器学习的知识。没有他们,我永远不可能开
始第1版。特别感谢我个人的ML专家Clément Courbet、Julien


Dubois、Mathias Kende、Daniel Kitachewsky、James Pack、
Alexander Pak、Anosh Raj、Vitor Sessak、Wiktor Tomczak、
Ingrid von Glehn和RichWashington。感谢在的YouTube和令人惊叹的
Google山景城研究团队中与我合作的所有人。也非常感谢Martin
Andrews、Sam Witteveen和Jason Zaman在Soonson Kwon的大力支持
下,欢迎我加入新加坡的Google Developer Experts小组,我们就深
度学习和TensorFlow进行的所有精彩讨论使我深受启发。任何对深度
学习感兴趣的人都应该加入他们的新加坡深度学习聚会。特别感谢
Jason,他在第19章分享了他的TFLite专业知识!
我永远不会忘记审阅本书第1版的好心人,包括David
Andrzejewski、Lukas Biewald、Justin Francis、Vincent
Guilbeau、Eddy Hung、Karim Matrah、Grégoire Mesnil、Salim
Sémaoune、Iain Smears、Michel Tessier、Ingrid von Glehn、Pete
Warden,当然还有我亲爱的兄弟Sylvain。特别感谢Haesun Park,他
在把本书第1版翻译成韩语时给了我很多出色的反馈,并发现了一些错
误。他还把Jupyter notebook翻译成韩文,更不用说TensorFlow的文
档了。我不会说韩语,但是从他的反馈意见的质量来看,他的所有翻
译都很出色!Haesun还为第2版的练习题提供了一些答案。
最后,我无限感激我心爱的妻子Emmanuelle和我们三个漂亮的孩
子(Alexandre、Rémi和Gabrielle),他们鼓励我努力写本书。我也
感谢他们的无限好奇心:向我的妻子和孩子们解释本书中一些最困难
的概念,这有助于我阐明自己的想法,并直接改善了其中的许多内
容。他们无限量地给我提供饼干和咖啡!人生如此,夫复何求?
[1] Geoffrey E.Hinton et al.,“A Fast Learning Algorithm for
Deep Belief Nets” , Neural Computation 18 ( 2006 ) : 1527
1554.


第一部分 机器学习的基础知识
第1章 机器学习概览
当大多数人听到“机器学习”,会在脑海中浮现出一个机器人:
一个可靠的管家或一个可怕的终结者,这取决于你问的是谁。但是机
器学习并不是未来的幻想,它已经来了。事实上,在一些特定的应用
中机器学习已经存在几十年了,比如光学字符识别(Optical
Character Recognition,OCR)。但是直到20世纪90年代,第一个影
响了数亿人的机器学习应用才真正变成主流,它就是垃圾邮件过滤
器。虽然它并不是一个有自我意识的天网系统(Skynet),但是从技
术上来说是符合机器学习的(它可以很好地进行学习,以至于用户几
乎不用将某个邮件标记为垃圾邮件)。后来出现了数以百计的机器学
习应用,支撑了数百个现在经常使用的产品和特性(从更好的推荐系
统到语音搜索)。
那机器学习从哪里开始和在哪里结束呢?机器进行学习到底是什
么意思?如果我下载了一份维基百科的副本,我的计算机就真的学会
了什么吗?它突然就变聪明了吗?在本章中,我们首先会澄清机器学
习到底是什么,以及为什么你想使用它。
在探索机器学习新大陆之前,先观察地图来学习下这片大陆上的
主要地区和最显著的地标:监督学习和无监督学习、在线学习和批量
学习、基于实例学习和基于模型学习。然后我们来看一个典型的机器
学习项目的工作流程,讨论你可能会遇到的难点,并介绍如何评估和
微调一个机器学习系统。
本章介绍了每个数据科学家需要牢记在心的大量基础概念(和专
业术语)。虽然本章是概览(唯一没有代码的一章),相对简单,但


在继续学习本书其余章节之前,要确保掌握每一个知识点。端起一杯
咖啡,开始学习吧!
如果你已经知道机器学习的所有基础概念,可以直接学习第2
章。如果你不确定,可以尝试回答本章末尾列出的问题,然后再继
续。


1.1 什么是机器学习
机器学习是一门通过编程让计算机从数据中进行学习的科学(和
艺术)。
下面是一个稍微通用一点的定义:
机器学习是一个研究领域,让计算机无须进行明确编程就具备学
习能力。
——亚瑟·萨缪尔(Arthur Samuel),1959
更工程化的概念:
一个计算机程序利用经验E来学习任务T,性能是P,如果针对任务
T的性能P随着经验E不断增长,则称为机器学习。
——汤姆·米切尔(Tom Mitchell),1997
例如,垃圾邮件过滤器就是一个机器学习程序,它可以根据垃圾
邮件(比如,用户标记的垃圾邮件)和普通邮件(非垃圾邮件,也称
作ham)学习标记垃圾邮件。系统用来进行学习的样例称作训练集。每
个训练样例称作训练实例(或样本)。在这个示例中,任务T就是标记
新邮件是否是垃圾邮件,经验E是训练数据,性能P需要定义。例如,
可以使用正确分类邮件的比例。这个性能指标称为准确率,通常用在
分类任务中。
如果你只下载了一份维基百科的副本,虽然你的计算机有了很多
数据,但不会在任何工作中变得聪明起来。因此,下载一份维基百科
的副本不是机器学习。


1.2 为什么使用机器学习
思考一下,你会如何使用传统的编程技术写一个垃圾邮件过滤器
(见图1-1):
1.你会先看一下垃圾邮件一般都是什么样子。你可能注意到一些词
或短语(比如4U、credit card、free、amazing)在邮件主题中频繁出
现,也许还注意到一些在邮件的发件人名字、正文和其他地方会出现的
一些固定模式,等等。
2.你会为观察到的每个模式各写一个检测算法,如果检测到了某个
规律,程序就会将邮件标记为垃圾邮件。
3.你会测试程序,重复第1步和第2步,直到足够好可以发布。
因为这个问题很困难,你的程序很可能会变成一长串复杂的规则
——很难维护。
相反,基于机器学习技术的垃圾邮件过滤器会自动学习词和短语,
这些词和短语是垃圾邮件的预测因素,通过与非垃圾邮件比较,检测垃
圾邮件中反复出现的词语模式(见图1-2)。这个程序更短,更易维
护,也更精确。


图1-1:传统方法
图1-2:机器学习方法
如果垃圾邮件的发送者发现所有包含“4U”的邮件都被屏蔽了,他
们会转而使用“For U”。使用传统方法的垃圾邮件过滤器需要更新来
标记“For U”。如果垃圾邮件的发送者持续更改,你就需要一直不停
地写入新规则。
相反,基于机器学习的垃圾邮件过滤器会自动注意到“For U”在
用户手动标记的垃圾邮件中频繁出现,然后就能自动标记垃圾邮件而无
须人工干预了(见图1-3)。
图1-3:自动适应改变


机器学习的另一个亮点是善于处理对于传统方法而言太复杂或没有
已知算法的问题。例如,对于语音识别,假设你想写一个可以识别
“one”和“two”的简单程序。你可能注意到“two”的起始是一个高
音(“T”),因此会写一个可以测量高音强度的硬编码算法,用于区
分“one”和“two”。但是很明显,这个方法不能推广到所有的语音识
别(人们所处环境不同、语言不同、使用的词汇不同)。(现在)最佳
的方法是根据给定的大量单词录音,写一个可以自我学习的算法。
最后,机器学习可以帮助人类进行学习(见图1-4)。机器学习算
法可以检测自己学到了什么(尽管这对于某些算法很棘手)。例如,在
垃圾邮件过滤器训练了足够多的垃圾邮件后,就可以用它列出垃圾邮件
预测器的单词和单词组合。有时可能会发现不引人关注的关联或新趋
势,这有助于更好地理解问题。使用机器学习方法挖掘大量数据来帮助
发现不太明显的规律。这称作数据挖掘。
图1-4:机器学习可以帮助人类学习
总结一下,机器学习适用于:
·有解决方案(但解决方案需要进行大量人工微调或需要遵循大量
规则)的问题:机器学习算法通常可以简化代码,相比传统方法有更好
的性能。


·传统方法难以解决的复杂问题:最好的机器学习技术也许可以找
到解决方案。
·环境有波动:机器学习算法可以适应新数据。
·洞察复杂问题和大量数据。


1.3 机器学习的应用示例
下面介绍一些机器学习的具体示例和所使用的技术。
分析生产线上的产品图像来对产品进行自动分类
这是图像分类问题,使用卷积神经网络(CNN,见第14章)的典型
示例。
通过脑部扫描发现肿瘤
这是语义分割,图像中的每个像素都需要被分类(当我们想确定
肿瘤的确切位置和形状时),也使用CNN。
自动分类新闻
这是自然语言处理(NLP),更具体地是文本分类,可以使用循环
神经网络(RNN)、CNN或者Transformer(见第16章)。
论坛中自动标记恶评
这也是文本分类,使用相同的自然语言处理工具。
自动对长文章做总结
这是自然语言处理的一个分支,叫作文本总结,使用相同的工
具。
创建一个聊天机器人或者个人助理


这涉及自然语言处理的很多分支,包括自然语言理解(NLU)和问
答模块。
基于很多性能指标来预测公司下一年的收入
这是一个回归问题(如预测值),需要使用回归模型进行处理,
例如线性回归或多项式回归(见第4章)、SVM回归(见第5章)、随机
森林回归(见第7章)或者人工神经网络(见第10章),如果考虑过去
的性能指标,可以使用RNN、CNN或者Transformer(见第15章和第16
章)。
让应用对语音命令做出反应
这是语音识别,要求能处理音频采样。因为音频是很长、很复杂
的序列,所以一般使用RNN、CNN或者Transformer(见第15章和第16
章)进行处理。
检测信用卡欺诈
这是异常检测(见第9章)。
基于客户的购买记录来对客户进行分类,对每一类客户设计不同
的市场策略
这是聚类问题(见第9章)。
用清晰而有洞察力的图表来表示复杂的高维数据集
这是数据可视化,经常涉及降维技术(见第8章)。
基于以前的购买记录给客户推荐可能感兴趣的产品


这是推荐系统,一个办法是将以前的购买记录(和客户的其他信
息)输入人工神经网络(见第10章),从而输出客户最可能购买的产
品。这个神经网络是在所有客户的购买记录上训练的。
为游戏建造智能机器人
这通常通过强化学习(RL,见第18章)来解决。强化学习是机器
学习的一个分支,在一个给定的环境(例如游戏)中,训练代理(例
如机器人)选择在一段时间内将它们的奖励最大化的行动(例如,机
器人可能会在玩家每次失去一些生命值时获得奖励)。在围棋比赛中
打败世界冠军的著名AlphaGo程序就是使用RL构建的。
这个列表可以一直延伸下去,但希望它能让你了解机器学习所能
处理的任务的广度和复杂性,以及你在每个任务中会用到的技术类
型。


1.4 机器学习系统的类型
现有的机器学习系统类型繁多,为便于理解,我们根据以下标准将
它们进行大的分类:
·是否在人类监督下训练(有监督学习、无监督学习、半监督学习
和强化学习)。
·是否可以动态地进行增量学习(在线学习和批量学习)。
·是简单地将新的数据点和已知的数据点进行匹配,还是像科学家
那样,对训练数据进行模式检测然后建立一个预测模型(基于实例的学
习和基于模型的学习)。
这些标准之间互相并不排斥,你可以以你喜欢的方式将其任意组
合。例如,现在最先进的垃圾邮件过滤器可能是使用深度神经网络模型
对垃圾邮件和常规邮件进行训练,完成动态学习。这使其成为一个在线
的、基于模型的有监督学习系统。
我们来看看这几个标准。
1.4.1 有监督学习和无监督学习
根据训练期间接受的监督数量和监督类型,可以将机器学习系统分
为以下四个主要类别:有监督学习、无监督学习、半监督学习和强化学
习。
有监督学习
在有监督学习中,提供给算法的包含所需解决方案的训练集称为标
签(见图1-5)。


分类任务是一个典型的有监督学习任务。垃圾邮件过滤器就是一个
很好的示例:通过大量的电子邮件示例及其所属的类别(垃圾邮件还是
常规邮件)进行训练,然后学习如何对新邮件进行分类。
图1-5:用于垃圾邮件分类的已标记训练集(有监督学习的示例)
另一个典型的任务是通过给定一组称为预测器的特征(里程、使用
年限、品牌等)来预测一个目标数值(例如汽车的价格)。这种类型的
任务称为回归(见图1-6)[1]。要训练这样一个系统,需要提供大量的
汽车示例,包括它们的预测器和标签(即价格)。
图1-6:回归问题:在给定输入特征的情况下预测值(通常有多个输入
特征,有时有多个输出值)


在机器学习里,属性是一种数据类型(例如“里程”),而特
征取决于上下文,可能有多个含义,但是通常状况下,特征意味着一个
属性加上其值(例如,“里程=15 000”)。尽管如此,许多人还是在
使用属性和特征这两个名词时不做区分。
值得注意的是,一些回归算法也可以用于分类任务,反之亦然。例
如,逻辑回归就被广泛地用于分类,因为它可以输出“属于某个给定类
别的概率”的值(例如,20%的概率是垃圾邮件)。
这里是一些最重要的有监督学习算法(本书中会介绍):
·k-近邻算法
·线性回归
·逻辑回归
·支持向量机(SVM)
·决策树和随机森林
·神经网络[2]
无监督学习
顾名思义,无监督学习的训练数据都是未经标记的(见图1-7)。
系统会在没有“老师”的情况下进行学习。


图1-7:无标签的训练集,用于无监督学习
这里有一些最重要的无监督学习算法(大部分会在第8章和第9章中
介绍):
·聚类算法
·k-均值算法
·DBSCAN
·分层聚类分析(HCA)
·异常检测和新颖性检测
·单类SVM
·孤立森林
·可视化和降维
·主成分分析(PCA)
·核主成分分析


·局部线性嵌入(LLE)
·t-分布随机近邻嵌入(t-SNE)
·关联规则学习
·Apriori
·Eclat
例如,假设你现在拥有大量关于自己博客访客的数据。你想通过一
个聚类算法来检测相似访客的分组(见图1-8)。你不大可能告诉这个
算法每个访客属于哪个分组——算法会自行寻找这种关联。例如,它可
能会注意到40%的访客是喜欢漫画的男性,并且通常在夜晚阅读你的博
客;20%的访客是年轻的科幻爱好者,通常在周末访问;等等。如果使
用的是分层聚类算法,还可以将每组细分为更小的组。这可能有助于你
针对不同的分组来发布博客内容。
图1-8:聚类
可视化算法也是无监督学习算法的一个不错的示例:你提供大量复
杂的、未标记的数据,算法轻松绘制输出2D或3D的数据表示(见图1
9)。这些算法会尽其所能地保留尽量多的结构(例如,尝试保持输入
的单独集群在可视化中不会被重叠),以便于你理解这些数据是怎么组
织的,甚至识别出一些未知的模式。


与之相关的一个任务是降维,降维的目的是在不丢失太多信息的前
提下简化数据。方法之一是将多个相关特征合并为一个。例如,汽车里
程与其使用年限存在很大的相关性,所以降维算法会将它们合并成一个
代表汽车磨损的特征。这个过程叫作特征提取。
通常比较好的做法是,先使用降维算法减少训练数据的维度,
再将其提供给另一个机器学习算法(例如有监督学习算法)。这会使它
运行得更快,数据占用的磁盘空间和内存都会更小,在某些情况下,执
行性能也会更高。
图1-9:语义聚类的t-SNE可视化示例[3]
另一个很重要的无监督任务是异常检测——例如,检测异常信用卡
交易以防止欺诈,捕捉制造缺陷,或者在给另一种机器学习算法提供数
据之前自动从数据集中移除异常值。系统用正常实例进行训练,然后当
看到新的实例时,它就可以判断出这个新实例看上去是正常还是异常
(见图1-10)。一个非常类似的任务是新颖性检测。它的目的是检测看
起来与训练集中的所有实例不同的新实例。这需要一个非常“干净”的


训练集,没有你希望算法能检测到的任何实例。例如,如果你有成千上
万张狗的照片,其中1%是吉娃娃犬,那么一个新颖性检测算法不应将吉
娃娃犬的新图片视为新颖。另一方面,异常检测算法可能会认为这些狗
非常罕见,与其他狗不同,可能会把它们归类为异常(没有对吉娃娃犬
不敬的意思)。
图1-10:异常检测
最后,还有一个常见的无监督任务是关联规则学习,其目的是挖掘
大量数据,发现属性之间的有趣联系。例如,假设你开了一家超市,在
销售日志上运行关联规则之后发现买烧烤酱和薯片的人也倾向于购买牛
排。那么,你可能会将这几样商品摆放得更近一些。
半监督学习
由于通常给数据做标记是非常耗时和昂贵的,你往往会有很多未标
记的数据而很少有已标记的数据。有些算法可以处理部分已标记的数
据。这被称为半监督学习(见图1-11)。


图1-11:半监督学习有两个类别(三角形和正方形):未标记的示例
(圆形)有助于将新实例(十字)分类为三角形类别而不是正方形类
别,即使它更接近于标记的正方形
有些照片托管服务(例如Google相册)就是很好的示例。一旦你将
所有的家庭照片上传到服务器后,它会自动识别出人物A出现在照片1、
5和11中,人物B出现在照片2、5和7中。这是算法的无监督部分(聚
类)。现在系统需要你做的只是告诉它这些人都是谁。给每个人一个标
签之后[4],它就可以给每张照片中的每个人命名,这对于搜索图片非
常重要。
大多数半监督学习算法是无监督算法和有监督算法的结合。例如,
深度信念网络(DBN)基于一种互相堆叠的无监督组件,这个组件叫作
受限玻尔兹曼机(RBM)。受限玻尔兹曼机以无监督方式进行训练,然
后使用有监督学习技术对整个系统进行微调。
强化学习
强化学习则是一个非常与众不同的“巨兽”。它的学习系统(在其
语境中称为智能体)能够观察环境,做出选择,执行动作,并获得回报
(或者是以负面回报的形式获得惩罚,见图1-12)。所以它必须自行学
习什么是最好的策略,从而随着时间的推移获得最大的回报。策略代表
智能体在特定情况下应该选择的动作。


图1-12:强化学习
例如,许多机器人通过强化学习算法来学习如何行走。DeepMind的
AlphaGo项目也是一个强化学习的好示例。2017年5月,AlphaGo在围棋
比赛中击败世界冠军柯洁而声名鹊起。通过分析数百万场比赛,然后自
己跟自己下棋,它学到了制胜策略。要注意,在跟世界冠军对弈的时
候,AlphaGo处于关闭学习状态,它只是应用它所学到的策略而已。
1.4.2 批量学习和在线学习
另一个给机器学习系统分类的标准是看系统是否可以从传入的数据
流中进行增量学习。
批量学习
在批量学习中,系统无法进行增量学习——即必须使用所有可用数
据进行训练。这需要大量时间和计算资源,所以通常都是离线完成的。


离线学习就是先训练系统,然后将其投入生产环境,这时学习过程停
止,它只是将其所学到的应用出来。
如果希望批量学习系统学习新数据(例如新型垃圾邮件),需要在
完整数据集(包括新数据和旧数据)的基础上重新训练系统的新版本,
然后停用旧系统,用新系统取而代之。幸运的是,整个训练、评估和启
动机器学习系统的过程可以很轻易地实现自动化(如图1-3所示),所
以即使是批量学习系统也能够适应变化。只是需要不断地更新数据,并
根据需要频繁地训练系统的新版本。
这个解决方案比较简单,通常也都能正常工作,只是每次都使用完
整数据集进行训练可能需要花上好几个小时,所以,你很有可能会选择
每天甚至每周训练一次新系统。如果系统需要应对快速变化的数据(例
如,预测股票价格),那么你需要一个更具响应力的解决方案。
此外,使用完整数据集训练需要耗费大量的计算资源(CPU、内存
空间、磁盘空间、磁盘I/O、网络I/O等)。如果你的数据量非常大,并
且每天从零开始自动执行训练系统,那最终你将为此花费大量的金钱。
而假如你面对的是海量数据,甚至可能无法再应用批量学习算法。
所以如果你的资源有限(例如,一个智能手机应用程序或一个火星
上的漫游器),而系统需要实现自主学习,那么像这样携带大量训练数
据,占用大量资源,动辄每天耗费几小时来进行训练的方式,肯定会让
你心有余而力不足。
幸运的是,在所有这些情况下,我们有一个更好的选择——能够进
行增量学习的算法。
在线学习
在在线学习中,你可以循序渐进地给系统提供训练数据,逐步积累
学习成果。这种提供数据的方式可以是单独的,也可以采用小批量的小


组数据来进行训练。每一步学习都很快速并且便宜,这样系统就可以根
据飞速写入的最新数据进行学习(见图1-13)。
图1-13:在线学习中,模型经过训练并投入生产环境,然后随着新数据
的进入而不断学习
对于这类系统——需要接收持续的数据流(例如股票价格),同时
对数据流的变化做出快速或自主的反应,使用在线学习是一个非常好的
方式。如果你的计算资源有限,在线学习同样也是一个很好的选择:新
的数据实例一旦经过在线学习系统的学习,就不再需要,你可以将其丢
弃(除非你想回滚到前一个状态,再“重新学习”数据),这可以节省
大量的空间。
对于超大数据集——超出一台计算机的主存储器的数据,在线学习
算法也同样适用(这称为核外学习)。算法每次只加载部分数据,并针
对这部分数据进行训练,然后不断重复这个过程,直到完成所有数据的
训练(见图1-14)。


图1-14:使用在线学习来处理超大数据集
核外学习通常是离线完成的(也就是不在实时(live)系统
上),因此在线学习这个名字很容易让人产生误解。我们可以将其视为
增量学习。
在线学习系统的一个重要参数是其适应不断变化的数据的速度,这
就是所谓的学习率。如果设置的学习率很高,那么系统将会迅速适应新
数据,但同时也会很快忘记旧数据(你肯定不希望垃圾邮件过滤器只对
最新显示的邮件进行标记)。反过来,如果学习率很低,系统会有更高
的惰性,也就是说,学习会更缓慢,同时也会对新数据中的噪声或者非
典型数据点(离群值)的序列更不敏感。
在线学习面临的一个重大挑战是,如果给系统输入不良数据,系统
的性能将会逐渐下降。现在某些实时系统的客户说不定已经注意到了这
个现象。不良数据的来源可能是机器上发生故障的传感器,或者是有人
对搜索引擎恶意刷屏以提高搜索结果排名等。为了降低这种风险,你需
要密切监控系统,一旦检测到性能下降,就及时中断学习(可能还需要
恢复到之前的工作状态)。当然,同时你还需要监控输入数据,并对异
常数据做出响应(例如,使用异常检测算法)。


1.4.3 基于实例的学习与基于模型的学习
另一种对机器学习系统进行分类的方法是看它们如何泛化。大多数
机器学习任务是要做出预测。这意味着系统需要通过给定的训练示例,
在它此前并未见过的示例上进行预测(泛化)。在训练数据上实现良好
的性能指标固然重要,但是还不够充分。真正的目的是要在新的对象实
例上表现出色。
泛化的主要方法有两种:基于实例的学习和基于模型的学习。
基于实例的学习
我们最司空见惯的学习方法就是简单地死记硬背。如果以这种方式
创建一个垃圾邮件过滤器,那么它可能只会标记那些与已被用户标记为
垃圾邮件完全相同的邮件——这虽然不是最差的解决方案,但肯定也不
是最好的。
除了完全相同的,你还可以通过编程让系统标记与已知的垃圾邮件
非常相似的邮件。这里需要两封邮件之间的相似度度量。一种(基本
的)相似度度量方式是计算它们之间相同的单词数目。如果一封新邮件
与一封已知的垃圾邮件有许多单词相同,系统就可以将其标记为垃圾邮
件。
这被称为基于实例的学习:系统用心学习这些示例,然后通过使用
相似度度量来比较新实例和已经学习的实例(或它们的子集),从而泛
化新实例。例如,图1-15中的新实例会归为三角形,因为大多数最相似
的实例属于那一类。


图1-15:基于实例的学习
基于模型的学习
从一组示例集中实现泛化的另一种方法是构建这些示例的模型,然
后使用该模型进行预测。这称为基于模型的学习(见图1-16)。
举例来说,假设你想知道金钱是否让人感到快乐,你可以从经合组
织(OECD)的网站上下载“幸福指数”的数据,再从国际货币基金组织
(IMF)的网站上找到人均GDP的统计数据,将数据并入表格,按照人均
GDP排序,你会得到如表1-1所示的摘要。
图1-16:基于模型的学习
表1-1:金钱能让人更快乐吗?


让我们绘制这些国家的数据(见图1-17)。
图1-17:趋势图
这里似乎有一个趋势!虽然数据包含噪声(即部分随机),但是仍
然可以看出随着该国人均GDP的增加,生活满意度或多或少呈线性上升
的趋势。所以你可以把生活满意度建模成一个关于人均GDP的线性函
数。这个过程叫作模型选择。你为生活满意度选择了一个线性模型,该
模型只有一个属性,就是人均GDP(见公式1-1)。
公式1-1:一个简单的线性模型
这个模型有两个模型参数:θ0和θ1[5]。通过调整这两个参数,可
以用这个模型来代表任意线性函数,如图1-18所示。


图1-18:一些可能的线性模型
在使用模型之前,需要先定义参数θ0和θ1的值。怎么才能知道什
么值可以使模型表现最佳呢?要回答这个问题,需要先确定怎么衡量模
型的性能表现。要么定义一个效用函数(或适应度函数)来衡量模型有
多好,要么定义一个成本函数来衡量模型有多差。对于线性回归问题,
通常的选择是使用成本函数来衡量线性模型的预测与训练实例之间的差
距,目的在于尽量使这个差距最小化。
这正是线性回归算法的意义所在:通过你提供的训练样本,找出最
符合提供数据的线性模型的参数,这称为训练模型。在这个案例中,算
法找到的最优参数值为θ0=4.85和θ1=4.91×10-5。
令人困惑的是,同一个词“模型”可以指模型的一种类型
(例如,线性回归),到一个完全特定的模型架构(例如,有一个输入
和一个输出的线性回归),或者到最后可用于预测的训练模型(例如,
有一个输入和一个输出的线性回归,使用参数θ0=4.85和
θ1=4.91×10-5)。模型选择包括选择模型的类型和完全指定它的架
构。训练一个模型意味着运行一种寻找模型参数的算法,使其最适合训
练数据(希望能对新的数据做出好的预测)。
现在,(对于线性模型而言)模型基本接近训练数据,如图1-19所
示。


图1-19:最拟合训练数据的线性模型
现在终于可以运行模型来进行预测了。例如,你想知道塞浦路斯人
有多幸福,但是经合组织的数据没有提供答案。幸好你有这个模型可以
做出预测:先查查塞浦路斯的人均GDP是多少,发现是22 587美元,然
后应用到模型中,发现生活满意度大约是4.85+22 587×4.91×10
5=5.96。
为了激发你的兴趣,示例1-1是一段加载数据的Python代码,包括
准备数据[6],创建一个可视化的散点图,然后训练线性模型并做出预
测[7]。
示例1-1:使用Scikit-Learn训练并运行一个线性模型
import matplotlib.pyplot as plt import numpy as np import pandas as pd import sklearn.linear_model
# Load the data oecd_bli = pd.read_csv("oecd_bli_2015.csv", thousands=',') gdp_per_capita = pd.read_csv("gdp_per_capita.csv",thousands=',',delimiter='\t', encoding='latin1', na_values="n/a")
# Prepare the data country_stats = prepare_country_stats(oecd_bli, gdp_per_capita) X = np.c_[country_stats["GDP per capita"]] y = np.c_[country_stats["Life satisfaction"]]
# Visualize the data country_stats.plot(kind='scatter', x="GDP per capita", y='Life satisfaction') plt.show()


# Select a linear model model = sklearn.linear_model.LinearRegression() # Train the model model.fit(X, y)
# Make a prediction for Cyprus X_new = [[22587]] # Cyprus's GDP per capita print(model.predict(X_new)) # outputs [[ 5.96242338]]
如果使用基于实例的学习算法,你会发现斯洛文尼亚的人均
GDP最接近塞浦路斯(20 732美元),而经合组织的数据告诉我们,斯
洛文尼亚人的生活满意度是5.7,因此你很可能会预测塞浦路斯的生活
满意度为5.7。如果稍微拉远一些,看看两个与之最接近的国家——葡
萄牙和西班牙的生活满意度分别为5.1和6.5。取这三个数值的平均值,
得到5.77,这也非常接近基于模型预测所得的值。这个简单的算法被称
为k-近邻回归(在本例中,k=3)。
要将前面代码中的线性回归模型替换为k-近邻回归模型非常简单,
只需要将下面这行代码:
import sklearn.linear_model model = sklearn.linear_model.LinearRegression()
替换为:
import sklearn.neighbors model = sklearn.neighbors.KNeighborsRegressor( n_neighbors=3)
如果一切顺利,你的模型将会做出很棒的预测。如果不行,则需要
使用更多的属性(例如就业率、健康、空气污染等),获得更多或更高


质量的训练数据,或者选择一个更强大的模型(例如,多项式回归模
型)。
简而言之:
·研究数据。
·选择模型。
·使用训练数据进行训练(即前面学习算法搜索模型参数值,从而
使成本函数最小化的过程)。
·最后,应用模型对新示例进行预测(称为推断),希望模型的泛
化结果不错。
以上就是一个典型的机器学习项目。在第2章中,你还将通过一个
端到端的项目来体验这一切。
到目前为止,我们介绍了多个领域。你已经知道什么是真正的机器
学习,它为何有用,机器学习系统最常见的类别有哪些,以及典型的项
目工作流程。现在让我们看看在学习过程中可能会遇到哪些阻碍你做出
准确预测的问题。
[1] 有趣的事实:这个奇怪的名字是Francis Galton在研究高个子的孩
子往往比父母矮的事实时引入的一个统计术语。由于孩子比父母要矮一
些,他称这种现象为回归到均值。该术语后来被他应用于分析变量之间
相关性的方法。
[2] 某些神经网络架构可以是无监督的,例如自动编码器和受限玻尔兹
曼机。它们也可以是半监督的,例如在深度信念网络和无监督的预训练
中。
[3] 请注意,动物与车辆的隔离得很远,马与鹿的距离近却与鸟的距离
远。图的使用得到了Richard Socher等人许可,“Zero-Shot Learning


Through Cross-Modal Transfer” , Proceedings of the 26th
International Conference on Neural Information Processing
Systems 1(2013):935–943。
[4] 这是系统运行良好的情况。在实践中,它通常为每人创建几个集
群,有时将两个看起来相似的人混合在一起,因此你可能需要为每个人
提供一些标签并手动清理一些集群。
[5] 按照惯例,希腊字母θ(theta)通常用于表示模型参数。
[6] prepare_country_stats()函数的定义未在此处显示(如果需要
所有详细信息,请参阅本章的Jupyter notebook)。这只是pandas代
码,将OECD的生活满意度数据与IMF的人均GDP数据相结合。
[7] 如果你还不理解所有代码,没有关系,我们将在以下各章中介绍
Scikit-Learn。


1.5 机器学习的主要挑战
简单来说,由于你的主要任务是选择一种学习算法,并对某些数据
进行训练,所以最可能出现的两个问题不外乎是“坏算法”和“坏数
据”,让我们先从坏数据开始。
1.5.1 训练数据的数量不足
要教一个牙牙学语的小朋友什么是苹果,你只需要指着苹果说“苹
果”(可能需要重复这个过程几次)就行了,然后孩子就能够识别各种
颜色和形状的苹果了,简直是天才!
机器学习还没达到这一步,大部分机器学习算法需要大量的数据才
能正常工作。即使是最简单的问题,很可能也需要成千上万个示例,而
对于诸如图像或语音识别等复杂问题,则可能需要数百万个示例(除非
你可以重用现有模型的某些部分)。
数据的不合理有效性
在2001年发表的一篇著名论文中,微软研究员Michele Banko和
Eric Brill表明,给定足够的数据,截然不同的机器学习算法(包括相
当简单的算法)在自然语言歧义消除这个复杂问题上[1],表现几乎完
全一致(如图1-20所示)。


图1-20:数据与算法的重要性[2]
正如作者所说:“这些结果表明,我们可能会重新思考如何在二者
之间做权衡——将钱和时间花在算法的开发上,还是花在语料库的建设
上。”
对复杂问题而言,数据比算法更重要,这一想法被Peter Norvig等
人进一步推广,于2009年发表论文“The Unreasonable Effectiveness
of Data”[3]。不过需要指出的是,中小型数据集依然非常普遍,获得
额外的训练数据并不总是一件轻而易举或物美价廉的事情,所以暂时先
不要抛弃算法。
1.5.2 训练数据不具代表性
为了很好地实现泛化,至关重要的一点是对于将要泛化的新示例来
说,训练数据一定要非常有代表性。无论你使用的是基于实例的学习还
是基于模型的学习,都是如此。


例如,前面用来训练线性模型的国家数据集并不具备完全的代表
性,有部分国家的数据缺失。图1-21显示了补充缺失国家信息之后的数
据表现。
图1-21:更具代表性的训练样本
如果你用这个数据集训练线性模型,将会得到图中的实线,而虚线
表示旧模型。正如你所见,添加部分缺失的国家信息不仅显著地改变了
模型,也更清楚地说明这种简单的线性模型可能永远不会那么准确。看
起来,某些非常富裕的国家并不比中等富裕的国家更幸福(事实上,看
起来甚至是不幸福),反之,一些贫穷的国家也似乎比许多富裕的国家
更加幸福。
使用不具代表性的训练集训练出来的模型不可能做出准确的预估,
尤其是针对那些特别贫穷或特别富裕的国家。
针对你想要泛化的案例使用具有代表性的训练集,这一点至关重
要。不过说起来容易,做起来难:如果样本集太小,将会出现采样噪声
(即非代表性数据被选中);而即便是非常大的样本数据,如果采样方
式欠妥,也同样可能导致非代表性数据集,这就是所谓的采样偏差。
关于采样偏差的一个示例


最著名的采样偏差的示例发生在1936年美国总统大选期间,兰登对
决罗斯福。Literary Digest当时举行了一次大范围的民意调查,向约
1000万人发送邮件,并得到了240万个回复,因此做出了高度自信的预
言——兰登将获得57%的选票。结果恰恰相反,罗斯福赢得了62%的选
票。问题就在于Literary Digest的采样方式:
·首先,为了获取发送民意调查的地址,Literary Digest采用了
电话簿、杂志订阅名单、俱乐部会员名单等类似名簿。而所有这些名单
上的人往往对富人有更大的偏好,也就更有可能支持共和党(即兰
登)。
·其次,收到民意调查邮件的人中,不到25%的人给出了回复。这
再次引入了采样偏差,那些不怎么关心政治的人、不喜欢Literary
Digest的人以及其他的一些关键群体直接被排除在外了。这是一种特殊
类型的采样偏差,叫作无反应偏差。
再举一个示例,假设你想创建一个系统用来识别funk音乐视频。构
建训练集的方法之一是直接在YouTube上搜索“funk music”,然后使
用搜索结果的视频。但是,这其实基于一个假设——YouTube的搜索引
擎返回的视频结果是所有能够代表funk音乐的视频。而实际的搜索结果
可能会更偏向于当前流行的音乐人(如果你住在巴西,你会得到很多关
于“funk carioca”的视频,这听起来跟James Brown完全不是一回
事)。另一方面,你还能怎样获得一个大的训练集?
1.5.3 低质量数据
显然,如果训练集满是错误、异常值和噪声(例如,低质量的测量
产生的数据),系统将更难检测到底层模式,更不太可能表现良好。所
以花时间来清理训练数据是非常值得的投入。事实上,大多数数据科学
家都会花费很大一部分时间来做这项工作。例如:


·如果某些实例明显是异常情况,那么直接将其丢弃,或者尝试手
动修复错误,都会大有帮助。
·如果某些实例缺少部分特征(例如,5%的顾客没有指定年龄),
你必须决定是整体忽略这些特征、忽略这部分有缺失的实例、将缺失的
值补充完整(例如,填写年龄值的中位数),还是训练一个带这个特征
的模型,再训练一个不带这个特征的模型。
1.5.4 无关特征
正如我们常说的:垃圾入,垃圾出。只有训练数据里包含足够多的
相关特征以及较少的无关特征,系统才能够完成学习。一个成功的机器
学习项目,其关键部分是提取出一组好的用来训练的特征集。这个过程
叫作特征工程,包括以下几点:
·特征选择(从现有特征中选择最有用的特征进行训练)。
·特征提取(将现有特征进行整合,产生更有用的特征——正如前
文提到的,降维算法可以提供帮助)。
·通过收集新数据创建新特征。
现在我们已经看了不少“坏数据”的示例,再来看几个“坏算法”
的示例。
1.5.5 过拟合训练数据
假设你正在国外旅游,被出租车司机敲诈,你很可能会说,那个国
家的所有出租车司机都是强盗。过度概括是我们人类常做的事情,不幸
的是,如果我们不小心,机器很可能也会陷入同样的陷阱。在机器学习
中,这称为过拟合,也就是指模型在训练数据上表现良好,但是泛化时
却不尽如人意。


图1-22显示了一个训练数据过拟合的高阶多项式生活满意度模型。
虽然它在训练数据上的表现比简单的线性模型要好得多,但是你真的敢
相信它的预测吗?
图1-22:过拟合训练数据
虽然诸如深度神经网络这类的复杂模型可以检测到数据中的微小模
式,但是如果训练集本身是有噪声的,或者数据集太小(引入了采样噪
声),那么很可能会导致模型检测噪声本身的模式。很显然,这些模式
不能泛化至新的实例。举例来说,假设你给生活满意度模型提供了更多
其他的属性,包括一些不具信息的属性(例如国家名)。在这种情况
下,一个复杂模型可能会检测到这样的事实模式:训练数据中,名字中
带有字母w的国家,如新西兰(New Zealand,生活满意度为7.3)、挪
威(Norway,生活满意度为7.4)、瑞典(Sweden,生活满意度为7.2)
和瑞士(Switzerland,生活满意度为7.5),生活满意度均大于7。当
把这个w满意度规则泛化到卢旺达(Rwanda)或津巴布韦(Zim-babwe)
时,你对结果有多大的自信?显然,训练数据中的这个模式仅仅是偶然
产生的,但是模型无法判断这个模式是真实的还是噪声产生的结果。
当模型相对于训练数据的数量和噪度都过于复杂时,会发生
过拟合。可能的解决方案如下。


·简化模型:可以选择较少参数的模型(例如,选择线性模型而不
是高阶多项式模型)也可以减少训练数据中的属性数量,或者是约束模
型。
·收集更多的训练数据。
·减少训练数据中的噪声(例如,修复数据错误和消除异常值)。
通过约束模型使其更简单,并降低过拟合的风险,这个过程称为正
则化。例如,我们前面定义的线性模型有两个参数:θ0和θ1。因此,
该算法在拟合训练数据时,调整模型的自由度就等于2,它可以调整线
的高度(θ0)和斜率(θ1)。如果我们强行让θ1=0,那么算法的自
由度将会降为1,并且拟合数据将变得更为艰难——它能做的全部就只
是将线上移或下移来尽量接近训练实例,最后极有可能停留在平均值附
近。这确实太简单了!如果我们允许算法修改θ1,但是我们强制它只
能是很小的值,那么算法的自由度将位于1和2之间,这个模型将会比自
由度为2的模型稍微简单一些,同时又比自由度为1的模型略微复杂一
些。你需要在完美匹配数据和保持模型简单之间找到合适的平衡点,从
而确保模型能够较好地泛化。
图1-23显示了三个模型。点线表示的是在以圆圈表示的国家上训练
的原始模型(没有正方形表示的国家),虚线是我们在所有国家(圆圈
和方形)上训练的第二个模型,实线是用与第一个模型相同的数据训练
的模型,但是有一个正则化约束。可以看到,正则化强制了模型的斜率
较小:该模型与训练数据(圆圈)的拟合不如第一个模型,但它实际上
更好地泛化了它没有在训练时看到的新实例(方形)。
在学习时,应用正则化的程度可以通过一个超参数来控制。超参数
是学习算法(不是模型)的参数。因此,它不受算法本身的影响。超参
数必须在训练之前设置好,并且在训练期间保持不变。如果将正则化超
参数设置为非常大的值,会得到一个几乎平坦的模型(斜率接近零)。
学习算法虽然肯定不会过拟合训练数据,但是也更加不可能找到一个好


的解决方案。调整超参数是构建机器学习系统非常重要的组成部分(将
在第2章中详细举例)。
图1-23:正则化降低了过拟合的风险
1.5.6 欠拟合训练数据
你可能已经猜到了,欠拟合和过拟合正好相反。它的产生通常是因
为对于底层的数据结构来说,你的模型太过简单。例如,用线性模型来
描述生活满意度就属于欠拟合。现实情况远比模型复杂得多,所以即便
是对于用来训练的示例,该模型产生的预测都一定是不准确的。
解决这个问题的主要方式有:
·选择一个带有更多参数、更强大的模型。
·给学习算法提供更好的特征集(特征工程)。
·减少模型中的约束(例如,减少正则化超参数)。
1.5.7 退后一步
现在你已经对机器学习有了一定了解。不过讲了这么多概念,你可
能有点晕,我们暂且退后一步,纵观一下全局:


·机器学习是关于如何让机器可以更好地处理某些特定任务的理
论,它从数据中学习,而无须清晰地编码规则。
·机器学习系统有很多类型:有监督和无监督,批量的和在线的,
基于实例的和基于模型的,等等。
·在一个机器学习项目中,你从训练集中采集数据,然后将数据交
给学习算法来计算。如果算法是基于模型的,它会调整一些参数来将模
型适配于训练集(即对训练集本身做出很好的预测),然后算法就可以
对新的场景做出合理的预测。如果算法是基于实例的,它会记住这些示
例,并根据相似度度量将它们与所学的实例进行比较,从而泛化这些新
实例。
·如果训练集的数据太少或数据代表性不够,包含太多噪声或者被
一些无关特征污染(垃圾进,垃圾出),那么系统将无法很好地工作。
最后,你的模型既不能太简单(会导致欠拟合),也不能太复杂(会导
致过拟合)。
还有最后一个要讲的重要主题是:一旦训练了一个模型,你就不能
只是“希望”它可以正确地对新的场景做出泛化,你还需要评估它,必
要时做出一些调整。现在我们看看怎么做到这一点。
[1] 例如,根据上下文知道是写“to”“two”还是“too”。
[2] 图经Michele Banko和Eric Brill许可转载,“Scaling to Very
Very Large Corpora for Natural Language Disambiguation” ,
Proceedings of the 39th Annual Meeting of the Association for
Computational Linguistics(2001):26–33.
[3] Peter Norvig et al. , “The Unreasonable Effectiveness of
Data”,IEEE Intelligent Systems 24,no.2(2009):8–12.


1.6 测试与验证
了解一个模型对于新场景的泛化能力的唯一办法就是让模型真实
地去处理新场景。做法之一是将其部署在生产环境中,然后监控它的
输出。这种做法不错,不过如果模型非常糟糕,你的用户就会抱怨,
所以这显然不是最好的办法。
更好的选择是将数据分割成两部分:训练集和测试集。顾名思
义,你可以用训练集的数据来训练模型,然后用测试集的数据来测试
模型。应对新场景的误差率称为泛化误差(或者样例外误差),通过
测试集来评估你的模型,就可以得到对这个误差的评估。这个估值可
以告诉你模型在处理新场景时的能力如何。
如果训练误差很低(模型对于训练集来说很少出错),但是泛化
误差很高,那么说明你的模型对于训练数据存在过拟合。
通常将80%的数据用于训练,而保持20%供测试用。但是,这
取决于数据集的大小。如果数据包含1000万个实例,那么保留1%意味
着包含100 000个实例作为你的测试集,可能足以很好地估计泛化误
差。
1.6.1 超参数调整和模型选择
评估一个模型很简单:用测试集就行了。现在假设你在两个模型
(一个线性模型和一个多项式模型)之间犹豫不决,如何做出判断
呢?做法是训练两个模型,然后对比它们对测试数据的泛化能力。
现在假设线性模型的泛化能力更强,但是你想要应用一些正则化
来避免过拟合。问题又来了,要如何选择正则化超参数的值呢?做法


之一是使用100个不同的超参数值来训练100个不同的模型。然后假设
你由此找到了最佳的超参数值,它生成的模型泛化误差最小,比如仅
仅5%。然后在生产环境中运行这个模型,可是很不幸,它并没有如预
期那样工作,反而产生了15%的误差。到底发生了什么?
问题出在你对测试集的泛化误差进行了多次度量,并且调整模型
和超参数来得到拟合那个测试集的最佳模型。这意味着该模型对于新
的数据不太可能有良好的表现。
解决此问题的常见方法称为保持验证:你只需保持训练集的一部
分,以评估几种候选模型并选择最佳模型。新的保留集称为验证集,
有时也称为开发集(dev set)。更具体地说,你可以在简化的训练集
上(即完整训练集减去验证集)训练具有各种超参数的多个模型,并
且选择在验证集上表现最佳的模型。在此保持验证之后,你在完整的
训练集(包括验证集)上训练最佳模型,这就是你的最终模型。最
后,你在测试集上评估这个模型以获得泛化误差的估计值。
这个解决方案通常效果很好。但是,如果验证集太小,则模型评
估将不精确:你可能最终错误地选择一个次优模型。相反,如果验证
集太大,则剩余训练集将比完整的训练集小得多。为什么这样不好?
好吧,既然最终模型将在完整的训练集上训练,比较在更小的训练集
上训练出来的候选模型不是一个好办法。就像选择最快的短跑运动员
参加马拉松比赛。解决此问题的一种方法是执行使用许多小验证集重
复进行的交叉验证。每个模型都在对其余数据进行训练后,在每个验
证集上评估一次。通过对模型的所有评估求平均值,可以更准确地衡
量模型的性能。但是有一个缺点:训练时间是验证集个数的倍数。
1.6.2 数据不匹配
在某些情况下,很容易获得大量训练数据,但是这些数据可能不
能完全代表将用于生产环境的数据。


例如,假设你要创建一个移动App来拍摄花朵并自动确定其种类。
你可以在网络轻松下载数以百万计的花朵图片,但它们并不能完美地
代表在移动设备上使用该App拍摄的图片。也许你只有10 000张代表图
片(即App实际拍摄的照片)。在这种情况下,最重要的规则是:验证
集和测试集必须与在生产环境中使用的数据具有相同的代表性,因此
它们应当由专用代表性图片组成:你可以将其混洗并一半放入验证集
中,一半放入测试集中(确保两者不重复也不接近重复)。但是在网
络图片上训练了模型之后,如果模型在验证集上的性能令人失望,那
么你将不知道这是因为你的模型过拟合了训练集,还是只是由于网络
图片和移动应用图片之间的不匹配。一种解决方案是将一些训练图片
(网络上下载的)放到被吴恩达(Andrew Ng)称为train-dev(训练
开发)集的另外一个集合中。训练模型后(在训练集而不是在train
dev集上),你可以在train-dev集上对其进行评估。如果模型表现良
好,则不会过拟合训练集。如果在验证集上表现不佳,那么问题一定
来自数据不匹配。你可以尝试通过预处理网络图片来使其看起来更像
由移动应用拍摄的照片,然后重新训练模型。相反,如果模型在
train-dev集上表现不佳,则它肯定在训练集上过拟合了,因此你应该
尝试简化或规范化模型,获取更多训练数据,并清理训练数据。
没有免费的午餐定理
模型是观察的简化版。这个简化丢弃了那些不大可能泛化至新实
例上的多余细节。但是,要决定丢弃哪些数据以及保留哪些数据,你
必须要做出假设。例如,线性模型基于的假设就是数据基本上都是线
性的,而实例与直线之间的距离都只是噪声,可以安全地忽略它们。
1996年David Wolpert在一篇著名论文中表明[1],如果你对数据绝
对没有任何假设,那么就没有理由更偏好于某个模型,这称为没有免
费的午餐(No Free Lunch,NFL)定理。对某些数据集来说,最佳模
型是线性模型,而对于其他数据集来说,最佳模型可能是神经网络模
型。不存在一个先验模型能保证一定工作得更好(这正是定理名称的


由来)。想要知道哪个模型最好的方法就是对所有模型进行评估,但
实际上这是不可能的,因此你会对数据做出一些合理的假设,然后只
评估部分合理的模型。例如,对于简单的任务,你可能只会评估几个
具有不同正则化水平的线性模型,而对于复杂问题,你可能会评估多
个神经网络模型。
[1] David Wolpert , “The Lack of A Priori Distinctions
Between Learning Algorithms” , Neural Computation 8 ,
no.7(1996):1341–1390.


1.7 练习题
本章中,我们提及了机器学习中最重要的一些概念。第2章将会进
行更深入的探讨,也会写更多代码,但是在那之前,请先确保你已经
知道如何回答下列问题:
1.如何定义机器学习?
2.机器学习在哪些问题上表现突出,你能给出四种类型吗?
3.什么是被标记的训练数据集?
4.最常见的两种监督学习任务是什么?
5.你能举出四种常见的无监督学习任务吗?
6.要让一个机器人在各种未知的地形中行走,你会使用什么类型
的机器学习算法?
7.要将顾客分成多个组,你会使用什么类型的算法?
8.你会将垃圾邮件检测的问题列为监督学习还是无监督学习?
9.什么是在线学习系统?
10.什么是核外学习?
11.什么类型的学习算法依赖相似度来做出预测?
12.模型参数与学习算法的超参数之间有什么区别?


13.基于模型的学习算法搜索的是什么?它们最常使用的策略是什
么?它们如何做出预测?
14.你能给出机器学习中的四个主要挑战吗?
15.如果模型在训练数据上表现很好,但是应用到新实例上的泛化
结果却很糟糕,是怎么回事?能给出三种可能的解决方案吗?
16.什么是测试集,为什么要使用测试集?
17.验证集的目的是什么?
18.什么是train-dev集,什么时候需要它,怎么使用?
19.如果你用测试集来调超参数会出现什么错误?
以上练习题的答案见附录A。


第2章 端到端的机器学习项目
本章将介绍一个端到端的项目案例。假设你是一个房地产公司最
近新雇用的数据科学家[1],以下是你将会经历的主要步骤:
1.观察大局。
2.获得数据。
3.从数据探索和可视化中获得洞见。
4.机器学习算法的数据准备。
5.选择并训练模型。
6.微调模型。
7.展示解决方案。
8.启动、监控和维护系统。
[1] 项目案例纯属虚构,目的仅仅是为了说明机器学习项目的主要步
骤,而不是为了了解房地产业务。


2.1 使用真实数据
学习机器学习最好使用真实数据进行实验,而不仅仅是人工数据
集。我们有成千上万覆盖了各个领域的开放数据集可以选择。以下是一
些可以获得数据的地方。
·流行的开放数据存储库:
·UC Irvine Machine Learning
Repository(http://archive.ics.uci.edu/ml/)
·Kaggle datasets(https://www.kaggle.com/datasets)
·Amazon’s AWS
datasets(http://aws.amazon.com/fr/datasets/)
·元门户站点(它们会列出开放的数据存储库):
·Data Portals(http://dataportals.org/)
·OpenDataMonitor(http://opendatamonitor.eu/)
·Quandl(http://quandl.com/)
·其他一些列出许多流行的开放数据存储库的页面:
·Wikipedia’s list of Machine Learning
datasets(https://goo.gl/SJHN2k)
·Quora.com(http://goo.gl/zDR78y)


·The datasets
subreddit(https://www.reddit.com/r/datasets)
本章我们从StatLib库中选择了加州住房价格的数据集(见图2-1)
[1]。该数据集基于1990年加州人口普查的数据。虽然不算是最新的数
据(当时你还能负担得起一个湾区的好房子),但是有很多可以学习的
特质,所以我们就假定这是最新的数据吧。出于教学目的,我们还特意
添加了一个分类属性,并且移除了一些特征。
图2-1:加州住房价格
[1] 原 始 数 据 集 由 R.Kelley Pace 和 Ronald Barry 提 供 , “Sparse
Spatial Autoregressions”,Statistics&Probability Letters 33,
no.3(1997):291–297。


2.2 观察大局
欢迎来到机器学习房产公司!你要做的第一件事是使用加州人口普
查的数据建立起加州的房价模型。数据中有许多指标,诸如每个街区的
人口数量、收入中位数、房价中位数等。街区是美国人口普查局发布样
本数据的最小地理单位(一个街区通常人口数为600到3000人)。这
里,我们将其简称为“区域”。
你的模型需要从这个数据中学习,从而能够根据所有其他指标,预
测任意区域的房价中位数。
如果你是一名习惯良好的数据科学家,要做的第一件事应该是
拿出机器学习项目清单。你可以从附录B中的清单项开始,它适合绝大
多数机器学习项目,但还是要确保它满足你的需求。本章我们将会讨论
这个清单中的部分内容,但也会跳过一部分,有些是因为不需要多做解
释,有些是因为在后面的章节中会展开讨论。
2.2.1 框架问题
你问老板的第一个问题应该是业务目标是什么,因为建立模型本身
可能不是最终的目标。公司期望知道如何使用这个模型,如何从中获
益?这才是重要的问题,因为这将决定你怎么设定问题,选择什么算
法,使用什么测量方式来评估模型的性能,以及应该花多少精力来进行
调整。
老板回答说,这个模型的输出(对一个区域房价中位数的预测)将
会跟其他许多信号一起被传输给另一个机器学习系统(见图2-2)[1]。
而这个下游系统将被用来决策一个给定的区域是否值得投资。因为直接
影响到收益,所以正确获得这个信息至关重要。


图2-2:一个针对房地产投资的机器学习流水线
流水线
一个序列的数据处理组件称为一个数据流水线。流水线在机器学习
系统中非常普遍,因为需要大量的数据操作和数据转化才能应用。
组件通常是异步运行的。每个组件拉取大量的数据,然后进行处
理,再将结果传输给另一个数据仓库。一段时间之后,流水线中的下一
个组件会拉取前面的数据,并给出自己的输出,以此类推。每个组件都
很独立:组件和组件之间的连接只有数据仓库。这使得整个系统非常简
单易懂(在数据流图表的帮助下),不同团队可以专注于不同的组件。
如果某个组件发生故障,它的下游组件还能使用前面的最后一个输出继
续正常运行(至少一段时间),所以使得整体架构鲁棒性较强。
当然,从另一方面来说,如果没有实施适当的监控,坏掉的组件可
能在一段时间内都无人发现,那么过期数据会导致整个系统的性能下
降。
要向老板询问的第二个问题是当前的解决方案(如果有的话)。你
可以将其当作参考,也能从中获得解决问题的洞察。老板回答说,现在
是由专家团队在手动估算区域的住房价格:一个团队持续收集最新的区
域信息,当他们不能得到房价中位数时,便使用复杂的规则来进行估
算。


这个过程既昂贵又耗时,而且估算结果还不令人满意,在某些情况
下,他们估计的房价和实际房价的偏差高达20%。这就是为什么该公司
认为给定该区域的其他数据有助于训练模型来预测该区域的房价中位
数。普查数据看起来像是一个可用于此目的的很好的数据集,因为它包
括数千个区域的房价中位数和其他数据。
有了这些信息,你现在可以开始设计系统了。首先,你需要回答框
架问题:是有监督学习、无监督学习还是强化学习?是分类任务、回归
任务还是其他任务?应该使用批量学习还是在线学习技术?在继续阅读
之前,请先暂停一会儿,尝试回答一下这些问题。
找到答案了吗?我们来看看:显然,这是一个典型的有监督学习任
务,因为已经给出了标记的训练示例(每个实例都有预期的产出,也就
是该区域的房价中位数)。并且这也是一个典型的回归任务,因为你要
对某个值进行预测。更具体地说,这是一个多重回归问题,因为系统要
使用多个特征进行预测(使用区域的人口、收入中位数等)。这也是一
元回归问题,因为我们仅尝试预测每个区域的单个值。如果我们试图预
测每个区域的多个值,那将是多元回归问题。最后,我们没有一个连续
的数据流不断流进系统,所以不需要针对变化的数据做出特别调整,数
据量也不是很大,不需要多个内存,所以简单的批量学习应该就能胜
任。
如果数据庞大,则可以跨多个服务器拆分批处理学习(使用
MapReduce技术)或使用在线学习技术。
2.2.2 选择性能指标
下一步是选择性能指标。回归问题的典型性能指标是均方根误差
(RMSE)。它给出了系统通常会在预测中产生多大误差,对于较大的误
差,权重较高。公式2-1给出了计算RMSE的数学公式。


公式2-1:均方根误差(RMSE)
符号表示
这个公式引入了我们在本书中将使用的几种常见的机器学习符号:
·m是要在其上测量RMSE的数据集中的实例数。
·例如,如果你要在2000个区域的验证集上评估RMSE,则m=2000。
·x(i)是数据集中第i个实例的所有特征值(不包括标签)的向
量,而y(i)是其标签(该实例的期望输出值)。
·例如,如果数据集中的第一个区域位于经度-118.29°,纬度
33.91°,居民1416人,收入中位数为38 372美元,房屋价值中位数为
156 400美元(忽略其他特征),那么
和


·X是一个矩阵,其中包含数据集中所有实例的所有特征值(不包
括标签)。每个实例只有一行,第i行等于x(i)的转置,记为
(x(i))T[2]。
·例如,如果第一个区域如上所述,则矩阵X如下所示:
·h是系统的预测函数,也称为假设。当给系统输入一个实例的特
征向量x(i)时,它会为该实例输出一个预测值 ( 读为
“y-帽”)。
·例如,如果系统预测第一个区域的房价中位数为158 400美元,
则 158 400。该区域的预测误差为 。
·RMSE(X,h)是使用假设h在一组示例中测量的成本函数。
我们将小写斜体字体用于标量值(例如m或y(i))和函数名称(例
如h),将小写粗斜体字体用于向量(例如x(i)),将大写粗斜体字体
用于矩阵(例如X)。


尽管RMSE通常是回归任务的首选性能指标,但在某些情况下,你可
能更喜欢使用其他函数。例如,假设有许多异常区域。在这种情况下,
你可以考虑使用平均绝对误差(Mean Absolute Error,MAE,也称为平
均绝对偏差。参见公式2-2):
公式2-2:平均绝对误差(MAE)
RMSE和MAE都是测量两个向量(预测值向量和目标值向量)之间距
离的方法。各种距离度量或范数是可能的:
·计算平方和的根(RMSE)与欧几里得范数相对应:这是你熟悉的
距离的概念,它也称为 2范数,记为||·||2(或仅记为||·||)。
·计算绝对值之和(MAE)对应于 1范数,记为||·||1。有时将其
称为“曼哈顿范数”,因为如果你只能沿着正交的城市街区行动,它测
量城市中两点之间的距离。
·一般而言,包含n个元素的向量v的 k范数定义为
。 0给出了向量中的非零元素数量,
∞给出向量中的最大绝对值。
·范数指标越高,它越关注大值而忽略小值。这就是RMSE对异常值
比MAE更敏感的原因。但是,当离群值呈指数形式稀有时(如钟形曲
线),RMSE表现非常好,通常是首选。
2.2.3 检查假设


最后,列举和验证到目前为止(由你或者其他人)做出的假设,是
一个非常好的习惯。这可以在初期检查出严重问题。例如,当机器学习
系统输出区域价格给下游系统时,我们的假设是价格会被使用。但是,
如果下游系统实际上是将价格转换成为类别(例如,廉价、中等或者昂
贵),转而使用这些类别,而不是价格本身呢?在这种情形下,并不需
要完全准确地预估价格,你的系统只需要得出正确的类别就够了。如果
是这种情况,那么这个问题应该被设定为分类任务而不是回归任务。你
肯定不会愿意在回归系统上努力了几个月之后才发现这一点。
幸运的是,跟下游系统的团队聊过之后,证实需要的确实是价格而
不是类别。很好!一切就绪,绿灯亮了,现在可以开始编程了!
[1] 参考Claude Shannon的信息论,他将这种信息(信号)馈送到机器
学习系统中,该信息论是他在贝尔实验室开发的,用于提高通讯质量。
他的理论:你想要一个高信噪比。
[2] 回忆一下,转置运算符将列向量翻转为行向量(反之亦然)。


2.3 获取数据
现在是着手动工的时候了。不要犹豫,打开你的笔记本电脑,先过
一遍Jupyter notebook里的代码示例。完整的Jupyter notebook可以通
过https://github.com/ageron/handson-ml2获得。
2.3.1 创建工作区
首先,你需要安装Python。你可能早已经装好,如果还没有,那么
可以在https://www.python.org/上获取[1]。接下来,你需要为机器学
习的代码和数据集创建一个工作区目录。打开一个终端并输入以下命令
行(在$提示符之后):
$ export ML_PATH="$HOME/ml" # You can change the path if you prefer $ mkdir -p $ML_PATH
此外,你还需要一些Python模块:Jupyter、NumPy、pandas、
Matplotlib以及ScikitLearn。如果已经安装好所有这些模块,并运行
了Jupyter,那么可以跳到2.3.2节。如果还没有完全安装所有模块(以
及它们的依赖项),以下有多种办法进行安装。可以使用系统的包管理
器进行安装(例如,Ubuntu的apt-get,或者MacOS上的MacPorts和
Homebrew等),安装一个Scientific Python的发行版(例如
Anaconda),然后使用其包管理器,又或者直接使用Python自己的包管
理器pip,默认情况下,(自2.7.9版本之后)Python的二进制安装程序
里应该都包含pip[2]。你可以输入以下命令行查看是否安装了pip:
$ python3 -m pip --version pip 19.3.1 from [...]/lib/python3.7/site-packages/pip (python 3.7)


请确保安装的pip版本是最新的,要升级pip模块,请输入(实际版
本可能有所不同)[3]:
$ python3 -m pip install --user -U pip2 Collecting pip [...] Successfully installed pip-19.3.13
创建一个隔离环境
如果你希望在一个隔离的环境里工作(强烈推荐,这样你可以在库
版本不冲突的情况下处理不同的项目),可以通过运行以下pip命令来
安装virtualenv[4](如果你想在你的机器上为所有用户安装
virtualenv,去掉--user并用管理员权限运行命令):
$ python3 -m pip install --user -U virtualenv Collecting virtualenv [...] Successfully installed virtualenv-16.7.6
输入以下命令创建一个隔离的Python环境:
$ cd $ML_PATH $ python3 -m virtualenv my_env Using base prefix '[...]' New python executable in [...]/ml/my_env/bin/python3 Also creating executable in [...]/ml/my_env/bin/python Installing setuptools, pip, wheel...done.
现在开始,每当想要激活这个环境时,只需要打开终端并输入:


$ cd $ML_PATH $ source my_env/bin/activate # on Linux or macOS $ .\my_env\Scripts\activate # on Windows
要停用这个环境,用deactivate命令。当这个环境处于激活状态
时,使用pip安装的任何软件包都将被安装在这个隔离的环境中,
Python只拥有这些包的访问权限(如果你还希望访问系统站点的软件
包,则需要使用virtualenv的--system-sitepackages命令选项)。更
多详情可以参考virtualenv的文档。
现在可以使用简单的pip命令安装必需的模块及其依赖项了(如果
没有使用virtualenv,你将需要--user选项或管理员权限):
$ python3 -m pip install -U jupyter matplotlib numpy pandas scipy scikit-learn Collecting jupyter Downloading https://[...]/jupyter-1.0.0-py2.py3-none-any.whl Collecting matplotlib [...]
如果你创建了virtualenv,则需要注册到Jupyter并给它一个名
字:
$ python3 -m ipykernel install --user --name=python3
现在可以输入以下命令来启动Jupyter:
$ jupyter notebook [...] Serving notebooks from local directory: [...]/ml [...] The Jupyter Notebook is running at: [...] http://localhost:8888/?token=60995e108e44ac8d8865a[...] [...] or http://127.0.0.1:8889/?token=60995e108e44ac8d8865a[...] [...] Use Control-C to stop this server and shut down all kernels [...]


一个Jupyter服务器正在你的终端中运行,监听端口为8888。你可
以打开浏览器,输入http://localhost:8888/访问该服务器(通常服务
器启动时会自动运行),可以看到一个空的工作区目录(如果你遵循了
上述virtualenv指令,这时仅包含env目录)。
单击New按钮,选择适当的Python版本,创建一个Python
notebook(见图2-3)[5]。它会在你的工作区中创建一个名为
Untitled.ipynb的新notebook文件,然后启动Jupyter Python内核来运
行这个文件,最后在浏览器新标签里打开这个笔记本。先单击Untitled
并键入新名称将这个笔记本重命名为“Housing”(文件将自动被重命
名为Housing.ipynb)。
一个notebook内包含一个单元格列表,每个单元格可以是可执行代
码或格式化的文本。现在,这个notebook只有一个空的代码单元,标记
为“In[1]:”。在单元格中输入print("Hello world!"),然后单击
执行按钮(参见图2-4)或按组合键“Shift+Enter”。这时,当前单元
格会被送到这个notebook的Python内核,运行并返回输出结果。结果显
示在单元格下方,同时因为我们到了notebook的末尾,所以还会自动创
建一个新的单元格。更多的基础知识可以从Jupyter的Help菜单“User
Interface Tour”中了解。


图2-3:你的Jupyter工作间
图2-4:Hello world Python notebook
2.3.2 下载数据
在典型环境中,数据存储在关系型数据库里(或其他一些常用数据
存储),并分布在多个表/文档/文件中。访问前,你需要先获得证书和
访问权限[6],并熟悉数据库模式。不过在这个项目中,事情要简单得
多:你只需要下载一个压缩文件housing.tgz即可,这个文件已经包含
所有的数据——一个以逗号来分隔值的CSV文档housing.csv。
你可以选择使用浏览器下载压缩包,运行tar xzf housing.tgz来
解压缩并提取CSV文件,但更好的选择是创建一个小函数来实现它。尤
其是当数据会定期发生变化时,这个函数非常有用:你可以编写一个小
脚本,在需要获取最新数据时直接运行(或者也可以设置一个定期自动
运行的计划任务)。如果需要在多台机器上安装数据集,这个自动获取
数据的函数也非常好用。
获取数据[7]的函数如下所示:
import os import tarfile import urllib


DOWNLOAD_ROOT = "https://raw.githubusercontent.com/ageron/handson-ml2/master/" HOUSING_PATH = os.path.join("datasets", "housing") HOUSING_URL = DOWNLOAD_ROOT + "datasets/housing/housing.tgz"
def fetch_housing_data(housing_url=HOUSING_URL, housing_path=HOUSING_PATH): os.makedirs(housing_path, exist_ok=True) tgz_path = os.path.join(housing_path, "housing.tgz") urllib.request.urlretrieve(housing_url, tgz_path) housing_tgz = tarfile.open(tgz_path) housing_tgz.extractall(path=housing_path) housing_tgz.close()
现在,每当你调用fetch_housing_data(),就会自动在工作区中
创建一个datasets/housing目录,然后下载housing.tgz文件,并将
housing.csv解压到这个目录。
现在我们来使用pandas加载数据。你也应该写一个小函数来加载数
据:
import pandas as pd
def load_housing_data(housing_path=HOUSING_PATH): csv_path = os.path.join(housing_path, "housing.csv") return pd.read_csv(csv_path)
这个函数会返回一个包含所有数据的pandas DataFrame对象。
2.3.3 快速查看数据结构
我们来看看使用DataFrames的head()方法之后的前5行是怎样的
(见图2-5)。


图2-5:数据集中的前5行
每一行代表一个区域,总共有10个属性(在图2-5中可以看到前6
个):longitude、latitude、housing_median_age、total_rooms、
total_bedrooms、population、households、median_income、
median_house_value以及ocean_proximity。
通过info()方法可以快速获取数据集的简单描述,特别是总行
数、每个属性的类型和非空值的数量(见图2-6)。
图2-6:住房信息
数据集中包含20 640个实例,以机器学习的标准来看,这个数字非
常小,但却是个完美的开始。注意,total_bedrooms这个属性只有20


433个非空值,这意味着有207个区域缺失这个特征。我们后面需要考虑
到这一点。
所有属性的字段都是数字,除了ocean_proximity。它的类型是
object,因此它可以是任何类型的Python对象,不过因为你从CSV文件
中加载了该数据,所以它必然是文本属性。通过查看前5行,你可能会
注意到,该列中的值是重复的,这意味着它有可能是一个分类属性。你
可以使用value_counts()方法查看有多少种分类存在,每种类别下分
别有多少个区域:
>>> housing["ocean_proximity"].value_counts() <1H OCEAN 9136 INLAND 6551 NEAR OCEAN 2658 NEAR BAY 2290 ISLAND 5 Name: ocean_proximity, dtype: int64
再来看看其他区域,通过describe()方法可以显示数值属性的摘
要(见图2-7)。
count、mean、min以及max行的意思很清楚。需要注意的是,这里
的空值会被忽略(因此本例中,total_bedrooms的count是20 433而不
是20 640)。std行显示的是标准差(用来测量数值的离散程度)[8]。
25%、50%和75%行显示相应的百分位数:百分位数表示一组观测值中给
定百分比的观测值都低于该值。例如,对于housing_median_age的值,
25%的区域小于18,50%的区域小于29,以及75%的区域小于37。这些通
常分别称为第25百分位数(或者第一四分位数)、中位数以及第75百分
位数(或者第三四分位数)。


图2-7:每个数值属性的摘要
另一种快速了解数据类型的方法是绘制每个数值属性的直方图。直
方图用来显示给定值范围(横轴)的实例数量(纵轴)。你可以一次绘
制一个属性,也可以在整个数据集上调用hist()方法(如以下代码示
例所示),绘制每个属性的直方图(见图2-8)。
%matplotlib inline # only in a Jupyter notebook import matplotlib.pyplot as plt housing.hist(bins=50, figsize=(20,15)) plt.show()
hist()方法依赖于Matplotlib,而Matplotlib又依赖于用户
指定的图形后端才能在屏幕上完成绘制。所以在绘制之前,你需要先指
定Matplotlib使用哪个后端。最简单的选择是使用Jupyter的神奇命
令%matplotlib inline。它会设置Matplotlib从而使用Jupyter自己的
后端,随后图形会在notebook上呈现。需要注意的是,因为Jupyter在
执行每个单元格时会自动显示图形,所以在Jupyter notebook中调用
show()是可选的。


图2-8:每个数值属性的直方图
回到直方图,请注意以下几点:
1.首先,收入中位数这个属性看起来不像是用美元(USD)在衡
量。经与收集数据的团队核实,你得知数据已经按比例缩小,并框出中
位数的上限为15(实际为15.0001),下限为0.5(实际为0.4999)。数
字后的单位为万美元,例如,15代表15万美元。在机器学习中,使用经
过预处理的属性是很常见的事情,倒不一定是个问题,但是你至少需要
了解数据是如何计算的。
2.房龄中位数和房价中位数也被设定了上限。而由于后者正是你的
目标属性(标签),因此这可能是个大问题。你的机器学习算法很可能
会学习到价格永远不会超过这个限制。你需要再次与客户团队(使用你
的系统输出的团队)进行核实,查看是否存在问题。如果他们告诉你,


他们需要精确的预测值,甚至可以超过50万美元,那么,通常你有两个
选择:
a.对那些标签值被设置了上限的区域,重新收集标签值。
b.将这些区域的数据从训练集中移除(包括从测试集中移除,因为
如果预测值超过50万美元,系统不应被评估为不良)。
3.这些属性值被缩放的程度各不相同。这将在本章稍后探讨特征缩
放时再做讨论。
4.最后,许多直方图都表现出重尾:图形在中位数右侧的延伸比左
侧要远得多。这可能会导致某些机器学习算法难以检测模式。稍后我们
会尝试一些转化方法,将这些属性转化为更偏向钟形的分布。
相信现在你对正在处理的数据应该有了更好的理解。
等等!在进一步查看数据之前,你需要先创建一个测试集,
然后即可将其放置一旁,不用过多理会。
2.3.4 创建测试集
在这个阶段主动搁置部分数据听起来可能有些奇怪。毕竟,你才只
简单浏览了一下数据而已,在决定用什么算法之前,当然还需要了解更
多的知识,对吧?没错,但是大脑是个非常神奇的模式检测系统,也就
是说,它很容易过拟合:如果是你本人来浏览测试集数据,很可能会跌
入某个看似有趣的测试数据模式,进而选择某个特殊的机器学习模型。
然后当你再使用测试集对泛化误差率进行估算时,估计结果将会过于乐
观,该系统启动后的表现将不如预期那般优秀。这称为数据窥探偏误
(data snooping bias)。


理论上,创建测试集非常简单,只需要随机选择一些实例,通常是
数据集的20%(如果数据集很大,比例将更小),然后将它们放在一
边:
import numpy as np
def split_train_test(data, test_ratio): shuffled_indices = np.random.permutation(len(data)) test_set_size = int(len(data) * test_ratio) test_indices = shuffled_indices[:test_set_size] train_indices = shuffled_indices[test_set_size:] return data.iloc[train_indices], data.iloc[test_indices]
你可以这样使用如下函数[9]:
>>> train_set, test_set = split_train_test(housing, 0.2) >>> len(train_set) 16512 >>> len(test_set) 4128
是的,这确实能行,但这并不完美。如果再运行一遍,它又会产生
一个不同的数据集!这样下去,你(或者你的机器学习算法)将会看到
整个完整的数据集,而这正是创建测试集时需要避免的。
解决方案之一是在第一次运行程序后即保存测试集,随后的运行只
是加载它而已。另一种方法是在调用np.random.permutation()之前
设置一个随机数生成器的种子(例如,np.random.seed(42))[10],
从而让它始终生成相同的随机索引。
但是,这两种解决方案在下一次获取更新的数据时都会中断。为了
即使在更新数据集之后也有一个稳定的训练测试分割,常见的解决方案
是每个实例都使用一个标识符来决定是否进入测试集(假定每个实例都
有一个唯一且不变的标识符)。例如,你可以计算每个实例标识符的哈


希值,如果这个哈希值小于或等于最大哈希值的20%,则将该实例放入
测试集。这样可以确保测试集在多个运行里都是一致的,即便更新数据
集也仍然一致。新实例的20%将被放入新的测试集,而之前训练集中的
实例也不会被放入新测试集。
实现方式如下:
from zlib import crc32
def test_set_check(identifier, test_ratio): return crc32(np.int64(identifier)) & 0xffffffff < test_ratio * 2**32
def split_train_test_by_id(data, test_ratio, id_column): ids = data[id_column] in_test_set = ids.apply(lambda id_: test_set_check(id_, test_ratio)) return data.loc[~in_test_set], data.loc[in_test_set]
不幸的是,housing数据集没有标识符列。最简单的解决方法是使
用行索引作为ID:
housing_with_id = housing.reset_index() # adds an `index` column train_set, test_set = split_train_test_by_id(housing_with_id, 0.2, "index")
如果使用行索引作为唯一标识符,你需要确保在数据集的末尾添加
新数据,并且不会删除任何行。如果不能保证这一点,那么你可以尝试
使用某个最稳定的特征来创建唯一标识符。例如,一个区域的经纬度肯
定几百万年都不会变,你可以将它们组合成如下的ID[11]
housing_with_id["id"] = housing["longitude"] * 1000 + housing["latitude"] train_set, test_set = split_train_test_by_id(housing_with_id, 0.2, "id")


Scikit-Learn提供了一些函数,可以通过多种方式将数据集分成多
个子集。最简单的函数是train_test_split(),它与前面定义的函数
split_train_test()几乎相同,除了几个额外特征。首先,它也有
random_state参数,让你可以像之前提到过的那样设置随机生成器种
子;其次,你可以把行数相同的多个数据集一次性发送给它,它会根据
相同的索引将其拆分(例如,当你有一个单独的DataFrame用于标记
时,这就非常有用):
from sklearn.model_selection import train_test_split
train_set, test_set = train_test_split(housing, test_size=0.2, random_state=42)
到目前为止,我们思考过了纯随机的抽样方法。如果数据集足够庞
大(特别是相较于属性的数量而言),这种方式通常不错;如果不是,
则有可能会导致明显的抽样偏差。如果一家调查公司想要打电话给1000
个人来调研几个问题,他们不会在电话簿中纯随机挑选1000个人。他们
试图确保让这1000人能够代表全体人口。例如,美国人口组成为51.3%
的女性和48.7%的男性,所以,要想在美国进行一场有效的调查,样本
中应该试图维持这一比例,即513名女性和487名男性。这就是分层抽
样:将人口划分为均匀的子集,每个子集称为一层,然后从每层抽取正
确的实例数量,以确保测试集合代表了总的人口比例。如果使用纯随机
的抽样方法,将有12%的可能得到抽样偏斜的测试集——要么女性比例
不到49%,要么女性比例超过54%。不论出现哪种情况都会导致调查结果
出现显著偏差。
如果你咨询专家,他们会告诉你,要预测房价中位数,收入中位数
是一个非常重要的属性。于是你希望确保在收入属性上,测试集能够代
表整个数据集中各种不同类型的收入。由于收入中位数是一个连续的数
值属性,所以你得先创建一个收入类别的属性。我们先来看一下收入中
位数的直方图(见图2-8):大多数收入中位数值聚集在1.5~6(15
000~60 000美元)左右,但也有一部分远远超过了6万美元。在数据集


中,每一层都要有足够数量的实例,这一点至关重要,不然数据不足的
层,其重要程度很有可能会被错估。也就是说,你不应该将层数分得太
多,每一层应该要足够大才行。下面这段代码是用pd.cut()来创建5
个收入类别属性的(用1~5来做标签),0~1.5是类别1,1.5~3是类
别2,以此类推:
housing["income_cat"] = pd.cut(housing["median_income"], bins=[0., 1.5, 3.0, 4.5, 6., np.inf], labels=[1, 2, 3, 4, 5])
这些收入类别如图2-9所示。
housing["income_cat"].hist()
现在,你可以根据收入类别进行分层抽样了。使用Scikit-Learn的
StratifiedShuffleSplit类:
from sklearn.model_selection import StratifiedShuffleSplit split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42) for train_index, test_index in split.split(housing, housing["income_cat"]): strat_train_set = housing.loc[train_index] strat_test_set = housing.loc[test_index]


图2-9:收入类别的直方图
看看这个运行是否如我们所料。首先,可以看看测试集中收入类别
比例分布:
>>> strat_test_set["income_cat"].value_counts() / len(strat_test_set) 3 0.350533 2 0.318798 4 0.176357 5 0.114583 1 0.039729 Name: income_cat, dtype: float64
使用类似代码你还可以测量测试集中的收入类别比例分布。图2-10
比较了在三种不同的数据集(完整数据集、分层抽样的测试集、纯随机
抽样的测试集)中收入类别比例分布。正如你所见,分层抽样的测试集
中的比例分布与完整数据集中的分布几乎一致,而纯随机抽样的测试集
结果则是有偏的。