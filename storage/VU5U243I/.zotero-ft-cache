凤凰架构:构建可靠的大型分布式系统
周志明 著
ISBN:978-7-111-68391-9
本书纸版由机械工业出版社于2021年出版,电子版由华章分社(北京 华章图文信息有限公司,北京奥维博世图书发行有限公司)全球范围 内制作与发行。
版权所有,侵权必究
客服热线:+ 86-10-68995265
客服信箱:service@bbbvip.com
官方网址:www.hzmedia.com.cn
新浪微博 @华章数媒
微信公众号 华章电子书(微信号:hzebook)


目录
赞誉 自序 前言 第一部分 演进中的架构 第1章 服务架构演进史 1.1 原始分布式时代 1.2 单体系统时代 1.3 SOA时代 1.4 微服务时代 1.5 后微服务时代 1.6 无服务时代 第二部分 架构师的视角 第2章 访问远程服务 2.1 远程服务调用 2.1.1 进程间通信 2.1.2 通信的成本 2.1.3 三个基本问题 2.1.4 统一的RPC 2.1.5 分裂的RPC 2.2 REST设计风格 2.2.1 理解REST 2.2.2 RESTful的系统 2.2.3 RMM 2.2.4 不足与争议 第3章 事务处理 3.1 本地事务 3.1.1 实现原子性和持久性 3.1.2 实现隔离性 3.2 全局事务 3.3 共享事务 3.4 分布式事务 3.4.1 CAP与ACID 3.4.2 可靠事件队列 3.4.3 TCC事务 3.4.4 SAGA事务


第4章 透明多级分流系统 4.1 客户端缓存 4.1.1 强制缓存 4.1.2 协商缓存 4.2 域名解析 4.3 传输链路 4.3.1 连接数优化 4.3.2 传输压缩 4.3.3 快速UDP网络连接 4.4 内容分发网络 4.4.1 路由解析 4.4.2 内容分发 4.4.3 CDN应用 4.5 负载均衡 4.5.1 数据链路层负载均衡 4.5.2 网络层负载均衡 4.5.3 应用层负载均衡 4.5.4 均衡策略与实现 4.6 服务端缓存 4.6.1 缓存属性 4.6.2 缓存风险 第5章 架构安全性 5.1 认证 5.1.1 认证的标准 5.1.2 认证的实现 5.2 授权 5.2.1 RBAC 5.2.2 OAuth 2 5.3 凭证 5.3.1 Cookie-Session 5.3.2 JWT 5.4 保密 5.4.1 保密的强度 5.4.2 客户端加密 5.4.3 密码存储和验证 5.5 传输 5.5.1 摘要、加密与签名


5.5.2 数字证书 5.5.3 传输安全层 5.6 验证 第三部分 分布式的基石 第6章 分布式共识 6.1 Paxos 6.1.1 Paxos的诞生 6.1.2 算法流程 6.1.3 工作实例 6.2 Multi Paxos 6.3 Gossip协议 第7章 从类库到服务 7.1 服务发现 7.1.1 服务发现的意义 7.1.2 可用与可靠 7.1.3 注册中心实现 7.2 网关路由 7.2.1 网关的职责 7.2.2 网络I/O模型 7.2.3 BFF网关 7.3 客户端负载均衡 7.3.1 客户端负载均衡器 7.3.2 代理负载均衡器 7.3.3 地域与区域 第8章 流量治理 8.1 服务容错 8.1.1 容错策略 8.1.2 容错设计模式 8.2 流量控制 8.2.1 流量统计指标 8.2.2 限流设计模式 8.2.3 分布式限流 第9章 可靠通信 9.1 零信任网络 9.1.1 零信任安全模型的特征 9.1.2 Google的实践探索 9.2 服务安全


9.2.1 建立信任 9.2.2 认证 9.2.3 授权 第10章 可观测性 10.1 事件日志 10.1.1 输出 10.1.2 收集与缓冲 10.1.3 加工与聚合 10.1.4 存储与查询 10.2 链路追踪 10.2.1 追踪与跨度 10.2.2 数据收集 10.2.3 追踪规范化 10.3 聚合度量 10.3.1 指标收集 10.3.2 存储查询 10.3.3 监控预警 第四部分 不可变基础设施 第11章 虚拟化容器 11.1 容器的崛起 11.1.1 隔离文件:chroot 11.1.2 隔离访问:名称空间 11.1.3 隔离资源:cgroups 11.1.4 封装系统:LXC 11.1.5 封装应用:Docker 11.1.6 封装集群:Kubernetes 11.2 以容器构建系统 11.2.1 隔离与协作 11.2.2 韧性与弹性 11.3 以应用为中心的封装 11.3.1 Kustomize 11.3.2 Helm与Chart 11.3.3 Operator与CRD 11.3.4 开放应用模型 第12章 容器间网络 12.1 Linux网络虚拟化 12.1.1 网络通信模型


12.1.2 干预网络通信 12.1.3 虚拟化网络设备 12.1.4 容器间通信 12.2 容器网络与生态 12.2.1 CNM与CNI 12.2.2 CNM到CNI 12.2.3 网络插件生态 第13章 持久化存储 13.1 Kubernetes存储设计 13.1.1 Mount和Volume 13.1.2 静态存储分配 13.1.3 动态存储分配 13.2 容器存储与生态 13.2.1 Kubernetes存储架构 13.2.2 FlexVolume与CSI 13.2.3 从In-Tree到Out-of-Tree 13.2.4 容器插件生态 第14章 资源与调度 14.1 资源模型 14.2 服务质量与优先级 14.3 驱逐机制 14.4 默认调度器 第15章 服务网格 15.1 透明通信的涅槃 15.1.1 通信成本 15.1.2 数据平面 15.1.3 控制平面 15.2 服务网格与生态 15.2.1 服务网格接口 15.2.2 通用数据平面API 15.2.3 服务网格生态 第五部分 技术方法论 第16章 向微服务迈进 16.1 目的:微服务的驱动力 16.2 前提:微服务需要的条件 16.3 边界:微服务的粒度 16.4 治理:理解系统复杂性


16.4.1 静态的治理 16.4.2 发展的治理 附录A 技术演示工程实践 附录B 部署Kubernetes集群


赞誉
一本好的技术书不仅能告诉你某个技术点怎么做、为什么这么 做,还会让你明白所有技术点如何协同配合,最终构建出一个完整的 技术体系。本书很好地兼顾了技术细节和宏观体系两方面,从分布式 服务的基础功能到高级治理能力,结合作者的思考,层层推进、娓娓 道来,引人深思。相信深入钻研此书的读者必定能在架构能力方面得 到如凤凰涅槃般的升华。
——李鑫 天弘基金线上渠道技术负责人/《微服务治理:体系、架构
及实践》作者
从大型机到单体架构,从微服务架构到无服务架构,每一次架构 模式的演进都是一次涅槃。每一个软件系统都是由大量服务构成的生 态体系,个体服务的“死亡”和“重生”是整个系统能否持续可靠运 行的关键因素。本书从5个方面全面剖析了如何构建一个可靠的分布式 系统,同时给出了Spring Boot、Spring Cloud、Kubernetes、 Istio、AWS Lambda五种架构风格的样例工程。推荐阅读。
——刘志勇 新浪微博平台研发部架构师
随着IT系统复杂度不断增加,无论是为了降低团队的知识负载, 还是为了最大化利用云原生的弹性能力,分布式架构已经成为处理新 一代复杂系统的默认架构模式。但它的引入也同样大幅提高了架构的 复杂性,导致系统可靠性降低。如何构建既可靠又灵活的大型分布式 架构,成为新的难点与课题。本书系统、全面且深入浅出地讲解了分 布式架构的方方面面,对大家了解并驾驭大型分布式架构非常有帮 助,强烈推荐。
——王健 ThoughtWorks首席咨询师
用“凤凰”这个词来诠释分布式架构,让人不禁联想到每一种架 构都是一只浴火重生的凤凰,仔细想来,确实如此。从小型系统迭代 到大型系统,从单体走向分布式,每一个成功的系统都会经历一次次 “涅槃重生”,从失败中站起来,从故障里爬出来,从经验中成长起 来。本书从“架构演进”出发,以“架构师视角”展开,详细讲述了


分布式架构的原理、基础设施、设计理念等,是一本很好的可以让架 构“浴火重生”的经验宝典。
——王晓波 同程旅行机票事业群CTO


自序
流水不腐,户枢不蠹
“Phoenix”(凤凰)这个词在东方的技术书中不常用,但在西方 的软件工程读物中,尤其是在关于敏捷、DevOps话题的作品中时常出 现。软件工程小说《凤凰项目》(见图1)讲述了徘徊在死亡边缘的凤 凰项目在精益方法下浴火重生的故事;Martin Fowler在诠释“持续交 付”时,曾多次提到“Phoenix Server”(凤凰服务器,取其能够 “涅槃重生”之意)与“Snowflake Server”(雪花服务器,取其 “世界上没有相同的两片雪花”之意)的优劣比对。也许是东西方文 化的差异,尽管有“失败是成功之母”这样的谚语,但我们东方人的 骨子里更注重的还是一次把事做对、做好,尽量别出乱子;而西方人 则要“更看得开”一些,把出错看作正常甚至是必需的发展过程,只 要出了问题能够兜底使其重回正轨便好。


图1 《凤凰项目》
在软件工程里,任何产品的研发,如果持续时间很长,人总免不 了疏忽、犯错,导致代码存在缺陷,电脑宕机崩溃,网络堵塞中 断......如果一项工程需要大量的人员共同研发某个大规模的软件产 品,并使其分布在网络中的大量的服务器节点中同时运行,随着项目 规模增大、运作时间变长,其必然会受到墨菲定律的无情打击。
为了得到高质量的软件产品,我们是应该把精力更多地集中在提 升其中每一个人员、过程、产出物的能力和质量上?还是应该把更多 精力放在整体流程和架构上?
笔者对这个问题先给一个“和稀泥”式的回答:这两者都重要。 前者重术,后者重道;前者更多与编码能力相关,后者更多与软件架 构相关;前者主要由开发者个体的水平决定,后者主要由技术决策者 的水平决定。
然而,笔者也必须强调此问题的另外一面:这两者的理解路径和 抽象程度是不一样的。如何学习一项具体的语言、框架、工具,譬如 Java、Spring、Vue.js等,是相对具象的,不论其蕴含的内容多少, 复杂程度高低,它至少是能看得见、摸得着的。而如何学习某一种风 格的架构方法,譬如单体、微服务、服务网格、无服务、云原生等, 则是相对抽象的,谈论它们可能要面临“一千个人眼中有一千个哈姆 雷特”的困境。谈这方面的话题,若要言之有物,就不能是单纯的经 验陈述。回到这些架构根本的出发点和问题上,笔者认为,真正去使 用这些不同风格的架构方法来实现某些需求,解决某些问题,然后在 实践中观察它们的异同优劣,会是一种很好的也许是最好的讲述方 式。笔者想说一下这些架构,而且想说得透彻明白,就需要代码与文 字的配合,于是便有了这本书,以及与它配套的实践项目。
可靠的系统
让我们再来思考一个问题,构建一个大规模但依然可靠的软件系 统,是否可行?
这个问题听起来的第一感觉也许会有点荒谬。如果这个事情从理 论上来说就是根本不可能的,那我们这些软件开发人员在瞎忙活些什 么?但你再仔细想想,前面才提到的“墨菲定律”和在“大规模”这


个前提下必然会遇到各种“不靠谱”的人员、代码、硬件、网络等因 素,从中能得出一个听起来颇为合理的推论:如果一项工作要经过多 个“不靠谱”的过程相互协作完成,其中的误差应会不断累积叠加, 导致最终结果必然不能收敛稳定。
这个问题也并非杞人忧天、庸人自扰式的瞎操心,计算机之父冯 ·诺依曼在20世纪40年代末期,曾经花费大约两年时间,研究这个问 题并且得出了一个理论——自复制自动机(Self-Reproducing Automata)(见图2)。这个理论以机器应该如何从基本的部件中构造 出与自身相同的另一台机器引出,其目的并不是想单纯地模拟或者理 解生物体的自我复制,也并不是想简单地制造自我复制的计算机,而 是想回答一个理论问题:如何用一些“不可靠”部件构造出一个可靠 的系统。
图2 当时自复制自动机的艺术表示(图片来自维基百科)
自复制自动机恰好就是一个最好的用“不可靠”部件构造可靠系 统的例子。这里,“不可靠”部件可以理解为构成生命的大量细胞, 甚至是分子。由于热力学扰动、生物复制差错等因素干扰,这些分子 本身并不可靠。但是生命系统之所以可靠,恰是因为它可以使用“不 可靠”部件来完成遗传迭代。这其中的关键点便是承认细胞等零部件 可能会出错,某个具体的零部件可能会崩溃消亡,但在存续生命的微


生态系统中其后代一定会出现,重新代替该零部件,实现它的作用, 以维持系统的整体稳定。在这个微生态里,每一个部件都可以看作一 只“不死鸟”(Phoenix),它会老迈,又能涅槃重生。
架构的演进
从大型机(Mainframe)、原始分布式(Distributed)、大型单 体(Monolithic)、面向服务(Service-Oriented)、微服务 (Microservice)、服务网格(Service Mesh)到无服务 (Serverless)等,技术架构确实呈现出“从大到小”的发展趋势。 近年来,自微服务兴起以后,涌现出各类文章去总结、赞美微服务带 来的种种好处,诸如简化部署、逻辑拆分更清晰、便于技术异构、易 于伸缩拓展以提供更高的性能等,这些当然都是重要优点和动力。可 是,如果不拘泥于特定系统或特定某个问题,以更宏观的角度来看, 前面所列的种种好处都只能算是“锦上添花”,是属于让系统“活得 更好”的动因,肯定比不上系统如何“确保生存”的需求更关键、更 贴近本质。在笔者看来,架构演变最重要的驱动力,或者说这种“从 大到小”的变化趋势的最根本驱动力,始终都是为了方便某个服务能 够顺利地“死去”与“重生”。个体服务的生死更迭,是关系到整个 系统能否可靠存续的关键因素。
举个例子,某企业中应用的单体架构的Java系统,其更新、升级 都必须要有固定的停机计划,必须在特定的时间窗口内才能按时开 始,且必须按时结束。如果出现了非计划的宕机,那便是生产事故。 但是软件的缺陷不会遵循定下的停机计划来“安排时间出错”。为了 应对缺陷与变化,做到不停机地检修,Java曾经制定了OSGi和JVMTI Instrumentation等复杂的HotSwap方案,以实现“给奔跑中的汽车更 换轮胎”这种匪夷所思却又无可奈何的需求。而在微服务架构的视角 下,所谓系统检修,不过只是一次在线服务更新而已,先停掉1/3的机 器,升级新的软件版本,再有条不紊地导流、测试、做金丝雀发布, 一切都显得如此理所当然、平淡寻常。在无服务架构的视角下,我们 甚至都不需要关心服务所运行的基础设施,连机器是哪台都不必知 道,停机升级就更无须关注了。
流水不腐。有老朽,有消亡,有重生,有更迭,才是生态运行的 合理规律。设想一下,如果你的系统中的每个部件都符合“Phoenix” 的特性,哪怕其中某些部件采用了由“极不靠谱”的人员所开发的 “极不靠谱”的程序,哪怕存在严重的内存泄漏问题,哪怕最多只能


服务三分钟就会崩溃,只要在整体架构设计有恰当且自动化的错误熔 断、服务淘汰和重建机制,从系统外部来观察,架构仍然有可能表现 出稳定和健壮的服务能力。
凤凰架构
在企业软件开发的历史中,一项新技术发布时,常有伴以该技术 开发的“宠物店”(PetStore)作为演示的传统(如J2EE PetStore、.NET PetShop、Spring PetClinic等)。在对不同架构风 格的演示中,笔者本也希望能遵循此传统,却无奈从来没养过宠物, 遂改行开了书店(Fenix’s Bookstore),里面出售了几本笔者的著 作,算是夹带一点私货,同时也避免了使用素材时的版权隐患。
尽管相信没有人会误解,但笔者最后还是多强调一句,Oracle、 Microsoft、Pivotal等公司设计“宠物店”的目的绝不是为了日后能 在网上贩卖“宠物”,而是纯粹为了演示技术。所以也请勿以“实现 这种学生毕业设计复杂度的需求,引入如此规模的架构或框架,纯属 大炮打苍蝇,肯定是过度设计”的眼光来看待接下来的“Fenix’s Bookstore”项目。相反,如果可能的话,笔者会在有新的技术、框架 发布时,持续更新,以恰当的形式添加到项目的不同版本中,其技术 栈可能越来越复杂。笔者希望把这些新的、不断发展的知识,融入已 有的知识框架之中,便于自己学习、理解、思考,同时能将这些技术 连同自己的观点和看法分享给更多感兴趣的人。
也算是缘分,网名“IcyFenix”是二十多年前笔者从中学时代开 始使用的,它源自暴雪公司的即时战略游戏《星际争霸》的Protoss英 雄Fenix。如名字预示的那样,他曾经是Zealot,牺牲后以Dragoon的 形式重生,带领Protoss与刀锋女王Kerrigan继续抗争。尽管中学时期 我已经笃定自己未来肯定会从事信息技术相关的工作,但显然不可能 预计到二十年后我会写下这些文字。
所以,既然我们要开始一段关于“Phoenix”的代码与故事,那便 叫它“凤凰架构”,如何?


前言
本书是一本以“如何构建一套可靠的大型分布式系统”为叙述主 线的技术手册。笔者十多年来一直从事大型企业级软件的架构研发工 作,较完整地经历了从最早的大型单体系统到如今基于云原生基础设 施的架构演变过程,希望借此机会,系统性地整理相关知识,查漏补 缺,将它们都融入既有的知识框架之中,也希望能将这些知识与大家 分享讨论。笔者相信要深入理解一门技术,不仅要去看、去读、去 想、去用,更要去说、去写。将自己“认为掌握了的”知识叙述出 来,尽量将知识说得条理清晰,让他人听得明白,释去心中疑惑,同 时把自己的观点交予别人审视,乃至质疑,在此过程之中,自己也会 挖掘出很多潜藏在“已知”背后的“未知”。
如何阅读本书
本书一共分为演进中的架构、架构师的视角、分布式的基石、不 可变基础设施和技术方法论五部分,每一部分都有相对明确的主题与 目标,建议按顺序阅读各部分以获得更有逻辑性的阅读体验。不过每 部分内各章节之间并没有明显的前后依赖关系,读者从任何一个感兴 趣的章节开始阅读都可以。
笔者并没有假定本书的所有读者都在架构方面具备特别专业的技 术水平,因此在讲解各个知识点时,会力求在保证逻辑完整、描述准 确的前提下,尽量用通俗的语言和案例去讲述架构中与开发关系最为 密切的内容。但本书的主题毕竟是软件架构,这就不可避免地需要读 者有一定的技术基础。本书依然主要面向中、高级程序员群体,一些 常用的开发框架、类库和语法等基础知识点,均假设读者已有所了 解。书中虽然会涉及这些工具、类库、框架的使用案例,但本书并不 是它们的操作指南,只是借助它们去讲解技术原理。
学习任何知识都不应该脱离实践去空谈理论。为了讲清楚不同架 构风格下的工程实现差异,也为了尽量少在书中贴代码,将宝贵的版 面空间节省出来,笔者在GitHub上分别建立了基于Spring Boot、 Spring Cloud、Kubernetes、Istio和AWS Lambda的五种架构风格的样 例工程。如果你阅读之前对架构并没有太深刻的理解,建议先阅读一 遍本书附录A的内容。如果你是一名驾驶初学者,最合理的学习路径应


该是先把汽车发动,然后慢慢行驶起来,而不是先从“引擎动力原 理”“变速箱构造”入手去深刻地了解一辆汽车。计算机技术也是同 理,先从运行程序开始,看看效果,搭建好开发、调试环境,对即将 学习的内容先有一个整体的认知是很有好处的。
最后,笔者再简要介绍下本书每一部分的读者对象、目标和价 值。
第一部分 演进中的架构
这部分只有第1章,适合所有开发者,但尤其推荐刚刚从单体架构 向微服务架构转型的开发者阅读。
第一部分既是全书的绪论,也是对后续将用到的大量名词概念所 做的铺垫。这部分没有谈论过于具体的技术,只是着重介绍了软件开 发历史中多种主流架构出现的契机、解决的问题以及带来的新缺陷。
第二部分 架构师的视角
这部分包括第2~5章,适合所有技术架构师、系统设计与开发人 员,主要讨论与风格无关的架构知识。
“架构师”这个词的外延非常宽泛,不同语境中有不同含义。本 书中的技术架构师特指企业架构中面向技术模型的系统设计者,这意 味着讨论范围不会涉及贴近企业战略、业务流程的系统分析、信息战 略设计等内容,而是聚焦于贴近一线研发人员的技术方案设计者。这 部分将介绍一名架构师应该在架构设计时思考哪些问题,有哪些主流 的解决方案和行业标准做法,各种方案有什么优缺点,不同的解决方 法会带来什么不同的影响,等等,以达到将“架构设计”这种听起来 抽象的工作具体化、具象化的目的。
作为后续实践的基础,第二部分的内容与具体的架构风格无关, 讨论的是普适的架构技术与使用技巧。无论你是否关注微服务、云原 生这些概念,无论你从事架构设计还是编码开发,了解这里所列的基 础知识,都是有实用价值的。
第三部分 分布式的基石


这部分包括第6~10章,主要面向使用分布式架构的开发人员。
只要选择了分布式架构,无论是SOA、微服务、服务网格或者其他 架构风格,涉及与远程服务的交互时,服务的注册发现、跟踪治理、 负载均衡、故障隔离、认证授权、伸缩扩展、传输通信、事务处理等 一系列问题都是不可避免的。不同的架构风格,其区别是到底要在技 术规范上提供统一的解决方案,由应用系统自行解决,还是在基础设 施层面将这类问题隔离掉。第三部分将重点讨论这类问题的解决思 路、方法和常见工具。
第四部分 不可变基础设施
这部分包括第11~15章,主要面向基础设施的运维人员、技术平 台的开发人员。
“不可变基础设施”这个概念由来已久。2012年Martin Fowler设
想的“凤凰服务器[1]”与2013年Chad Fowler正式提出的“不可变基
础设施[2]”,都阐明了基础设施不变性带来的益处。在云原生基金会 (Cloud Native Computing Foundation,CNCF)所定义的“云原生” 概念中,“不可变基础设施”被提升到与微服务平级的重要程度,此 时它已不再局限于方便运维、程序升级和部署的手段,而是升华为向 应用代码隐藏分布式架构复杂度、让分布式架构得以成为一种可普遍 推广的普适架构风格的必要前提。在云原生时代、后微服务时代,软 件与硬件之间的界线已经彻底模糊,无论是基础设施的运维人员,抑 或是技术平台的开发人员,都有必要深入理解基础设施不变性的目 的、原理与实现途径。
第五部分 技术方法论
这部分包括第16章,主要面向企业中重要技术的决策者。
本书的主体内容是务实的,偏重具体技术,而非方向理论。但在 第16章会集中讨论几点与分布式、微服务、架构等相关的相对务虚的 话题。
笔者认为,对于一个技术人员,成长的主要驱动力是实践,是在 开发程序、解决问题中增长知识,再将知识归纳、总结、升华成为理 论,所以笔者将本章安排到全书的末尾,也是希望大家能先去实践,


再谈理论。同时,笔者也认为,对于一名研究人员或者企业中技术方 向的决策者,理论与实践都不可缺少,在涉及决策的场景中,成体系 的理论知识甚至比实践经验还要关键,因为执行力再强,也必须用在 正确的方向上才有价值。如果你对自己的规划是有朝一日从一名技术 人员发展成研究或者管理人员,补充这部分知识是必不可少的。
联系作者
在本书交稿的时候,笔者并没有想象中的那样兴奋或轻松,写作 之时那种“战战兢兢、如履薄冰”的感觉依然萦绕在心头。在每一 章、每一节落笔之时,笔者都在考虑如何才能把各个知识点更有条理 地讲述出来,都在担心会不会由于自己理解有偏差而误导了大家。囿 于写作水平和写作时间,书中难免存在不妥之处,后续的勘误会在本 书的网站(https://icyfenix.cn)上贴出,大家如有任何意见或建 议,都欢迎在此网站上留言。相信写书与写程序一样,作品一定都是 不完美的,因为不完美,我们才有不断追求完美的动力。
致谢
首先要感谢我的家人,是家人在本书写作期间对我的悉心照顾, 才让我能够全身心地投入写作之中,而无后顾之忧。
同时要感谢我的工作单位远光软件,公司为我提供了宝贵的工 作、学习和实践环境,书中的许多知识点都来自工作之中;也感谢与 我一起工作的同事们,非常荣幸能与你们一起在这个富有激情的团队 中共同奋斗。
最后,感谢机械工业出版社华章公司的编辑,本书能够顺利出 版,离不开他们的敬业精神和一丝不苟的工作态度。
周志明
[1] 参见https://martinfowler.com/bliki/PhoenixServer.html。
[2] 参见http://chadfowler.com/2013/06/23/immutable-deployments.html。


第一部分 演进中的架构
■第1章 服务架构演进史


第1章 服务架构演进史
架构并不是被发明出来的,而是持续演进的结果。本章我们暂且 放下代码与技术,借讨论历史之名,来梳理软件架构发展历程中出现 过的名词术语,以全局的视角,从这些概念的起源去分析它们是什 么,它们取代了什么,它们为什么能够在竞争中取得成功,为什么变 得不可或缺,以及它们为什么会失败,在斗争中被淘汰,逐渐湮灭于 历史的烟尘当中。


1.1 原始分布式时代
可能与绝大多数人的认知有些差异,“使用多个独立的分布式服 务共同构建一个更大型系统”的设想与实际尝试,其实要比今天大家 所了解的大型单体系统出现的时间更早。
在20世纪70年代末期到80年代初,计算机科学刚经历了从以大型 机为主向以微型机为主的蜕变,计算机逐渐从一种存在于研究机构、 实验室当中的科研设备,转变为存在于商业企业中的生产设备,甚至 是面向家庭、个人用户的娱乐设备。此时的微型计算机系统通常具有 16位寻址能力、不足5MHz时钟频率的处理器和128KB左右的内存地址空 间。譬如著名的英特尔处理器的鼻祖Intel 8086处理器,就是在1978 年研制成功,流行于80年代中期,甚至一直持续到90年代初期仍在生 产销售。
计算机硬件有限的运算处理能力,已直接影响到了单台计算机上 信息系统软件能够达到的最大规模。为突破硬件算力的限制,高校、 研究机构、软硬件厂商开始分头探索,寻找使用多台计算机共同协作 来支撑同一套软件系统的可行方案。这一阶段是对分布式架构最原始 的探索,从结果来看,历史局限决定了它不可能一蹴而就地解决分布 式的难题,但从过程来看,这个阶段的探索称得上成绩斐然,研究过 程中的很多成果都对今天计算机科学的诸多领域产生了深远影响,并 直接推动了后续软件架构的演化进程。譬如,惠普公司(及后来被惠 普收购的Apollo)提出的网络运算架构(Network Computing Architecture,NCA)是未来远程服务调用的雏形;卡内基·梅隆大学 提出的AFS(Andrew File System,Andrew文件系统)是日后分布式文 件系统的最早实现(Andrew意为纪念Andrew Carnegie和Andrew Mellon);麻省理工学院提出的Kerberos协议是服务认证和访问控制 的基础性协议,也是分布式服务安全性的重要支撑,目前仍被用于实 现包括Windows和Mac OS在内的众多操作系统的登录、认证功能等。
为了避免UNIX系统的版本战争[1]在分布式领域中重演,负责制定 UNIX系统技术标准的“开放软件基金会”(Open Software Foundation,OSF,也即后来的“国际开放标准组织”)邀请了当时业 界主流的计算机厂商一起参与,共同制订了名为“分布式运算环境
[2]”(Distributed Computing Environment,DCE)的分布式技术体


系。DCE包含一套相对完整的分布式服务组件规范与参考实现,譬如源 自NCA的远程服务调用规范(Remote Procedure Call,RPC),当时被 称为DCE/RPC,它与后来Sun公司向互联网工程任务组(Internet Engineering Task Force,IETF)提交的基于通用TCP/IP协议的远程 服务标准ONC RPC被认为是现代RPC的共同鼻祖;源自AFS的分布式文件 系统(Distributed File System,DFS)规范,当时被称为DCE/DFS; 源自Kerberos的服务认证规范;还有时间服务、命名与目录服务,甚 至现在程序中很常用的通用唯一识别符(Universally Unique Identifier,UUID)也是在DCE中发明出来的。
额外知识
UNIX的分布式设计哲学
保持接口与实现的简单性,比系统的任何其他属性,包括准确
性、一致性和完整性,都来得更加重要。
——Richard P.Gabriel,The Rise of Worse is Better,1991
由于OSF本身的UNIX背景,当时对这些技术的研究都带着浓厚的 UNIX设计风格,有一个预设的重要原则是要使分布式环境中的服务调 用、资源访问、数据存储等操作尽可能透明化、简单化,从而使开发 人员不必过于关注他们访问的方法或其他资源是位于本地还是远程。 这样的设计主旨非常符合UNIX一贯的设计哲学,然而这个过于理想化 的目标背后其实蕴含着彼时根本不可能完美解决的技术困难。关于 UNIX设计哲学,有几个不同的版本,这里指的是Common Lisp的作者 Richard P.Gabriel提出的简单优先原则,即“Worse is Better”。
尽管“调用远程方法”与“调用本地方法”只有两字之差,但若 要兼顾简单、透明、性能、正确、鲁棒、一致等特点,两者的复杂度 就完全不可同日而语了。且不说远程方法不能再依靠本地方法那些以 内联为代表的传统编译优化来提升速度,光是“远程”二字带来的网 络环境下的新问题,譬如,远程的服务在哪里(服务发现),有多少 个(负载均衡),网络出现分区、超时或者服务出错了怎么办(熔 断、隔离、降级),方法的参数与返回结果如何表示(序列化协 议),信息如何传输(传输协议),服务权限如何管理(认证、授 权),如何保证通信安全(网络安全层),如何令调用不同机器的服


务返回相同的结果(分布式数据一致性)等一系列问题,全都需要设 计者耗费大量精力。
面对重重困难与压力,DCE不仅从零开始、从无到有地回答了其中 大部分问题,构建出大量的分布式基础组件与协议,而且真的尽力做 到了相对“透明”,譬如在DFS上访问文件,如果不考虑性能差异,很 难感受到它与本地磁盘文件系统有什么不同。可是,一旦考虑性能差 异,那远程和本地的鸿沟是无比深刻的,两者的速度往往有着数量级 上的差距,完全不可调和。尤其是在那个时代的机器硬件条件下,为 了让程序在运行效率上可被用户接受,开发者只能在方法本身运行时 间很长、可以相对忽略远程调用成本时的情况下考虑分布式。如果方 法本身运行时间不够长,就要人为用各种Tricks刻意构造出这样的场 景,譬如将几个原本毫无关系的方法打包到一个方法体内,一起进行 远程调用。一方面,这种长耗时方法本身就与期望用分布式来突破硬 件算力限制、提升性能的初衷相悖;另一方面,此时的开发人员实际 上仍然必须每时每刻都意识到自己是在编写分布式程序,不可轻易踏 过本地与远程的界限。设计向性能做出的妥协,令DCE“尽量简单透 明”的努力几乎全部付诸东流,无论是从编码、设计、部署还是从运 行效率上看,远程与本地都有着天壤之别。开发一个能良好运作的分 布式应用,需要极高的编程技巧和各方面的专业知识去支撑,这时候 反而是人本身对软件规模的约束超过了机器算力上的约束。
对DCE的研究是计算机科学第一次对分布式有组织领导、有标准可 循、有巨大投入的尝试,但无论是DCE还是稍后出现的CORBA,从结果 来看,都不能称得上成功,因为将一个系统拆分到不同的机器中运 行,为解决这样做带来的服务发现、跟踪、通信、容错、隔离、配 置、传输、数据一致性和编码复杂度等方面的问题所付出的代价已远 远超过了分布式所取得的收益。亲身经历过那个年代的计算机科学 家、IBM院士Kyle Brown事后曾评价道,“这次尝试最大的收获就是对 RPC、DFS等概念的开创,以及得到了一个价值千金的教训:某个功能 能够进行分布式,并不意味着它就应该进行分布式,强行追求透明的 分布式操作,只会自寻苦果。”
额外知识
原始分布式时代的教训


某个功能能够进行分布式,并不意味着它就应该进行分布式,强
行追求透明的分布式操作,只会自寻苦果。
——Kyle Brown,IBM Fellow,Beyond Buzzwords:A Brief History of
Microservices Patterns,2016
以上结论是有违UNIX设计哲学的,却是当时现实情况下不得不做 出的让步。摆在计算机科学面前有两条通往更大规模软件系统的道 路:一条是尽快提升单机的处理能力,以避免分布式带来的种种问 题;另一条是找到更完美的、解决如何构建分布式系统的解决方案。
20世纪80年代正是摩尔定律开始稳定发挥作用的黄金时期,微型 计算机的性能以每两年增长一倍的惊人速度提升,硬件算力束缚软件 规模的链条很快变得松动,信息系统进入以单台或少量几台计算机即 可作为服务器来支撑大型信息系统运作的单体时代,且在很长的一段 时间内,单体都将是软件架构的绝对主流。尽管如此,对于另外一条 路,即对分布式计算、远程服务调用的探索也从未中断。关于远程服 务调用这个关键问题的历史、发展与现状,笔者还会在第2章中以现代 RPC和RESTful为主角来进行更详细的讲述。那些在原始分布式时代中 遇到的各种分布式问题,也还会在软件架构演进后面几个时代里被人 们反复提起。
原始分布式时代提出的构建符合UNIX设计哲学的、如同本地调用 一般简单透明的分布式系统的这个目标,是软件开发者对分布式系统 最初的美好愿景,但迫于现实,它会在一定时期内被妥协、被舍弃。 换句话说,分布式将会经过一段越来越复杂的发展过程。不过,在三
十多年后的21世纪10年代[3],随着分布式架构逐渐成熟、完善,并取 代单体成为大型软件的主流架构风格以后,这个美好的愿景终将会重 新被开发者拾起。
[1] UNIX系统的版本战争:https://en.wikipedia.org/wiki/Unix_wars。
[2] 分 布 式 运 算 环 境 :
https://en.wikipedia.org/wiki/Distributed_Computing_Environment。
[3] 20世纪80年代的三十多年之后。这里是指服务网格提出后,重新崛
起的透明通信。


1.2 单体系统时代
单体架构是今天绝大多数软件开发者都学习、实践过的一种软件 架构,许多介绍微服务的图书和技术资料中也常把这种架构风格的应 用称作“巨石系统”(Monolithic Application)。“单体架构”在 整个软件架构演进的历史进程里,是出现时间最早、应用范围最广、 使用人数最多、统治历史最长的一种架构风格,但“单体”这个名 称,却是在微服务开始流行之后才“事后追认”所形成的概念。此 前,并没有多少人将“单体”看作一种架构,如果你去查找软件架构 的开发资料,可以轻易地找出大量以微服务为主题的图书和文章,却 很难找出专门教你如何开发单体架构的任何形式的材料,这一方面体 现了单体架构本身的简单性,另一方面也体现出在相当长的时间里, 大家都已经习惯了软件架构就应该是单体这种样子。
剖析单体架构之前,我们有必要先厘清一个概念误区,在许多微 服务的资料里,单体系统往往是以“反派角色”的身份登场的,譬如 著名的微服务入门书《微服务架构设计模式》,第1章的名字就是“逃 离单体的地狱”。这些材料所讲的单体系统,其实都有一个隐含定 语:“大型的单体系统”。对于小型系统,单台机器就足以支撑其良 好运行的系统,不仅易于开发、测试、部署,且由于系统中各个功 能、模块、方法的调用过程都是进程内调用,不会发生进程间通信
(Inter-Process Communication,IPC[1]),因此连运行效率也是最 高的,所以此时的单体架构完全不应该被贴上“反派角色”的标签, 反倒是那些爱赶技术潮流却不顾需求现状的微服务吹捧者更像是个反 派。单体系统的不足,必须在软件的性能需求超过了单机、软件的开
发人员规模明显超过了“2 Pizza Team”[2]范畴的前提下才有讨论的 价值,因此,本书后续讨论中所说的单体,均特指“大型的单体系 统”。也正是因此,本节中说到“单体是出现最早的架构风格”,与 上一节开篇提到的“使用多个独立的分布式服务共同构建一个更大型 系统的设想与实际尝试,反而要比今天大家所了解的大型单体系统出 现的时间更早”实际并无矛盾。
额外知识


Monolith means composed all in one piece.The Monolithic application describes a single-tiered software application in which different components combined into a single program from a single platform.
单体意味着自包含。单体应用描述了一种由同一技术平台的不同
组件构成的单层软件。
——Wikipedia
尽管“Monolithic”这个词语本身的意思,“巨石”,确实带有 一些“不可拆分”的隐含意味,但人们也不应该简单粗暴地把单体系 统在维基百科上的定义“all in one piece”翻译成“铁板一块”, 它其实更接近于“自给自足”(Self-Contained,在计算机中译为 “自包含”)的含义。不过,这种“铁板一块”的译法不能全算作段 子,笔者相信肯定有一部分人说起单体架构、巨石系统时,在脑海中 闪过的第一个缺点就是它的不可拆分、难以扩展,因此才不能支撑越 来越大的软件规模。这种想法看似合理,其实是有失偏颇的,至少不 完整。
从纵向角度来看,笔者在实际生产环境里从未见过哪个大型现代 信息系统是完全不分层的。分层架构(Layered Architecture)已是 现在所有信息系统建设中普遍认可、采用的软件设计方法,无论是单 体还是微服务,抑或是其他架构风格,都会对代码进行纵向层次划 分,收到的外部请求在各层之间以不同形式的数据结构进行流转传 递,触及最末端的数据库后按相反的顺序回馈响应,如图1-1所示。对 于这个意义上的“可拆分”,单体架构完全不会展露出丝毫的弱势, 反而可能会因更容易开发、部署、测试而获得更好的便捷性。
从横向角度来看,单体架构也支持按照技术、功能、职责等维 度,将软件拆分为各种模块,以便重用和管理代码。单体系统并不意 味着只能有一个整体的程序封装形式,如果需要,它完全可以由多个 JAR、WAR、DLL、Assembly或者其他模块格式来构成。即使是从横向扩 展(Scale Horizontally)的角度来衡量,在负载均衡器之后同时部 署若干个相同的单体系统副本,以达到分摊流量压力的效果,也是非 常常见的需求。


在“拆分”这方面,单体系统的真正缺陷不在如何拆分,而在拆 分之后的自治与隔离能力上。由于所有代码都运行在同一个进程内, 所有模块、方法的调用都无须考虑网络分区、对象复制这些麻烦的事 和性能损失,但在获得进程内调用的简单、高效等好处的同时,也意 味着如果任何一部分代码出现缺陷,过度消耗了进程空间内的资源, 所造成的影响也是全局性的、难以隔离的。譬如内存泄漏、线程爆 炸、阻塞、死循环等问题,都将会影响整个程序,而不仅仅是影响某 一个功能、模块本身的正常运作。如果出现问题的是某些更高层次的 公共资源,譬如端口号或者数据库连接池泄漏,还将会影响整台机器 甚至集群中其他单体副本的正常工作。


图1-1 分层架构示意


同样,由于所有代码都共享同一个进程,不能隔离,也就无法 (其实还是有办法的,譬如使用OSGi这种运行时模块化框架,但是很 别扭、很复杂)做到单独停止、更新、升级某一部分代码,因为不可 能有“停掉半个进程,重启1/4个程序”这样不合逻辑的操作,所以从 可维护性来说,单体系统也是不占优势的。对于单体系统,在对程序 升级、修改时往往需要制定专门的停机更新计划,做灰度发布、A/B测 试也相对更复杂。
如果说共享同一进程获得简单、高效的代价是同时损失了各个功 能模块的自治与隔离能力,那这两者孰轻孰重呢?这个问题的潜台词 似乎是在比较微服务、单体架构哪种更好用、更优秀。笔者认为“好 用和优秀”不会是放之四海皆准的,这点不妨举一个浅显的例子加以 说明。譬如,沃尔玛将超市分为仓储部、采购部、安保部、库存管理 部、巡检部、质量管理部、市场营销部等,划清职责,明确边界,让 管理能力能支持企业的成长规模。但如果是你家楼下开的小卖部, 爸、妈加儿子,再算上看家的中华田园犬小黄一共也就只有四名员 工,再去追求“先进管理”,划分仓储部、采购部、库存管理部...... 那纯粹是给自己找麻烦。单体架构下,哪怕是信息系统中两个相互毫 无关联的子系统,也依然会部署在同一个进程中。当系统规模小的时 候,这是优势,但当系统规模大或程序需要修改的时候,其部署的成 本、技术升级的迁移成本都会变得非常昂贵。继续以前面的例子来比 喻,当公司小时,让安保部和质检部这两个不相干的部门在同一栋大 楼中办公是节约资源;但当公司人数增加,办公室已经拥挤不堪时, 最多只能在楼顶加盖新楼层(相当于增强硬件性能)来解决办公问 题,而不能让安保部和质检部分开地方办公,这便是缺陷所在。
由于隔离能力的缺失,单体除了难以阻断错误传播、不便于动态 更新程序以外,还面临难以技术异构的困难,每个模块的代码通常都 需要使用一样的程序语言,乃至一样的编程框架去开发。单体系统的 技术栈异构并非一定做不到,譬如JNI就可以让Java混用C或C++实现, 但这通常是迫不得已的,并不是优雅的选择。
不过,以上列举的这些问题都还不是今天以微服务取代单体系统 成为潮流趋势的根本原因,笔者认为最重要的原因是:单体系统很难 兼容“Phoenix”的特性。这种架构风格潜在的要求是希望系统的每一 个部件、每一处代码都尽量可靠,尽量不出或少出缺陷。然而战术层 面再优秀,也很难弥补战略层面的不足。单体系统靠高质量来保证高 可靠性的思路,在小规模软件上还能运作良好,但当系统规模越来越


大时,交付一个可靠的单体系统就变得越来越具有挑战性。如本书前 言所说,正是随着软件架构演进,构建可靠系统的观念从“追求尽量 不出错”到正视“出错是必然”的转变,才是微服务架构得以挑战并 逐步取代单体架构的底气所在。
为了允许程序出错,获得自治与隔离的能力,以及实现可以技术 异构等目标,是继性能与算力之后,让程序再次选择分布式的理由。 然而,开发分布式程序也并不意味着一定要依靠今天的微服务架构才 能实现。在新旧世纪之交,人们曾经探索过几种服务拆分方法,将一 个大的单体系统拆分为若干个更小的、不运行在同一个进程的独立服 务,这些服务拆分方法后来带来了面向服务架构(Service-Oriented Architecture)的一段兴盛期,我们称其为“SOA时代”。
[1] 广义上讲,可以认为RPC是IPC的一种特例,但请注意这两个词里的
“PC”不是同个单词的缩写。
[2] 由亚马逊创始人Jeff Bezos提出的衡量团队大小的“量词”。指两个
Pizza能喂饱的人数,大概是6~12人。


1.3 SOA时代
为了对大型的单体系统进行拆分,让每一个子系统都能独立地部 署、运行、更新,开发者们尝试过很多种方案,这里列举三种较有代 表性的架构模式,具体如下。
·烟囱式架构(Information Silo Architecture):信息烟囱又名信息
孤岛(Information Island),使用这种架构的系统也被称为孤岛式信息
系统或者烟囱式信息系统。它指的是一种与其他相关信息系统完全没
有互操作或者协调工作的设计模式。这样的系统其实并没有什么“架
构设计”可言。接着上一节中企业与部门的例子来说,如果两个部门
真的完全没有任何交互,就没有什么理由强迫它们必须在同一栋楼里
办公。两个不发生交互的信息系统,让它们使用独立的数据库和服务
器即可实现拆分,而唯一的问题,也是致命的问题是,企业中真的存
在完全没有交互的部门吗?对于两个信息系统来说,哪怕真的毫无业
务往来关系,但系统的人员、组织、权限等主数据会是完全独立、没
有任何重叠的吗?这样“独立拆分”“老死不相往来”的系统,显然
不可能是企业所希望见到的。
·微内核架构(Microkernel Architecture):微内核架构也被称为插
件式架构(Plug-in Architecture)。既然在烟囱式架构中,没有业务往来
关系的系统也可能需要共享人员、组织、权限等一些公共的主数据,
那不妨就将这些主数据,连同其他可能被各子系统用到的公共服务、
数据、资源集中到一块,组成一个被所有业务系统共同依赖的核心
(Kernel,也称为Core System),具体的业务系统以插件模块(Plug-in
Module)的形式存在,这样也可提供可扩展的、灵活的、天然隔离的
功能特性,即微内核架构,如图1-2所示。


图1-2 微内核架构示意图
这种模式很适合桌面应用程序,也经常在Web应用程序中使用。任 何计算机系统都是由各种软件互相配合来实现具体功能的,本节列举 的不同架构实现的软件,都可视作整个系统的某种插件。对于平台型 应用来说,如果我们希望将新特性或者新功能及时加入系统,微内核 架构会是一种不错的选择。微内核架构也可以嵌入其他架构模式中, 通过插件的方式来提供新功能的定制开发能力。如果你准备实现一个 能够支持二次开发的软件系统,微内核也会是一种不错的选择。
不过,微内核架构也有局限性,它假设系统中各个插件模块之间 互不认识,且不可预知系统将安装哪些模块,因此这些插件可以访问 内核中一些公共的资源,但不会直接交互。可是,无论是企业信息系


统还是互联网应用,这一假设在许多场景中并不成立,所以我们必须 找到办法,既能拆分出独立的系统,也能让拆分后的子系统之间顺畅 地相互通信。
·事件驱动架构(Event-Driven Architecture):为了能让子系统互
相通信,一种可行的方案是在子系统之间建立一套事件队列管道
(Event Queue),来自系统外部的消息将以事件的形式发送至管道
中,各个子系统可以从管道里获取自己感兴趣、能够处理的事件消
息,也可以为事件新增或者修改其中的附加信息,甚至可以自己发布
一些新的事件到管道队列中去。如此,每一条消息的处理者都是独立
的、高度解耦的,但又能与其他处理者(如果存在其他消息处理者的
话)通过事件管道进行交互,如图1-3所示。


图1-3 事件驱动架构示意图


当架构演化至事件驱动架构时,在1.1节提到的第二条通往更大规 模软件的路径,即仍在并行发展的远程服务调用也迎来了SOAP协议的 诞生(详见第2章),此时面向服务的架构(Service Oriented Architecture,SOA)已经有了登上软件架构舞台所需要的全部前置条 件。
SOA的概念最早由Gartner公司在1994年提出,当时的SOA还不具备 发展的条件,直至2006年IBM、Oracle、SAP等公司共同成立了 OSOA(Open Service Oriented Architecture)联盟,用于联合制定 和推进SOA相关行业标准之后,情况才有所变化。2007年,在结构化资 讯标准促进组织(Organization for the Advancement of Structured Information Standard,OASIS)的倡议与支持下,OSOA 由一个软件厂商组成的松散联盟,转变为一个制定行业标准的国际组 织,并联合OASIS共同新成立了Open CSA(Open Composite Service Architecture)组织,这便是SOA的官方管理机构。
软件架构来到SOA时代,其包含的许多概念、思想都已经能在今天 的微服务中找到对应的身影了,譬如服务之间的松散耦合、注册、发 现、治理,隔离、编排等。这些在微服务中耳熟能详的概念,大多数 也是在分布式服务刚被提出时就已经可以预见的困难点。SOA针对这些 问题,甚至是针对“软件开发”这件事情本身,都进行了更具体、更 系统的探索。
·“更具体”体现在尽管SOA本身还属于抽象概念,而不是特指
某一种具体的技术,但它比单体架构和前面所列举的三种架构模式的
操作性更强,已经不能简单视为一种架构风格,而是一套软件设计的
基础平台。它拥有领导制定技术标准的组织Open CSA;有清晰的软件
设计的指导原则,譬如服务的封装性、自治、松耦合、可重用、可组
合、无状态,等等;明确了采用SOAP作为远程调用协议,依靠SOAP
协议族(WSDL、UDDI和WS-*协议)来完成服务的发布、发现和治
理;利用企业服务总线(Enterprise Service Bus,ESB)的消息管道来实
现各个子系统之间的交互,令各服务在ESB的调度下无须相互依赖就能
相互通信,实现了服务松耦合,也为以后进一步实施业务流程编排
(Business Process Management,BPM)提供了基础;使用服务数据对象
(Service Data Object,SDO)来访问和表示数据,使用服务组件架构
(Service Component Architecture,SCA)来定义服务封装的形式和服务


运行的容器,等等。在这一套成体系的可以相互精密协作的技术组件
支持下,若仅从技术可行性这一个角度来评判的话,SOA可以算是已
经成功解决了分布式环境中出现的主要技术问题。
·“更系统”指的是SOA的宏大理想,它的终极目标是希望总结
出一套自上而下的软件研发方法论,做到企业只需要跟着SOA的思
路,就能够一揽子解决掉软件开发过程中的全部问题,譬如该如何挖
掘需求、如何将需求分解为业务能力、如何编排已有服务、如何开发/
测试/部署新的功能,等等。这些技术问题确实是重点和难点,但也仅
仅是其中的一个方面,SOA不仅关注技术,还关注研发过程中涉及的
需求、管理、流程和组织。如果这个目标真的能够达成,软件开发就
有可能从此迈进工业化大生产的阶段。试想如果有一天开发符合客户
需求的软件会像写八股文一样有迹可循、有法可依,那对软件开发者
来说也许是无趣的,但整个社会实施信息化的效率肯定会大幅提升。
SOA在21世纪最初的十年里曾盛行一时,有IBM等一众行业巨头厂 商为其呐喊冲锋,吸引了不少软件开发商,尤其是企业级软件开发 商,但最终还是偃旗息鼓,沉寂了下去。在后面的2.1节中,笔者会提 到SOAP协议被逐渐边缘化的本质原因:过于严格的规范定义带来过度 的复杂性,而构建在SOAP基础之上的ESB、BPM、SCA、SDO等诸多上层 建筑,进一步加剧了这种复杂性。开发信息系统毕竟不是作八股文 章,过于精密的流程和理论需要懂得复杂概念的专业人员才能够驾 驭。SOA自诞生的那一天起,就已经注定只能是少数系统阳春白雪式的 精致奢侈品,它可以实现多个异构大型系统之间的复杂集成交互,却 很难作为一种具有广泛普适性的软件架构风格来推广。SOA最终没有获 得成功的致命伤与当年的EJB如出一辙,尽管有Sun和IBM等一众巨头在 背后力挺,EJB仍然败于以Spring、Hibernate为代表的“草根框 架”,可见一旦脱离人民群众,终究会淹没在群众的海洋之中,连信 息技术也不曾例外。
读到这里,你不妨回想下“如何使用多个独立的分布式服务共同 构建一个更大型的系统”这个问题,再回想下1.1节中UNIX DCE中提出 的分布式服务的设计主旨:“开发人员不必关心服务是远程还是本 地,都能够透明地调用服务或者访问资源”。经过三十年的技术发 展,信息系统经历了巨石、烟囱、插件、事件、SOA等架构模式,应用 受架构复杂度的牵绊却越来越大,已经距离“透明”二字越来越远


了,这是否算不自觉间忘掉了当年的初心呢?接下来我们所谈论的微 服务时代,似乎正是带着这样的自省式的问句而开启的。


1.4 微服务时代
“微服务”这个技术名词最早在2005年就已经被提出,由Peter Rodgers博士在2005年的云计算博览会(Web Services Edge 2005)上 首次使用,当时的说法是“Micro-Web-Service”,指的是一种专注于 单一职责的、与语言无关的细粒度Web服务(Granular Web Service)。“微服务”一词并不是Peter Rodgers凭空创造出来的概 念,它最初可以说是SOA发展时催生的产物,就如同EJB推广过程中催 生了Spring和Hibernate那样,这一阶段的微服务是作为SOA的一种轻 量化的补救方案而被提出的。时至今日,在英文版的维基百科上,仍 然将微服务定义为SOA的一种变体,所以微服务在最初阶段与SOA、Web Service这些概念有所牵扯也完全可以理解,但现在来看,维基百科对 微服务的定义已经颇有些过时了。
额外知识
微服务是一种软件开发技术,是SOA的一种变体。
——Wikipedia
微服务的概念提出后,在将近十年的时间里面,它并没有受到太 多追捧。如果只是对现有SOA架构的修修补补,确实难以唤起广大技术 人员的更多关注。不过,在这十年时间里,微服务本身也在不断蜕 变。2012年,在波兰克拉科夫举行的“33rd Degree Conference”大 会上,Thoughtworks首席咨询师James Lewis做了题为
“Microservices-Java,the UNIX Way”[1]的主题演讲,其中提到了 单一服务职责、康威定律、自动扩展、领域驱动设计等原则,却只字 未提SOA,反而号召应该重拾UNIX的设计哲学(As Well Behaved UNIX Service),这点仿佛与笔者在1.3节所说的“初心与自省”遥相呼 应。微服务已经迫不及待地要脱离SOA的附庸,成为一种独立的架构风 格,也许,未来还将是SOA的革命者。
微服务真正崛起是在2014年,相信阅读此文的大多数读者,也是 从Martin Fowler与James Lewis合写的文章“Microservices:A
Definition of This New Architectural Term”[2]中首次了解微服


务的。当然,这并不是指各位一定读过这篇文章,应该准确地说—今天大家所了解的“微服务”就是这篇文章中定义的“微服务”。此 文首先给出了现代微服务的概念:“微服务是一种通过多个小型服务 组合来构建单个应用的架构风格,这些服务围绕业务能力而非特定的 技术标准来构建。各个服务可以采用不同的编程语言、不同的数据存 储技术,运行在不同的进程之中。服务采取轻量级的通信机制和自动 化的部署机制实现通信与运维。”此外,文中列举了微服务的九个核 心的业务与技术特征,下面将其一一列出并解读。
·围绕业务能力构建(Organized around Business Capability)。这
里再次强调了康威定律的重要性,有怎样结构、规模、能力的团队,
就会产生对应结构、规模、能力的产品。这个结论不是某个团队、某
个公司遇到的巧合,而是必然的演化结果。如果本应该归属同一个产
品内的功能被划分在不同团队中,必然会产生大量的跨团队沟通协
作,而跨越团队边界无论在管理、沟通、工作安排上都有更高昂的成
本,因此高效的团队自然会针对其进行改进,当团队、产品磨合稳定
之后,团队与产品就会拥有一致的结构。
·分散治理(Decentralized Governance)。这里是指服务对应的开
发团队有直接对服务运行质量负责的责任,也有不受外界干预地掌控
服务各个方面的权力,譬如选择与其他服务异构的技术来实现自己的
服务。这一点在真正实践时多少存有宽松的处理余地,大多数公司都
不会在某一个服务使用Java,另一个服务用Python,再下一个服务用
Go,而是通常会用统一的主流语言,乃至统一的技术栈或专有的技术
平台。微服务不提倡也并不反对这种“统一”,只要负责提供和维护
基础技术栈的团队有被各方依赖的觉悟,有“经常被凌晨3点的闹钟吵
醒”的心理准备就好。微服务更加强调的是在确实需要技术异构时,
应能够有选择“不统一”的权利,譬如不应该强迫Node.js去开发报表
页面,要做人工智能训练模型时可以选择Python,等等。
·通过服务来实现独立自治的组件(Componentization via
Service)。之所以强调通过“服务”(Service)而不是“类库”
(Library)来构建组件,是因为类库在编译期静态链接到程序中,通
过本地调用来提供功能,而服务是进程外组件,通过远程调用来提供


功能。前文我们也已经分析过,尽管远程服务有更高昂的调用成本,
但这是为组件带来自治与隔离能力的必要代价。
·产品化思维(Product not Project)。避免把软件研发视作要去
完成某种功能,而是视作一种持续改进、提升的过程。譬如,不应该
把运维只看作运维团队的事,把开发只看作开发团队的事,团队应该
为软件产品的整个生命周期负责,开发者不仅应该知道软件如何开
发,还应该知道它如何运作,用户如何反馈,乃至售后支持工作是怎
样进行的。注意,这里服务的用户不一定是最终用户,也可能是消费
这个服务的另外一个服务。以前在单体架构下,程序的规模决定了无
法让全部成员都关注完整的产品,如开发、运维、支持等不同职责的
成员只关注自己的工作,但在微服务下,要求开发团队中每个人都具
有产品化思维,关心整个产品的全部方面是具有可行性的。
·数据去中心化(Decentralized Data Management)。微服务明确
提倡数据应该按领域分散管理、更新、维护、存储。在单体服务中,
一个系统的各个功能模块通常会使用同一个数据库。诚然,中心化的
存储天生就更容易避免一致性问题,但是,同一个数据实体在不同服
务的视角里,它的抽象形态往往是不同的。譬如,Bookstore应用中的
书本,在销售领域中关注的是价格,在仓储领域中关注的是库存数
量,在商品展示领域中关注的是书的介绍信息,如果使用中心化存
储,所有领域都必须修改和映射到同一个实体之中,这很可能使不同
服务相互影响而丧失独立性。尽管在分布式中处理好一致性问题也相
当困难,很多时候都没办法使用传统的事务处理来保证,但是两害相
权取其轻,即使有一些必要的代价,但仍是值得使用的。
·强终端弱管道(Smart Endpoint and Dumb Pipe)。弱管道
(Dumb Pipe)几乎是直接反对SOAP和ESB的通信机制。ESB可以处理
消息的编码加工、业务规则转换等;BPM可以集中编排企业业务服
务;SOAP有几十个WS-*协议族在处理事务、一致性、认证授权等一
系列工作,这些构建在通信管道上的功能也许对某个系统中的某一部
分服务是有必要的,但对于另外更多的服务则是强加进来的负担。如
果服务需要上面的额外通信能力,就应该在服务自己的Endpoint上解


决,而不是在通信管道上一揽子处理。微服务提倡使用类似于经典
UNIX过滤器那样简单直接的通信方式,所以RESTful风格的通信在微
服务中会是更合适的选择。
·容错性设计(Design for Failure)。不再虚幻地追求服务永远稳
定,而是接受服务总会出错的现实,要求在微服务的设计中,能够有
自动的机制对其依赖的服务进行快速故障检测,在持续出错的时候进
行隔离,在服务恢复的时候重新联通。所以“断路器”这类设施,对
实际生产环境中的微服务来说并不是可选的外围组件,而是一个必需
的支撑点,如果没有容错性设计,系统很容易被一两个服务崩溃所带
来的雪崩效应淹没。可靠系统完全可能由会出错的服务组成,这是微
服务最大的价值所在,也是本书前言中所说的“凤凰架构”的含义。
·演进式设计(Evolutionary Design)。容错性设计承认服务会出
错,演进式设计则承认服务会被报废淘汰。一个设计良好的服务,应
该是能够报废的,而不是期望得到长存永生。假如系统中出现不可更
改、无可替代的服务,这并不能说明这个服务多么优秀、多么重要,
反而是一种系统设计上脆弱的表现,微服务所追求的自治、隔离,也
是反对这种脆弱性的表现。
·基础设施自动化(Infrastructure Automation)。基础设施自动
化,如CI/CD的长足发展,显著减少了构建、发布、运维工作的复杂
性。由于微服务架构下运维对象数量是单体架构运维对象数量的数量
级倍,使用微服务的团队更加依赖于基础设施的自动化,人工是很难
支撑成百上千乃至上万级别的服务的。
“Microservices”一文中对微服务特征的描写已经相当具体了, 文中除了定义微服务是什么,还专门申明了微服务不是什么——微服 务不是SOA的变体或衍生品,应该明确地与SOA划清界限,不再贴上任 何SOA的标签。如此,微服务的概念才算是一种真正丰满、独立的架构 风格,为它在未来几年时间里如明星一般闪耀崛起于技术舞台铺下了 理论基础。
额外知识


微服务与SOA
由于与SOA具有一致的表现形式,这让微服务的支持者更加迫切
地拒绝微服务再被打上SOA的标签,尽管有一些人坚持认为微服务就
是SOA的一种变体,也许从面向服务方面来说是对的,但无论如何,
SOA与微服务都是两种不同的东西,正因如此,使用一个别的名称来
简明地定义这种架构风格就显得更有必要。
——Martin Fowler/James Lewis
从以上微服务的定义和特征中,你应该可以明显地感觉到微服务 追求的是更加自由的架构风格,摒弃了几乎所有SOA里可以抛弃的约束 和规定,提倡以“实践标准”代替“规范标准”。可是,如果没有了 统一的规范和约束,以前SOA解决的那些分布式服务的问题,不也就一 下子都重新出现了吗?的确如此,对于服务的注册发现、跟踪治理、 负载均衡、故障隔离、认证授权、伸缩扩展、传输通信、事务处理等 问题,微服务中将不再有统一的解决方案。即使只讨论Java范围内会 使用到的微服务,仅一个服务间远程调用问题,可以列入解决方案的 候选清单的就有RMI(Sun/Oracle)、Thrift(Facebook)、 Dubbo(阿里巴巴)、gRPC(Google)、Motan2(新浪)、 Finagle(Twitter)、brpc(百度)、Arvo(Hadoop)、JSON-RPC、 REST,等等;仅一个服务发现问题,可以选择的就有 Eureka(Netflix)、Consul(HashiCorp)、Nacos(阿里巴巴)、 ZooKeeper(Apache)、etcd(CoreOS)、CoreDNS(CNCF),等等。 其他领域也与此类似。
微服务所带来的自由是一把双刃开锋的宝剑,当软件架构者拿起 这把宝剑,一刃指向SOA定下的复杂技术标准,将选择的权力夺回的同 一时刻,另外一刃也正朝着自己映出冷冷的寒光。在微服务时代,软 件研发本身的复杂度确实有所降低。一个简单服务,并不见得会同时 面临分布式中的所有问题,也就没有必要背上SOA那百宝袋般沉重的技 术包袱。需要解决什么问题,就引入什么工具;团队熟悉什么技术, 就使用什么框架。此外,像Spring Cloud这样胶水式的全家桶工具 集,通过一致的接口、声明和配置,进一步屏蔽了源自具体工具、框 架的复杂性,降低了在不同工具、框架之间切换的成本,所以,作为 一个普通的服务开发者,作为一个“螺丝钉”式的程序员,微服务架 构是友善的。可是,微服务对架构者却是满满的“恶意”,对架构能


力的要求已提升到史无前例的程度。笔者在本书的多处反复强调过, 技术架构者的第一职责就是决策权衡,有利有弊才需要决策,有取有 舍才需要权衡,如果架构者本身的知识面不足以覆盖所需要决策的内 容,不清楚其中利弊,恐怕将无可避免地陷入选择困难症的境遇之 中。
微服务时代充满着自由的气息,微服务时代充斥着迷茫的选择。 软件架构不会止步于自由,微服务仍不是架构探索的终点,如果有下 一个时代,笔者希望是信息系统拥有微服务的自由权利,围绕业务能 力构建自己的服务而不受技术规范管束,但又不用以承担自行解决分 布式的问题的责任为代价。管他什么利弊权衡!小孩子才做选择题, 成年人全部都要!
[1] 下载地址:http://2012.33degree.org/talk/show/67。
[2] 下载地址:https://martinfowler.com/articles/microservices.html。


1.5 后微服务时代
上节提到的分布式架构中出现的问题,如注册发现、跟踪治理、 负载均衡、传输通信等,其实在SOA时代甚至从原始分布式时代起就已 经存在了,只要是分布式架构的系统,就无法完全避免,但我们不妨 换个思路来想一下,这些问题一定要由软件系统自己来解决吗?
如果不局限于采用软件的方式,这些问题几乎都有对应的硬件解 决方案。譬如,某个系统需要伸缩扩容,通常会购买新的服务器,部 署若干副本实例来分担压力;如果某个系统需要解决负载均衡问题, 通常会布置负载均衡器,选择恰当的均衡算法来分流;如果需要解决 传输安全问题,通常会布置TLS传输链路,配置好CA证书以保证通信不 被窃听篡改;如果需要解决服务发现问题,通常会设置DNS服务器,让 服务访问依赖稳定的记录名而不是易变的IP地址,等等。随着计算机 科学多年的发展,这些问题大多有了专职化的基础设施去解决,而在 微服务时代,人们之所以选择在软件的代码层面而不是硬件的基础设 施层面去解决这些分布式问题,很大程度上是因为由硬件构成的基础 设施跟不上由软件构成的应用服务的灵活性的无奈之举。软件可以只 使用键盘命令就拆分出不同的服务,只通过拷贝、启动就能够实现伸 缩扩容服务,硬件难道就不可以通过键盘命令变出相应的应用服务 器、负载均衡器、DNS服务器、网络链路这些设施吗?
至此,估计大家已经听出下面要说的是虚拟化技术和容器化技术 了。微服务时代所取得的成就,本身就离不开以Docker为代表的早期 容器化技术的巨大贡献。在此之前,笔者从来没有提过“容器”二 字,这并不是刻意冷落,而是早期的容器只被简单地视为一种可快速 启动的服务运行环境,目的是方便程序的分发部署,在这个阶段,针 对单个应用进行封装的容器并未真正解决分布式架构问题。尽管2014 年微服务开始崛起的时候,Docker Swarm(2013年)和Apache Mesos(2012年)就已经存在,更早之前也出现了软件定义网络 (Software-Defined Networking,SDN)、软件定义存储(SoftwareDefined Storage,SDS)等技术,但是,被业界广泛认可、普遍采用 的通过虚拟化基础设施去解决分布式架构问题的开端,应该要从2017 年Kubernetes取得容器战争的胜利开始算起。


2017年是容器生态发展历史中具有里程碑意义的一年。在这一 年,长期作为Docker竞争对手的RKT容器一派的领导者CoreOS宣布放弃 自己的容器管理系统Fleet,并将会在未来把所有容器管理的功能移至 Kubernetes之上去实现。在这一年,容器管理领域的独角兽Rancher Labs宣布放弃其内置了数年的容器管理系统Cattle,提出“All-inKubernetes”战略,把1.x版本就能够支持多种容器编排系统的管理工 具Rancher,从2.0版本开始“反向升级”为完全绑定于Kubernetes这 一系统。在这一年,Kubernetes的主要竞争者Apache Mesos在9月正式 宣布了“Kubernetes on Mesos”集成计划,由竞争关系转为对 Kubernetes提供支持,使其能够与Mesos的其他一级框架(如HDFS、 Spark和Chronos等)进行集群资源动态共享、分配与隔离。在这一 年,Kubernetes的最大竞争者Docker Swarm的母公司Docker,终于在 10月被迫宣布Docker要同时支持Swarm与Kubernetes两套容器管理系 统,也即在事实上承认了Kubernetes的统治地位。这场已经持续了三 年时间,以Docker Swarm、Apache Mesos与Kubernetes为主要竞争者 的“容器编排战争”终于有了明确的结果。Kubernetes登基加冕是容 器发展中一个时代的终章,也将是软件架构发展下一个纪元的开端。 笔者在表1-1中列出了针对同一个分布式服务问题,Kubernetes中提供 的基础设施层面的解决方案与传统Spring Cloud中提供的应用层面的 解决方案的对比,尽管因为各自出发点不同,解决问题的方法和效果 都有所差异,但这无疑是提供了一条全新的、前途更加广阔的解题思 路。
表1-1 Kubernetes与传统Spring Cloud提供的解决方案对比


“前途广阔”不仅仅是一句恭维赞赏的客气话,当虚拟化的基础 设施从单个服务的容器扩展至由多个容器构成的服务集群、通信网络 和存储设施时,软件与硬件的界限便已模糊。一旦虚拟化的硬件能够 跟上软件的灵活性,那些与业务无关的技术性问题便有可能从软件层 面剥离,悄无声息地在硬件基础设施之内解决,让软件得以只专注业 务,真正围绕业务能力构建团队与产品。如此,DCE中未能实现的“透
明的分布式应用”成为可能,Martin Flower设想的“凤凰服务器[1]”
成为可能,Chad Fowler提出的“不可变基础设施[2]”也成为可能。从 软件层面独立应对分布式架构所带来的各种问题,发展到应用代码与 基础设施软、硬一体,合力应对架构问题,这个新的时代现在常被媒 体冠以“云原生”这个颇为抽象的名字加以宣传。云原生时代追求的 目标与此前微服务时代追求的目标并没有本质改变,都是在服务架构 演进的历史进程中,所以笔者更愿意称云原生时代为“后微服务时 代”。
Kubernetes成为容器战争胜利者标志着后微服务时代的开启,但 Kubernetes仍然没能完美解决全部的分布式问题——“不完美”的意 思是,仅从功能上看,单纯的Kubernetes反而不如之前的Spring


Cloud方案。这是因为有一些问题处于应用系统与基础设施的边缘,使 得很难完全在基础设施层面中精细化地处理。举个例子,如图1-4所 示,微服务A调用了微服务B的两个服务,称为B1和B2,假设B1表现正 常但B2出现了持续的500错,那在达到一定阈值之后就应该对B2进行熔 断,以避免产生雪崩效应。如果仅在基础设施层面来处理,这会遇到 一个两难问题,切断A到B的网络通路会影响B1的正常调用,不切断则 会持续受B2的错误影响。
图1-4 是否要熔断对服务B的访问
以上问题在通过Spring Cloud这类应用代码实现的微服务中并不 难处理,既然是使用程序代码来解决问题,只要合乎逻辑,想要实现 什么功能,只受限于开发人员的想象力与技术能力,但基础设施是针 对整个容器来管理的,粒度相对粗犷,只能到容器层面,对单个远程 服务则很难有效管控。类似的,在服务的监控、认证、授权、安全、 负载均衡等方面都有可能面临细化管理的需求,譬如服务调用时的负 载均衡,往往需要根据流量特征,调整负载均衡的层次、算法等,而 DNS虽然能实现一定程度的负载均衡,但通常并不能满足这些额外的需 求。
为了解决这一类问题,虚拟化的基础设施很快完成了第二次进 化,引入了今天被称为“服务网格”(Service Mesh)的“边车代理


模式”(Sidecar Proxy),如图1-5所示。所谓“边车”是一种带垮 斗的三轮摩托车,笔者小时候还算常见,现在基本就只在影视剧中才 会看到了。在虚拟化场景中的边车指的是由系统自动在服务容器(通 常是指Kubernetes的Pod)中注入一个通信代理服务器,相当于那个挎 斗,以类似网络安全里中间人攻击的方式进行流量劫持,在应用毫无 感知的情况下,悄然接管应用所有对外通信。这个代理除了实现正常 的服务间通信外(称为数据平面通信),还接收来自控制器的指令 (称为控制平面通信),根据控制平面中的配置,对数据平面通信的 内容进行分析处理,以实现熔断、认证、度量、监控、负载均衡等各 种附加功能。通过边车代理模式,便实现了既不需要在应用层面加入 额外的处理代码,也提供了几乎不亚于程序代码的精细管理能力。
我们很难从概念上判定清楚一个与应用系统运行于同一资源容器 之内的代理服务到底应该算软件还是基础设施,但它对应用是透明 的,不需要改动任何软件代码就可以实现服务治理,这便足够了。服 务网格在2018年才火起来,今天它仍然是个新潮的概念,未完全成 熟,甚至连Kubernetes也还算是个新生事物。但笔者相信,未来 Kubernetes将会成为服务器端的标准运行环境,如同现在的Linux系 统;服务网格也将会成为微服务之间通信交互的主流模式,把“选择 什么通信协议”“怎样调度流量”“如何认证授权”之类的技术问题 隔离于程序代码之外,取代今天Spring Cloud全家桶中大部分组件的 功能。微服务只需要考虑业务本身的逻辑,这才是最理想的智能终端 解决方案。


图1-5 边车代理流量示意[3]
业务与技术完全分离,远程与本地完全透明,也许这就是最好的 时代了吧?
[1] 凤凰服务器:https://martinfowler.com/bliki/PhoenixServer.html。


[2] 不 可 变 基 础 设 施 : http://chadfowler.com/2013/06/23/immutable
deployments.html。
[3] 图来自Istio的配置文档,图中的Mixer在Istio 1.5之后已经取消,这里
仅作示意。


1.6 无服务时代
人们研究分布式架构,最初是因为单台机器的性能无法满足系统 的运行需求,尽管在后来架构演进过程中,容错能力、技术异构、职 责划分等各方面因素都成为架构需要考虑的问题,但获得更好的性能 在架构设计需求中依然占很大的比重。对软件研发而言,不去做分布 式无疑是最简单的,如果单台服务器的性能可以是无限的,那架构演 进的结果肯定会与今天有很大差别,分布式也好,容器化也好,微服 务也好,恐怕都未必会如期出现,最起码一定不是今天这个样子。
绝对意义上的无限性能必然是不存在的,但在云计算落地已有十 余年的今天,相对意义的无限性能已经成为现实。
在工业界,2012年Iron.io公司率先提出了“无服务” (Serverless,应该翻译为“无服务器”才合适,但现在称“无服 务”已形成习惯了)的概念;2014年,亚马逊发布了名为Lambda的商 业化无服务计算平台,并在后续的几年里逐步得到开发者认可,发展 为目前世界上最大的无服务运行平台;到了2018年,中国的阿里云、 腾讯云等厂商也开始跟进,发布了旗下的无服务产品,“无服务”成 为近期技术圈里的“新网红”之一。
在学术界,2009年,云计算概念刚提出的早期,在加州大学伯克 利分校曾发表的论文“Above the Clouds:A Berkeley View of Cloud
Computing”[1]中预言的云计算的价值、演进和普及在接下来的十年 里一一得到验证。2019年,加州大学伯克利分校发表的第二篇有着相 同命名风格的论文“Cloud Programming Simplified:A Berkeley
View on Serverless Computing”[2]再次预言“无服务将会发展成为 未来云计算的主要形式”。由此来看,“无服务”也同样是被主流学 术界所认可的发展方向之一。
额外知识
我们预测无服务将会发展成为未来云计算的主要形式。


——Cloud Programming Simplified:A Berkeley View on Serverless
Computing,2019
无服务现在还没有一个特别权威的“官方”定义,但它的概念并 没有前面提到的各种架构那么复杂,本来无服务也是以“简单”为主 要卖点的,它只涉及两块内容:后端设施(Backend)和函数 (Function)。
·后端设施是指数据库、消息队列、日志、存储等这类用于支撑
业务逻辑运行,但本身无业务含义的技术组件,这些后端设施都运行
在云中,在无服务中将它们称为“后端即服务”(Backend as a
Service,BaaS)。
·函数是指业务逻辑代码,这里函数的概念与粒度都已经很接近
于程序编码角度的函数了,其区别是无服务中的函数运行在云端,不
必考虑算力问题,也不必考虑容量规划(从技术角度可以不考虑,从
计费的角度还是要掂量一下的),在无服务中将其称为“函数即服
务”(Function as a Service,FaaS)。
无服务的愿景是让开发者只需要纯粹地关注业务:不需要考虑技 术组件,后端的技术组件是现成的,可以直接取用,没有采购、版权 和选型的烦恼;不需要考虑如何部署,部署过程完全托管到云端,由 云端自动完成;不需要考虑算力,有整个数据中心支撑,算力可以认 为是无限的;不需要操心运维,维护系统持续平稳运行是云计算服务 商的责任而不再是开发者的责任。在UC Berkeley的论文中,把无服务 架构下开发者不再关心这些技术层面的细节,类比成当年软件开发从 汇编语言踏进高级语言的发展过程,开发者可以不去关注寄存器、信 号、中断等与机器底层相关的细节,从而令生产力得到极大解放。
无服务架构的远期前景看起来是很美好的,但笔者自己对无服务 架构短期内的发展并没有那么乐观。与单体架构、微服务架构不同, 无服务架构有一些天生的特点决定了它现在不是,以后如果没有重大 变革的话,估计也很难成为一种普适性的架构模式。无服务架构确实 能够降低一些应用的开发和运维环节的成本,譬如不需要交互的离线 大规模计算,又譬如多数Web资讯类网站、小程序、公共API服务、移 动应用服务端等都契合于无服务架构所擅长的短链接、无状态、适合


事件驱动的交互形式。但另一方面,对于那些信息管理系统、网络游 戏等应用,或者说对于具有业务逻辑复杂、依赖服务端状态、响应速 度要求较高、需要长链接等特征的应用,至少目前是相对不那么适合 的。这是因为无服务天生“无限算力”的假设决定了它必须要按使用 量(函数运算的时间和占用的内存)计费以控制消耗的算力的规模, 因而函数不会一直以活动状态常驻服务器,请求到了才会开始运行, 这就导致了函数不便依赖服务端状态,也导致了函数会有冷启动时 间,响应的性能可能不太好。目前无服务的冷启动过程大概是在数十 到百毫秒级别,对于Java这类启动性能差的应用,甚至是接近秒的级 别。
无论如何,云计算毕竟是大势所趋,今天信息系统建设的概念和 观点,在(较长尺度的)明天都是会转变成适应云端的,笔者并不怀 疑Serverless+API的设计方式会成为以后其中一种主流的软件形式, 届时无服务还会有更广阔的应用空间。
如果说微服务架构是分布式系统这条路当前所能做到的极致,那 无服务架构,也许就是“不分布式”的云端系统这条路的起点。虽然 在顺序上笔者将“无服务”安排到了“微服务”和“云原生”时代之 后,但它们并没有继承替代关系,强调这点是为了避免有读者从两者 的名称与安排的顺序中产生“无服务就会比微服务更加先进”的错误 想法。笔者相信软件开发的未来不会只存在某一种“最先进的”架构 风格,多种具有针对性的架构风格并存,是软件产业更有生命力的形 态。笔者同样相信在软件开发的未来,多种架构风格将会融合互补, “分布式”与“不分布式”的边界将逐渐模糊,两条路线将在云端的 数据中心中交汇。今天已经能初步看见一些使用无服务的云函数去实 现微服务架构的苗头了,将无服务作为技术层面的架构,将微服务视 为应用层面的架构,把它们组合起来使用是完全合理可行的。以后, 无论是物理机、虚拟机、容器,抑或是无服务云函数,都会是微服务 实现方案的候选项之一。
本节是架构演进历史的最后一节,如本章引言所说,我们谈历 史,重点不在考古,而是借历史之名,理解每种架构出现的意义与淘 汰的原因,为的是更好地解决今天的现实问题,寻找出未来架构演进 的发展道路。
对于架构演进的未来发展,2014年,Martin Fowler与James Lewis在“Microservices”的结束语中曾写到,他们对于微服务日后


能否被大范围推广,最多只持有谨慎乐观的态度。在无服务方兴未艾 的今天,与那时微服务的情况十分相近,笔者对无服务日后的推广同 样持谨慎乐观的态度。软件开发的最大挑战就在于只能在不完备的信 息下决定当前要处理的问题。时至今日,依然很难预想在架构演进之 路的前方,微服务和无服务之后还会出现何种形式的架构风格,但这 也契合了图灵的那句名言:尽管目光所及之处,只是不远的前方,即 使如此,依然可以看到那里有许多值得去完成的工作在等待我们。
额外知识
尽管目光所及之处,只是不远的前方,即使如此,依然可以看到
那里有许多值得去完成的工作在等待我们。
——Alan Turing,Computing Machinery and Intelligence,1950
[1] 论 文 地 址 :
https://www2.eecs.berkeley.edu/Pubs/TechRpts/2009/EECS-2009-28.pdf。
[2] 论文地址:https://arxiv.org/abs/1902.03383。


第二部分 架构师的视角
■第2章 访问远程服务
■第3章 事务处理
■第4章 透明多级分流系统
■第5章 架构安全性


第2章 访问远程服务
远程服务将计算机程序的工作范围从单机扩展至网络,从本地延 伸至远程,是构建分布式系统的首要基础。而远程服务又不仅仅是为 分布式系统服务的,在网络时代,浏览器、移动设备、桌面应用和服 务端的程序,普遍都有与其他设备交互的需求,所以今天已经很难找 到没有开发和使用过远程服务的程序员了,但是没有正确理解远程服 务的程序员却不少。


2.1 远程服务调用
远程服务调用(Remote Procedure Call,RPC)在计算机科学中 已经存在超过四十年时间,但在今天仍然可以在各种论坛、技术网站 上遇见“什么是RPC”“如何评价某某RPC技术”“RPC更好还是REST更 好”之类的问题,仍然有新的不同形状的RPC轮子被发明制造出来,仍 然有层出不穷的文章去比对Google gRPC、Facebook Thrift等各家的 RPC组件库的优劣。
像计算机科学这种快速更迭的领域,一项四十岁高龄的技术能有 如此关注度,可算是相当罕见的现象,这一方面是由于微服务风潮带 来的热度,另一方面,也不得不承认,确实有不少开发者对RPC本身解 决什么问题、如何解决这些问题、为什么要这样解决存在认知模糊的 情况。本节,笔者会从历史到现状,从现象到本质,尽可能深入地解 释清楚RPC的来龙去脉。


2.1.1 进程间通信
尽管今天的大多数RPC技术已经不再追求这个目标了,但不可否 认,RPC出现的最初目的,就是为了让计算机能够与调用本地方法一样 去调用远程方法。所以,我们先来看一下调用本地方法时,计算机是 如何处理的。笔者通过以下这段Java风格的伪代码来定义几个稍后要 用到的概念:
// Caller : 调用者,代码里的main() // Callee : 被调用者,代码里的println()
// Call Site : 调用点,即发生方法调用的指令流位置
// Parameter : 参数,由Caller传递给Callee的数据,即“hello world”
// Retval : 返回值,由Callee传递给Caller的数据,如果方法能够正常结束,它是
void,
如果方法异常完成,它是对应的异常
public static void main(String[] args) { System.out.println("hello world"); }
在完全不考虑编译器优化的前提下,程序运行至调用println()方 法输出hello world这行时,计算机(物理机或者虚拟机)要完成以下 几项工作。
1)传递方法参数:将字符串hello world的引用地址压栈。
2)确定方法版本:根据println()方法的签名,确定其执行版 本。这其实并不是一个简单的过程,无论是编译时静态解析,还是运 行时动态分派,都必须根据某些语言规范中明确定义的原则,找到明 确的Callee,“明确”是指唯一的一个Callee,或者有严格优先级的 多个Callee,譬如不同的重载版本。笔者曾在《深入理解Java虚拟 机》的第8章介绍该过程,有兴趣的读者可以参考,这里不再赘述。
3)执行被调方法:从栈中弹出Parameter的值或引用,并以此为 输入,执行Callee内部的逻辑。这里我们只关心方法是如何调用的, 而不关心方法内部具体是如何执行的。
4)返回执行结果:将Callee的执行结果压栈,并将程序的指令流 恢复到Call Site的下一条指令,继续向下执行。


我们再来考虑如果println()方法不在当前进程的内存地址空间中 会发生什么问题。不难想到,这样会至少面临两个直接的障碍。首 先,第一步和第四步所做的传递参数、传回结果都依赖于栈内存,如 果Caller与Callee分属不同的进程,就不会拥有相同的栈内存,此时 将参数在Caller进程的内存中压栈,对于Callee进程的执行毫无意 义。其次,第二步的方法版本选择依赖于语言规则,如果Caller与 Callee不是同一种语言实现的程序,方法版本选择就将是一项模糊的 不可知行为。
为了简化讨论,我们暂时忽略第二个障碍,假设Caller与Callee 是使用同一种语言实现的,先来解决两个进程之间如何交换数据的问 题,这件事情在计算机科学中被称为“进程间通信”(Inter-Process Communication,IPC)。可以考虑的解决办法有以下几种。
·管道(Pipe)或者具名管道(Named Pipe):管道类似于两个
进程间的桥梁,可通过管道在进程间传递少量的字符流或字节流。普
通管道只用于有亲缘关系的进程(由一个进程启动的另外一个进程)
间的通信,具名管道摆脱了普通管道没有名字的限制,除具有管道的
所有功能外,它还允许无亲缘关系的进程间的通信。管道典型的应用
就是命令行中的“|”操作符,譬如:
ps -ef | grep java
ps与grep都有独立的进程,以上命令就是通过管道操作符“|”将 ps命令的标准输出连接到grep命令的标准输入上。
·信号(Signal):信号用于通知目标进程有某种事件发生。除了
进程间通信外,进程还可以给进程自身发送信号。信号的典型应用是
kill命令,譬如:
kill -9 pid
以上命令即表示由Shell进程向指定PID的进程发送SIGKILL信号。


·信号量(Semaphore):信号量用于在两个进程之间同步协作手
段,它相当于操作系统提供的一个特殊变量,程序可以在上面进行
wait()和notify()操作。
·消息队列(Message Queue):以上三种方式只适合传递少量消
息,POSIX标准中定义了可用于进程间数据量较多的通信的消息队
列。进程可以向队列添加消息,被赋予读权限的进程还可以从队列消
费消息。消息队列克服了信号承载信息量少、管道只能用于无格式字
节流以及缓冲区大小受限等缺点,但实时性相对受限。
·共享内存(Shared Memory):允许多个进程访问同一块公共内
存空间,这是效率最高的进程间通信形式。原本每个进程的内存地址
空间都是相互隔离的,但操作系统提供了让进程主动创建、映射、分
离、控制某一块内存的程序接口。当一块内存被多进程共享时,各个
进程往往会与其他通信机制,譬如与信号量结合使用,来达到进程间
同步及互斥的协调操作。
·本地套接字接口(IPC Socket):消息队列与共享内存只适合单
机多进程间的通信,套接字接口则是更普适的进程间通信机制,可用
于不同机器之间的进程通信。套接字(Socket)起初是由UNIX系统的
BSD分支开发出来的,现在已经移植到所有主流的操作系统上。出于
效率考虑,当仅限于本机进程间通信时,套接字接口是被优化过的,
不会经过网络协议栈,不需要打包拆包、计算校验和、维护序号和应
答等操作,只是简单地将应用层数据从一个进程复制到另一个进程,
这种进程间通信方式即本地套接字接口(UNIX Domain Socket),又
叫作IPC Socket。


2.1.2 通信的成本
之所以花费那么多篇幅来介绍IPC的手段,是因为最初计算机科学 家们的想法,就是将RPC作为IPC的一种特例来看待,这个观点在今 天,仅从分类上说也仍然合理,只是到具体操作手段上就不合适了。
请特别注意最后一种基于套接字接口的通信方式(IPC Socket),它不仅适用于本地相同机器的不同进程间通信,由于 Socket是网络栈的统一接口,它也能支持基于网络的跨机进程间通 信。譬如Linux系统的图形化界面、X Window服务器和GUI程序之间的 交互就是由这套机制来实现的。这样做的好处是,由于Socket是各个 操作系统都提供的标准接口,完全有可能把远程方法调用的通信细节 隐藏在操作系统底层,从应用层面上来看可以做到远程调用与本地的 进程间通信在编码上完全一致。事实上,在原始分布式时代的早期确 实是奔着这个目标去做的,但这种透明的调用形式反而给程序员带来 通信无成本的假象,因而被滥用,以致于显著降低了分布式系统的性 能。1987年,在“透明的RPC调用”一度成为主流范式的时候,Andrew Tanenbaum教授曾发表论文“A Critique of The Remote Procedure
Call Paradigm”[1],对这种透明的RPC范式提出一系列质问。
·两个进程通信,谁作为服务端,谁作为客户端?
·怎样进行异常处理?异常该如何让调用者获知?
·服务端出现多线程竞争之后怎么办?
·如何提高网络利用的效率?连接是否可被多个请求复用以减少
开销?是否支持多播?
·参数、返回值如何表示?应该有怎样的字节序?
·如何保证网络的可靠性?调用期间某个链接忽然断开了怎么
办?
·发送的请求服务端收不到回复怎么办?


论文的中心观点是:把本地调用与远程调用当作同样的调用来处 理,这是犯了方向性的错误,把系统间的调用透明化,反而会增加程 序员工作的复杂度。此后几年,关于RPC应该如何发展、如何实现的论 文层出不穷,透明通信的支持者有之,反对者有之,冷静分析者有 之,狂热唾骂者也有之,但历史逐渐证明Andrew Tanenbaum的预言是 正确的。最终,到1994年至1997年间,由ACM和Sun院士Peter Deutsch、套接字接口发明者Bill Joy、Java之父James Gosling等一 众在Sun公司工作的专家们共同总结了通过网络进行分布式运算的八宗
罪(8 Fallacies of Distributed Computing)[2]。
1)The network is reliable.——网络是可靠的。
2)Latency is zero.——延迟是不存在的。
3)Bandwidth is infinite.——带宽是无限的。
4)The network is secure.——网络是安全的。
5)Topology doesn’t change.——拓扑结构是一成不变的。
6)There is one administrator.——总会有一个管理员。
7)Transport cost is zero.——不必考虑传输成本。
8)The network is homogeneous.——网络都是同质化的。
以上这八条反话被认为是程序员在网络编程中经常忽略的八大问 题,潜台词就是如果远程服务调用要透明化,就必须为这些罪过埋 单,这算是给RPC能否等同于IPC来暂时定下了一个具有公信力的结 论。至此,“RPC应该是一种高层次的或者说语言层次的特征,而不是 像IPC那样,是低层次的或者说系统层次的特征”的观点成为工业界、 学术界的主流观点。
在20世纪80年代初期,传奇的施乐Palo Alto研究中心发布了基于 Cedar语言的RPC框架——Lupine,并实现了世界上第一个基于RPC的商 业应用——Courier,这里施乐Palo Alto研究中心所定义的“远程服 务调用”的概念就是完全符合以上对RPC的结论的,所以,尽管此前已 经有用其他名词指代“调用远程服务”的操作,一般仍认为RPC的概念 最早是由施乐公司提出的。


额外知识
首次提出远程服务调用的定义
远程服务调用是指位于互不重合的内存地址空间中的两个程序,
在语言层面上,以同步的方式使用带宽有限的信道来传输程序控制信
息。
——Bruce Jay Nelson,Remote Procedure Call,Xerox PARC,1981
[1] 下 载 地 址 : https://www.cs.vu.nl/~ast/Publications/Papers/euteco
1988.pdf。
[2] 详 见 :
https://en.wikipedia.org/wiki/Fallacies_of_distributed_computing。


2.1.3 三个基本问题
20世纪80年代中后期,惠普和Apollo提出了网络运算架构 (Network Computing Architecture,NCA)的设想,并随后在DCE项 目中将其发展成在UNIX系统下的远程服务调用框架DCE/RPC。笔者曾经 在1.1节中介绍过DEC,这是历史上第一次对分布式的有组织的探索尝 试,由于DEC本身是基于UNIX操作系统的,所以DEC/RPC通常也仅适合 在UNIX系统程序之间使用。(微软COM/DCOM的前身MS RPC算是DCE的一 种变体,把这些派生版算进去的话就要普适一些。)在1988年,Sun公 司起草并向互联网工程任务组(Internet Engineering Task Force, IETF)提交了RFC 1050规范,此规范中设计了一套面向广域网或混合 网络环境的、基于TCP/IP的、支持C语言的RPC协议,后被称为ONC RPC(Open Network Computing RPC,也被称为Sun RPC),这两套RPC 协议就算是如今各种RPC协议和框架的鼻祖了,从它们开始,直至接下 来这几十年所有流行过的RPC协议,都不外乎变着花样使用各种手段来 解决以下三个基本问题。
1.如何表示数据
这里的数据包括传递给方法的参数以及方法执行后的返回值。无 论是将参数传递给另外一个进程,还是从另外一个进程中取回执行结 果,都涉及数据表示问题。对于进程内的方法调用,使用程序语言预 置和程序员自定义的数据类型,就很容易解决数据表示问题;对于远 程方法调用,则完全可能面临交互双方各自使用不同程序语言的情 况,即使只支持一种程序语言的RPC协议,在不同硬件指令集、不同操 作系统下,同样的数据类型也完全可能有不一样的表现细节,譬如数 据宽度、字节序的差异等。有效的做法是将交互双方所涉及的数据转 换为某种事先约定好的中立数据流格式来进行传输,将数据流转换回 不同语言中对应的数据类型来使用。这个过程说起来拗口,但相信大 家一定很熟悉,就是序列化与反序列化。每种RPC协议都应该要有对应 的序列化协议,譬如:
·ONC RPC的外部数据表示(External Data Representation,
XDR)


·CORBA的通用数据表示(Common Data Representation,CDR)
·Java RMI的Java对象序列化流协议(Java Object Serialization
Stream Protocol)
·gRPC的Protocol Buffers
·Web Service的XML序列化
·众多轻量级RPC支持的JSON序列化
2.如何传递数据
如何传递数据,准确地说,是指如何通过网络,在两个服务的 Endpoint之间相互操作、交换数据。这里“交换数据”通常指的是应 用层协议,实际传输一般是基于TCP、UDP等标准的传输层协议来完成 的。两个服务交互不是只扔个序列化数据流来表示参数和结果就行, 许多在此之外的信息,譬如异常、超时、安全、认证、授权、事务 等,都可能产生双方需要交换信息的需求。在计算机科学中,专门有 一个名词“Wire Protocol”来表示这种两个Endpoint之间交换这类数 据的行为,常见的Wire Protocol如下。
·Java RMI的Java远程消息交换协议(Java Remote Message
Protocol,JRMP,也支持RMI-IIOP)
·CORBA的互联网ORB间协议(Internet Inter ORB Protocol,
IIOP,是GIOP协议在IP协议上的实现版本)
·DDS的实时发布订阅协议(Real Time Publish Subscribe
Protocol,RTPS)
·Web Service的简单对象访问协议(Simple Object Access
Protocol,SOAP)
·如果要求足够简单,双方都是HTTP Endpoint,直接使用HTTP
协议也是可以的(如JSON-RPC)


3.如何表示方法
确定表示方法在本地方法调用中并不是太大的问题,编译器或者 解释器会根据语言规范,将调用的方法签名转换为进程空间中子过程 入口位置的指针。不过一旦要考虑不同语言,事情又立刻麻烦起来, 每种语言的方法签名都可能有差别,所以“如何表示同一个方法” “如何找到对应的方法”还是需要一个统一的跨语言的标准才行。这 个标准可以非常简单,譬如直接给程序的每个方法都规定一个唯一 的、在任何机器上都绝不重复的编号,调用时压根不管它是什么方 法、签名是如何定义的,直接传这个编号就能找到对应的方法。这种 听起既粗鲁又寒碜的办法,还真的就是DCE/RPC当初准备的解决方案。 虽然最终DCE还是弄出了一套与语言无关的接口描述语言(Interface Description Language,IDL),成为此后许多RPC参考或依赖的基础 (如CORBA的OMG IDL),但那个唯一的绝不重复的编码方案 UUID(Universally Unique Identifier)也被保留且广为流传开来, 并被广泛应用于程序开发的方方面面。类似地,用于表示方法的协议 还有:
·Android的Android接口定义语言(Android Interface Definition
Language,AIDL)
·CORBA的OMG接口定义语言(OMG Interface Definition
Language,OMG IDL)
·Web Service的Web服务描述语言(Web Service Description
Language,WSDL)
·JSON-RPC的JSON Web服务协议(JSON Web Service Protocol,
JSON-WSP)
以上RPC中的三个基本问题,全部都可以在本地方法调用过程中找 到对应的解决方案。RPC的设计始于本地方法调用,尽管早已不再追求 实现与本地方法调用完全一致的目的,但其设计思路仍然带有本地方 法调用的深刻烙印,抓住两者间的联系来类比,对我们更深刻地理解 RPC的本质会很有帮助。


2.1.4 统一的RPC
虽然DEC/RPC与ONC RPC都有很浓厚的UNIX痕迹,但是它们并没有 真正在UNIX系统以外大规模流行过,而且它们还有一个“大问题”: 只支持传递值而不支持传递对象。尽管ONC RPC的XDR的序列化器能用 于序列化结构体,但结构体毕竟不是对象,这两种RPC协议都是面向C 语言设计的,根本就没有对象的概念。然而20世纪90年代正好又是面 向对象编程(Object-Oriented Programming,OOP)风头正盛的年 代,所以在1991年,对象管理组织(Object Management Group, OMG)发布了跨进程的、面向异构语言的、支持面向对象的服务调用协 议:CORBA 1.0(Common Object Request Broker Architecture)。 CORBA的1.0和1.1版本只提供了C、C++语言的支持,到了末代的CORBA 3.0版本,不仅支持C、C++、Java、Object Pascal、Python、Ruby等 多种主流编程语言,还支持Lisp、Smalltalk、Ada、COBOL等非主流语 言,阵营不可谓不强大。CORBA是一套由国际标准组织牵头,由多家软 件提供商共同参与制定的分布式规范,论影响力,当时只有微软私有 的DCOM能够与之稍微抗衡,但微软的DCOM与DCE一样,是受限于操作系 统的(尽管DCOM比DCE更强大些,能跨多语言),所以同时支持跨系 统、跨语言的CORBA原本是最有机会统一RPC这个领域的有力竞争者。
但无奈CORBA本身设计得实在太过于烦琐,甚至有些规定简直到了 荒谬的程度——写一个对象请求代理(ORB,这是CORBA中的核心概 念)大概要200行代码,其中大概有170行都是纯粹无用的废话——这 句话是CORBA的首席科学家Michi Henning在文章“The Rise and Fall
of CORBA”[1]中提出的愤怒批评。另一方面,为CORBA制定规范的专 家逐渐脱离实际,使得CORBA规范晦涩难懂,各家语言的厂商都有自己 的解读,导致CORBA实现互不兼容,实在是对CORBA号称支持众多异构 语言的莫大讽刺。这也间接导致稍后W3C Web Service出现后,CORBA 与Web Service竞争时犹如十八路诸侯讨伐董卓,互乱阵脚,一触即 溃,最终惨败。CORBA的最终归宿是与DCOM一同被扫进计算机历史的博 物馆中。
CORBA没有把握住统一RPC的大好时机,很快另外一个更有希望的 机会降临。1998年,XML 1.0发布,并成为万维网联盟(World Wide Web Consortium,W3C)的推荐标准。1999年末,SOAP 1.0(Simple


Object Access Protocol)规范的发布,标志着一种被称为“Web Service”的全新的RPC协议的诞生。Web Service是由微软和 DevelopMentor公司共同起草的远程服务协议,随后提交给W3C投票成 为国际标准,所以Web Service也被称为W3C Web Service。Web Service采用XML作为远程过程调用的序列化、接口描述、服务发现等 所有编码的载体,当时XML是计算机工业最新的银弹,只要是定义为 XML的东西几乎都被认为是好的,风头一时无两,连微软自己都主动宣 布放弃DCOM,迅速转投Web Service的怀抱。
交给W3C管理后,Web Service再没有天生属于哪家公司的烙印, 商业运作非常成功,大量的厂商都想分一杯羹。但从技术角度来看, 它设计得并不优秀,甚至同样可以说是有显著缺陷的。对于开发者而 言,Web Service的一大缺点是它过于严格的数据和接口定义所带来的 性能问题,尽管Web Service吸取了CORBA失败的教训,不需要程序员 手工编写对象的描述和服务代理,可是,XML作为一门描述性语言本身 信息密度就相对低下,(都不用与二进制协议比,与今天的JSON或 YAML比一下就知道了。)Web Service又是跨语言的RPC协议,这使得 一个简单的字段,为了在不同语言中不会产生歧义,要以XML严谨描述 的话,往往需要比原本存储这个字段值多出十几倍、几十倍乃至上百 倍的空间。这个特点一方面导致了使用Web Service必须要专门的客户 端去调用和解析SOAP内容,也需要专门的服务去部署(如Java中的 Apache Axis/CXF),更关键的是导致了每一次数据交互都包含大量的 冗余信息,性能奇差。
如果只是需要客户端,传输性能差也就算了,又不是不能用。既 然选择了XML,获得自描述能力,本来就没有打算把性能放到第一位, 但Web Service还有另外一个缺点:贪婪。“贪婪”是指它希望在一套 协议上一揽子解决分布式计算中可能遇到的所有问题,这促使Web Service生出了整个家族的协议——去网上搜索一下就知道这句话不是
拟人修辞[2]。Web Service协议家族中,除它本身包括的SOAP、 WSDL、UDDI协议外,还有一堆数不清的,以WS-*命名的,用于解决事 务、一致性、事件、通知、业务描述、安全、防重放等子功能的协 议,让开发者学习负担沉重。
当程序员们对Web Service的热情迅速兴起,又逐渐冷却之后,自 己也不禁开始反思:那些面向透明的、简单的RPC协议,如DCE/RPC、 DCOM、Java RMI,要么依赖于操作系统,要么依赖于特定语言,总有


一些先天约束;那些面向通用的、普适的RPC协议,如CORBA,就无法 逃过使用复杂性的困扰,CORBA烦琐的OMG IDL、ORB都是很好的佐证; 而那些意图通过技术手段来屏蔽复杂性的RPC协议,如Web Service, 又不免受到性能问题的束缚。简单、普适、高性能这三点,似乎真的 很难同时满足。
[1] 下载地址:https://dl.acm.org/doi/pdf/10.1145/1142031.1142044。
[2] 维 基 百 科 中 收 录 了 部 分 WS-* 的 子 协 议 :
https://en.wikipedia.org/wiki/List_of_web_service_specifications。


2.1.5 分裂的RPC
由于一直没有一个同时满足以上三点的“完美RPC协议”出现,所 以远程服务器调用这个小小的领域,逐渐进入群雄混战、百家争鸣的 战国时代,距离“统一”越来越远,并一直延续至今。现在,已经相 继出现过RMI(Sun/Oracle)、Thrift(Facebook/Apache)、 Dubbo(阿里巴巴/Apache)、gRPC(Google)、Motan1/2(新浪)、 Finagle(Twitter)、brpc(百度/Apache)、.NET Remoting(微 软)、Arvo(Hadoop)、JSON-RPC 2.0(公开规范,JSON-RPC工作 组)等难以穷举的协议和框架。这些RPC功能、特点不尽相同,有的是 某种语言私有,有的支持跨越多种语言,有的运行在应用层HTTP协议 之上,有的直接运行于传输层TCP/UDP协议之上,但并不存在哪一款是 “最完美的RPC”。今时今日,任何一款具有生命力的RPC框架,都不 再去追求大而全的“完美”,而是以某个具有针对性的特点作为主要 的发展方向,举例分析如下。
·朝着面向对象发展,不满足于RPC将面向过程的编码方式带到
分布式,希望在分布式系统中也能够进行跨进程的面向对象编程,代
表为RMI、.NET Remoting,之前的CORBA和DCOM也可以归入这类。
这种方式有一个别名叫作分布式对象(Distributed Object)。
·朝着性能发展,代表为gRPC和Thrift。决定RPC性能的主要因素
有两个:序列化效率和信息密度。序列化效率很好理解,序列化输出
结果的容量越小,速度越快,效率自然越高;信息密度则取决于协议
中有效负载(Payload)所占总传输数据的比例大小,使用传输协议的
层次越高,信息密度就越低,SOAP使用XML拙劣的性能表现就是前
车之鉴。gRPC和Thrift都有自己优秀的专有序列化器,而传输协议方
面,gRPC是基于HTTP/2的,支持多路复用和Header压缩,Thrift则直
接基于传输层的TCP协议来实现,省去了应用层协议的额外开销。
·朝着简化发展,代表为JSON-RPC,说要选功能最强、速度最快
的RPC可能会很有争议,但选功能弱的、速度慢的,JSON-RPC肯定会
是候选人之一。牺牲了功能和效率,换来的是协议的简单轻便,接口


与格式都更为通用,尤其适合用于Web浏览器这类一般不会有额外协
议支持、额外客户端支持的应用场合。
经历了RPC框架的“战国时代”,开发者们终于认可了不同的RPC 框架所提供的特性或多或少是有矛盾的,很难有某一种框架能满足所 有需求。若要朝着面向对象发展,就注定不会太简单,如建Stub、 Skeleton就很烦了,即使由IDL生成也很麻烦;功能多起来,协议就会 更复杂,效率一般也会受影响;要简单易用,那很多事情就必须遵循 约定而不是自行配置;要重视效率,那就需要采用二进制的序列化器 和较底层的传输协议,支持的语言范围容易受限。也正是每一种RPC框 架都有不完美的地方,所以才导致不断有新的RPC轮子出现,也决定了 在选择框架时,在获得一些利益的同时,要付出另外一些代价。
到了最近几年,RPC框架有明显向更高层次(不仅仅负责调用远程 服务,还管理远程服务)与插件化方向发展的趋势,不再追求独立地 解决RPC的全部三个问题(表示数据、传递数据、表示方法),而是将 一部分功能设计成扩展点,让用户自己选择。框架聚焦于提供核心 的、更高层次的能力,譬如提供负载均衡、服务注册、可观察性等方 面的支持。这一类框架的代表有Facebook的Thrift与阿里的Dubbo,尤 其是断更多年后重启的Dubbo表现得更为明显。Dubbo默认有自己的传 输协议(Dubbo协议),同时也支持其他协议;默认采用Hessian 2作 为序列化器,如果你有JSON的需求,可以替换为Fastjson,如果你对 性能有更高的追求,可以替换为Kryo、FST、Protocol Buffers等效率 更好的序列化器,如果你不想依赖其他组件库,也可以直接使用JDK自 带的序列化器。这种设计在一定程度上缓和了RPC框架必须取舍、难以 完美的缺憾。
最后,笔者提个问题,大家不妨来反思一下:开发一个分布式系 统,是不是就一定要用RPC呢?RPC的三大问题源自于对本地方法调用 的类比模拟,如果我们把思维从“方法调用”的约束中挣脱,那在解 决参数与结果如何表示、数据如何传递、方法如何表示这些问题时都 会有焕然一新的视角。但是我们写程序,真的可能不面向方法来编程 吗?这就是笔者下一节准备谈的话题了。
后记


前文提及DCOM、CORBA、Web Service的失败时,可能笔者的口
吻多少有一些戏谑,这只是落笔行文的方式。这些框架即使没有成
功,但作为早期的探索先驱,并没有什么该去讽刺的地方。而且它们
的后续发展,都称得上是知耻后勇,都值得我们赞赏。譬如说到
CORBA的消亡,OMG痛定思痛之后,提出了基于RTPS协议栈的“数
据分发服务”(Data Distribution Service,DDS)商业标准(就是要付
费使用的意思),如今主要流行于物联网领域,能够做到微秒级延
时,还能支持大规模并发通信。譬如说到DCOM的失败和Web Service
的式微,微软在它们的基础上推出的.NET WCF(Windows
Communication Foundation,Windows通信基础),不仅同时将REST、
TCP、SOAP等不同形式的调用自动封装为完全一致的如同本地方法调
用一般的程序接口,还依靠自家的“地表最强IDE”Visual Studio将工
作量减少到只需要指定一个远程服务地址,就可以获取服务描述、绑
定各种特性(譬如安全传输)、自动生成客户端调用代码,甚至还能
选择同步或者异步之类细节的程度。尽管.NET WCF只支持.NET平
台,而且与传统Web Service一样采用XML描述,但使用体验异常畅
快,能挽回Web Service中得罪开发者丢掉的全部印象分。


2.2 REST设计风格
很多人会拿REST与RPC相比较,其实,REST无论是在思想上、在概 念上,还是在使用范围上,与RPC都不尽相同,充其量只能算是有一些 相似,应用会有一部分重合之处,但本质上并不是同一类型的东西。
REST与RPC在思想上差异的核心是抽象的目标不一样,即面向过程 的编程思想与面向资源的编程思想两者之间的区别。面向过程编程、 面向对象编程想必大家都听说过,但什么是面向资源编程呢?这个问 题等介绍完REST的特征之后我们再细说。
REST与RPC在概念上的不同是指REST并不是一种远程服务调用协 议,甚至可以把定语也去掉,它就不是一种协议。协议都带有一定的 规范性和强制性,最起码也有一个规约文档,譬如JSON-RPC,哪怕再
简单,也有《JSON-RPC规范》[1]来规定协议的格式细节、异常、响应 码等信息,但是REST并没有定义这些内容,尽管有一些指导原则,但 实际上并不受任何强制的约束。常有人批评某个系统接口“设计得不 够RESTful”,其实这句话本身就有些争议,REST只能说是风格而不是 规范、协议,并且能完全符合REST所有指导原则的系统也是不多见 的,这一点我们同样将在后文中详细讨论。
至于使用范围,REST与RPC作为主流的两种远程调用方式,在使用 上确有重合,但重合区域的大小就见仁见智了。上一节提到了当前的 RPC协议框架都各有侧重点,并且列举了RPC的一些发展方向,如分布 式对象、提升调用效率、简化调用复杂性,等等。这里面分布式对象 的应用与REST可以说是毫无关联;而能够重视远程服务调用效率的应 用场景,就基本排除了REST应用得最多的供浏览器端消费的远程服 务,因为以浏览器作为前端,对于传输协议、序列化器的可选择性不 多,哪怕想要更高效率也有心无力。而在移动端、桌面端或者分布式 服务端的节点之间通信这一块,REST虽然有宽阔的用武之地,只要支 持HTTP就可以用于任何语言之间的交互,不过通常都会以网络没有成 为性能瓶颈为使用前提,在需要追求传输效率的场景里,REST提升传 输效率的潜力有限,死磕REST又想要好的网络性能,一般不会有好的 效果;对追求简化调用的场景——前面提到的浏览器端就属于这一类 的典型,众多RPC里也只有JSON-RPC有机会与REST竞争,其他RPC协议 与框架,哪怕能够支持HTTP协议,提供了JavaScript版本的客户端


(如gRPC-Web),也只是具备前端使用的理论可行性,很少有实际项 目把它们真正用到浏览器上。
尽管有着种种不同,REST与RPC还是引发了很频繁的比较与争论, 这两种分别面向资源和过程的远程调用方式,就如同当年面向对象与 过程的编程思想一样,非得分出高低不可。
[1] JSON-RPC 2.0规范地址:https://www.jsonrpc.org/specification。


2.2.1 理解REST
个人会有好恶偏爱,但计算机科学是务实的,有了RPC,还会提出 REST,有了面向过程编程之后还会产生面向资源编程,并引起广泛的 关注、使用和讨论,说明后者一定是有一些前者没有的闪光点,或者 解决、避免了一些前者的缺陷。我们不妨先去理解REST为什么会出 现,再来讨论评价它。
REST源于Roy Thomas Fielding在2000年发表的博士论文 “Architectural Styles and the Design of Network-based
Software Architectures”[1],此文的确是REST的源头,但我们不应 该忽略Fielding的身份和他此前的工作背景,这些信息对理解REST的 设计思想至关重要。
首先,Fielding是一名很优秀的软件工程师,他是Apache服务器 的核心开发者,后来成为著名的Apache软件基金会的联合创始人;同 时,Fielding也是HTTP 1.0协议(1996年发布)的专家组成员,后来 还晋升为HTTP 1.1协议(1999年发布)的负责人。HTTP 1.1协议设计 得极为成功,以至于在发布之后长达十年的时间里,都没有收到多少 修订的意见。用来指导HTTP 1.1协议设计的理论和思想,最初是以备 忘录的形式供专家组成员之间交流,除了IETF、W3C的专家外,并没有 在外界广泛流传。
从时间上看,对HTTP 1.1协议的设计工作贯穿了Fielding的整个 博士研究生涯,当起草HTTP 1.1协议的工作完成后,Fielding回到了 加州大学欧文分校继续攻读自己的博士学位。第二年,他更为系统、 严谨地阐述了这套理论框架,同时以这套理论框架导出了一种新的编 程思想,并为这种程序设计风格取了一个很多人难以理解,但是今天 已经广为人知的名字——REST(Representational State Transfer, 表征状态转移)。
哪怕对编程和网络都很熟悉的同学,也不太可能直接从名字弄明 白什么叫“表征”、什么东西的“状态”、从哪“转移”到哪。尽管
在论文中确有论述这些概念,但写得相当晦涩[2],所以笔者比较推荐 先理解什么是HTTP,再配合一些实际例子来对两者进行类比,以更清


楚地了解REST,你会发现REST实际上是“HTT”(Hypertext Transfer)的进一步抽象,两者的关系就如同接口与实现类的关系一 般。
HTTP中使用的“超文本”(Hypertext)一词是美国社会学家 Theodor Holm Nelson在1967年于“Brief Words on the Hypertext” 一文里提出的,下面引用的是他本人在1992年修正后的定义:
额外知识
现在,“超文本”一词已被普遍接受,它指的是能够进行分支判
断和差异响应的文本,相应地,“超媒体”一词指的是能够进行分支
判断和差异响应的图像、电影和声音(也包括文本)的复合体。
——Theodor Holm Nelson,Literary Machines,1992
以上定义描述的“超文本(或超媒体)”是一种“能够对操作进 行判断和响应的文本(或声音、图像等)”,这个概念在20世纪60年 代提出时应该还属于科幻的范畴,但是今天大众已经完全接受了它, 互联网中一段文字可以点击、可以触发脚本执行、可以调用服务端已 毫不稀奇。下面我们继续尝试从“超文本”或者“超媒体”的含义来 理解什么是“表征”以及REST中的其他关键概念,这里使用一个具体 事例将其描述如下。
·资源(Resource):譬如你现在正在阅读一篇名为《REST设计
风格》的文章,这篇文章的内容本身(你可以将其理解为蕴含的信
息、数据)称之为“资源”。无论你是通过阅读购买的图书、浏览器
上的网页还是打印出来的文稿,无论是在电脑屏幕上阅读还是在手机
上阅读,尽管呈现的样子各不相同,但其中的信息是不变的,你所阅
读的仍是同一份“资源”。
·表征(Representation):当你通过浏览器阅读此文章时,浏览
器会向服务端发出“我需要这个资源的HTML格式”的请求,服务端
向浏览器返回的这个HTML就被称为“表征”,你也可以通过其他方
式拿到本文的PDF、Markdown、RSS等其他形式的版本,它们同样是


一个资源的多种表征。可见“表征”是指信息与用户交互时的表示形
式,这与我们软件分层架构中常说的“表示层”(Presentation Layer)
的语义其实是一致的。
·状态(State):当你读完了这篇文章,想看后面是什么内容
时,你向服务端发出“给我下一篇文章”的请求。但是“下一篇”是
个相对概念,必须依赖“当前你正在阅读的文章是哪一篇”才能正确
回应,这类在特定语境中才能产生的上下文信息被称为“状态”。我
们所说的有状态(Stateful)抑或是无状态(Stateless),都是只相对于
服务端来说的,服务端要完成“取下一篇”的请求,要么自己记住用
户的状态,如这个用户现在阅读的是哪一篇文章,这称为有状态;要
么由客户端来记住状态,在请求的时候明确告诉服务端,如我正在阅
读某某文章,现在要读它的下一篇,这称为无状态。
·转移(Transfer):无论状态是由服务端还是由客户端来提供,
“取下一篇文章”这个行为逻辑只能由服务端来提供,因为只有服务
端拥有该资源及其表征形式。服务端通过某种方式,把“用户当前阅
读的文章”转变成“下一篇文章”,这就被称为“表征状态转移”。
通过“阅读文章”这个例子,相信你应该能够理解“表征状态转 移”的含义了。借着这个故事的上下文状态,笔者再继续介绍几个现 在不涉及但稍后要用到的概念。
·统一接口(Uniform Interface):上面说的服务端“通过某种方
式”让表征状态转移,那具体是什么方式呢?如果你真的是用浏览器
阅读本文电子版的话,请把本文滚动到结尾处,右下角有下一篇文章
的URI超链接地址,这是服务端渲染这篇文章时就预置好的,点击它
让页面跳转到下一篇,就是所谓“某种方式”的其中一种方式。任何
人都不会对点击超链接网页出现跳转感到奇怪,但你细想一下,URI
的含义是统一资源标识符,是一个名词,如何能表达出“转移”动作
的含义呢?答案是HTTP协议中已经提前约定好了一套“统一接
口”,它包括GET、HEAD、POST、PUT、DELETE、TRACE、
OPTIONS七种基本操作,任何一个支持HTTP协议的服务器都会遵守


这套规定,对特定的URI采取这些操作,服务器就会触发相应的表征
状态转移。
·超文本驱动(Hypertext Driven):尽管表征状态转移是由浏览
器主动向服务器发出请求所引发的,该请求导致了“在浏览器屏幕上
显示出了下一篇文章的内容”的结果。但是,我们都清楚这不可能真
的是浏览器的主动意图,浏览器是根据用户输入的URI地址来找到网
站首页,读取服务器给予的首页超文本内容后,浏览器再通过超文本
内部的链接来导航到这篇文章,阅读结束时,也是通过超文本内部的
链接再导航到下一篇。浏览器作为所有网站的通用的客户端,任何网
站的导航(状态转移)行为都不可能是预置于浏览器代码之中,而是
由服务器发出的请求响应信息(超文本)来驱动的。这点与其他带有
客户端的软件有十分本质的区别,在那些软件中,业务逻辑往往是预
置于程序代码之中的,有专门的页面控制器(无论在服务端还是在客
户端中)来驱动页面的状态转移。
·自描述消息(Self-Descriptive Message):由于资源的表征可能
存在多种不同形态,在消息中应当有明确的信息来告知客户端该消息
的类型以及应如何处理这条消息。一种被广泛采用的自描述方法是在
名为“Content-Type”的HTTP Header中标识出互联网媒体类型
(MIME type),譬如“Content-Type:application/json;charset=utf-8”说
明该资源会以JSON的格式来返回,请使用UTF-8字符集进行处理。
除了以上列出的这些概念外,在理解REST的过程中,还有一个常 见的误区值得注意:Fielding提出REST时所谈论的范围是“架构风格 与网络的软件架构设计”(Architectural Styles and Design of Network-based Software Architecture),而不是现在被人们所狭义 理解的一种“远程服务设计风格”,这两者的范围差别就好比本书所 谈论的话题“软件架构”与本章谈论话题“访问远程服务”的关系那 样,前者是后者的一个很大的超集,尽管基于本节的主题和多数人的 关注点考虑,我们确实会以“远程服务设计风格”作为讨论的重点, 但至少应该说清楚它们范围上的差别。
[1] 下 载 地 址 :
https://www.ics.uci.edu/~fielding/pubs/dissertation/top.htm。


[2] 不 想 读 英 文 的 同 学 从 此 处 获 得 中 文 翻 译 版 本 :
https://www.infoq.cn/article/2007/07/dlee-fielding-rest/。


2.2.2 RESTful的系统
如果你已经理解了上面这些概念,我们就可以开始讨论面向资源 的编程思想与Fielding所提出的几个具体的软件架构设计原则了。 Fielding认为,一套理想的、完全满足REST风格的系统应该满足以下 六大原则。
1.客户端与服务端分离(Client-Server)
将用户界面所关注的逻辑和数据存储所关注的逻辑分离开来,有 助于提高用户界面的跨平台的可移植性,也越来越受到广大开发者所 认可,以前完全基于服务端控制和渲染(如JSF这类)框架的实际用户 已甚少,而在服务端进行界面控制(Controller),通过服务端或者 客户端的模板渲染引擎来进行界面渲染的框架(如Struts、SpringMVC 这类)也受到了颇大冲击。这一点与REST可能关系并不大,前端技术 (从ES规范,到语言实现,再到前端框架等)在近年来的高速发展, 使得前端表达能力大幅度加强才是真正的幕后推手。由于前端的日渐 强势,现在还流行起由前端代码反过来驱动服务端进行渲染的 SSR(Server-Side Rendering)技术,在Serverless、SEO等场景中已 经占领了一席之地。
2.无状态(Stateless)
无状态是REST的一条核心原则,部分开发者在做服务接口规划 时,觉得REST风格的服务怎么设计都感觉别扭,很可能的一个原因是 服务端持有比较重的状态。REST希望服务端不用负责维护状态,每一 次从客户端发送的请求中,应包括所有必要的上下文信息,会话信息 也由客户端负责保存维护,服务端只依据客户端传递的状态来执行业 务处理逻辑,驱动整个应用的状态变迁。客户端承担状态维护职责以 后,会产生一些新的问题,譬如身份认证、授权等可信问题,它们都
应有针对性的解决方案[1]。
但必须承认的是,目前大多数系统都达不到这个要求,且越复 杂、越大型的系统越是如此。服务端无状态可以在分布式计算中获得 非常高价值的回报,但大型系统的上下文状态数量完全可能膨胀到客


户端无法承受的程度,在服务端的内存、会话、数据库或者缓存等地 方持有一定的状态成为一种事实上存在,并将长期存在、被广泛使用 的主流方案。
3.可缓存(Cacheability)
无状态服务虽然提升了系统的可见性、可靠性和可伸缩性,但降 低了系统的网络性。“降低网络性”的通俗解释是某个功能使用有状 态的设计时只需要一次(或少量)请求就能完成,使用无状态的设计 时则可能会需要多次请求,或者在请求中带有额外冗余的信息。为了 缓解这个矛盾,REST希望软件系统能够如同万维网一样,允许客户端 和中间的通信传递者(譬如代理)将部分服务端的应答缓存起来。当 然,为了缓存能够正确地运作,服务端的应答中必须直接或者间接地 表明本身是否可以进行缓存、可以缓存多长时间,以避免客户端在将 来进行请求的时候得到过时的数据。运作良好的缓存机制可以减少客 户端、服务端之间的交互,甚至有些场景中可以完全避免交互,这就 进一步提高了性能。
4.分层系统(Layered System)
这里所指的分层并不是表示层、服务层、持久层这种意义上的分 层,而是指客户端一般不需要知道是否直接连接到了最终的服务器, 抑或连接到路径上的中间服务器。中间服务器可以通过负载均衡和共 享缓存的机制提高系统的可扩展性,这样也便于缓存、伸缩和安全策 略的部署。该原则的典型应用是内容分发网络(Content Distribution Network,CDN)。如果你是通过网站浏览到这篇文章的 话,你所发出的请求一般(假设你在中国境内的话)并不是直接访问 位于GitHub Pages的源服务器,而是访问了位于国内的CDN服务器,但 作为用户,你完全不需要感知到这一点。我们将在第4章讨论如何构建 自动、可缓存的分层系统。
5.统一接口(Uniform Interface)
这是REST的另一条核心原则,REST希望开发者面向资源编程,希 望软件系统设计的重点放在抽象系统该有哪些资源,而不是抽象系统 该有哪些行为(服务)上。这条原则你可以类比计算机中对文件管理 的操作来理解,管理文件可能会涉及创建、修改、删除、移动等操 作,这些操作数量是可数的,而且对所有文件都是固定、统一的。如


果面向资源来设计系统,同样会具有类似的操作特征,由于REST并没 有设计新的协议,所以这些操作都借用了HTTP协议中固有的操作命令 来完成。
统一接口也是REST最容易陷入争论的地方,基于网络的软件系 统,到底是面向资源合适,还是面向服务更合适,这个问题恐怕在很 长时间里都不会有定论,也许永远都没有。但是,已经有一个基本清 晰的结论是:面向资源编程的抽象程度通常更高。抽象程度高带来的 坏处是距离人类的思维方式往往会更远,而好处是通用程度往往会更 好。用这样的语言去诠释REST,还是有些抽象,下面以一个例子来说 明:譬如,对于几乎每个系统都有的登录和注销功能,如果你理解成 登录对应于login()服务,注销对应于logout()服务这样两个独立服 务,这是“符合人类思维”的;如果你理解成登录是PUT Session,注 销是DELETE Session,这样你只需要设计一种“Session资源”即可满 足需求,甚至以后对Session的其他需求,如查询登录用户的信息,就 是GET Session而已,其他操作如修改用户信息等也都可以被这同一套 设计囊括在内,这便是“抽象程度更高”带来的好处。
如果想要在架构设计中合理恰当地利用统一接口,Fielding建议 系统应能做到每次请求中都包含资源的ID,所有操作均通过资源ID来 进行;建议每个资源都应该是自描述的消息;建议通过超文本来驱动 应用状态的转移。
6.按需代码(Code-On-Demand)
按需代码被Fielding列为一条可选原则。它是指任何按照客户端 (譬如浏览器)的请求,将可执行的软件程序从服务端发送到客户端 的技术。按需代码赋予了客户端无须事先知道所有来自服务端的信息 应该如何处理、如何运行的宽容度。举个具体例子,以前的Java Applet技术,今天的WebAssembly等都属于典型的按需代码,蕴含着具 体执行逻辑的代码是存放在服务端,只有当客户端请求了某个Java Applet之后,代码才会被传输并在客户端机器中运行,结束后通常也 会随即在客户端中被销毁。将按需代码列为可选原则的原因并非是它 特别难以达到,更多是出于必要性和性价比的实际考虑。
至此,REST中的主要概念与思想原则已经介绍完毕,我们再回过 头来讨论本节开篇提出的REST与RPC在思想上的差异。REST的基本思想 是面向资源来抽象问题,它与此前流行的编程思想——面向过程的编


程在抽象主体上有本质的差别。在REST提出以前,人们设计分布式系 统服务的唯一方案就只有RPC,RPC是将本地的方法调用思路迁移到远 程方法调用上,开发者是围绕“远程方法”去设计两个系统间交互 的,譬如CORBA、RMI、DCOM,等等。这样做的坏处不仅使“如何在异 构系统间表示一个方法”“如何获得接口能够提供的方法清单”成为 需要专门协议去解决的问题(RPC的三大基本问题之一),而且对于服 务使用者来说,由于服务的每个方法都是完全独立的,他们必须逐个 学习才能正确地使用这些方法。Google在“Google API Design
Guide”[2]中曾经写下这样一段话。
额外知识
以前,人们面向方法去设计RPC API,譬如CORBA和DCOM,随
着时间推移,接口与方法越来越多却又各不相同,开发人员必须了解
每一个方法才能正确使用它们,这样既耗时又容易出错。
——Google API Deign Guide,2017
REST提出以资源为主体的服务设计风格,可以带来不少好处。 (自然也有坏处,笔者将在下一节集中谈论REST的不足与争议。)
·降低服务接口的学习成本。统一接口是REST的重要标志,它将
对资源的标准操作都映射到标准的HTTP方法上去,这些方法对于每
个资源的用法都是一致的,语义都是类似的,不需要刻意去学习,更
不需要有诸如IDL之类的协议存在。
·资源天然具有集合与层次结构。以方法为中心抽象的接口,由
于方法是动词,逻辑上决定了每个接口都是互相独立的;但以资源为
中心抽象的接口,由于资源是名词,天然就可以产生集合与层次结
构。举个具体例子,假设一个商城用户中心的接口设计:用户资源会
拥有多个不同的下级的资源,譬如若干条短消息资源、一份用户资料
资源、一辆购物车资源,购物车中又会有自己的下级资源,譬如多本
图书资源。你很容易在程序接口中构造出这些资源的集合关系与层次
关系,而且这些关系是符合人们长期在单机或网络环境中管理数据的


经验的。相信你不需要专门阅读接口说明书,就能轻易推断出获取用
户icyfenix的购物车中的第2本书的REST接口应该表示为:
GET /users/icyfenix/cart/2
·REST绑定于HTTP协议。面向资源编程不是必须构筑在HTTP之
上,但REST是,这是缺点,也是优点。因为HTTP本来就是面向资源
设计的网络协议,纯粹只用HTTP(而不是SOAP over HTTP那样再构
筑协议)带来的好处是无须考虑RPC中的Wire Protocol问题,REST将
复用HTTP协议中已经定义的概念和相关基础支持来解决问题。HTTP
协议已经有效运作了三十年,其相关的技术基础设施已是千锤百炼,
无比成熟。而坏处自然是,当你想去考虑那些HTTP不提供的特性
时,便会彻底束手无策。
以上列举了一些面向资源编程的优点,但笔者并非要证明它比面 向过程、面向对象编程更优秀,是否选用REST的API设计风格,需要结 合你的需求场景、你团队的设计和开发人员是否能够适应面向资源的 思想来设计软件来权衡。在互联网中,面向资源进行网络传输是这三 十年来HTTP协议精心培养出来的用户习惯,如果开发者能够适应REST 这种不太符合人类思维习惯的抽象方式,使用REST匹配在HTTP基础上 构建的互联网,相信在效率与扩展性方面会有可观的收益。
[1] 这部分内容可参见本书第5章。
[2] 地址:https://cloud.google.com/apis/design。


2.2.3 RMM
前面我们花费大量篇幅讨论了REST的思想、概念和指导原则等理 论方面的内容,在本节中,我们将把重心放在实践上,把目光从整个 软件架构设计进一步聚焦到REST接口设计上,以切合2.2节的标题,也 顺带填了前面埋下的“如何评价服务是否RESTful”的坑。
RESTful Web APIs和RESTful Web Services的作者Leonard Richardson曾提出一个衡量“服务有多么REST”的Richardson成熟度 模型(Richardson Maturity Model,RMM),以便让那些原本不使用 REST的系统,能够逐步地导入REST。Richardson将服务接口“REST的 程度”从低到高,分为0至3级。
·第0级(The Swamp of Plain Old XML):完全不REST。
·第1级(Resources):开始引入资源的概念。
·第2级(HTTP Verbs):引入统一接口,映射到HTTP协议的方
法上。
·第3级(Hypermedia Controls):超媒体控制,在本文里面的说
法是“超文本驱动”,在Fielding论文里的说法是“Hypertext As The
Engine Of Application State,HATEOAS”,其实都是指同一件事情。
下面笔者借用Martin Fowler撰写的关于RMM的文章中的实际例子 (原文是XML写的,这里简化为JSON表示),来具体展示一下四种不同 程度的REST反映到实际接口中会是怎样的。假设你是一名软件工程 师,接到的需求(原文中的需求复杂一些,这里简化了)描述是这样 的:
医生预约系统
作为一名病人,我想要从系统中得知指定日期内我熟悉的医生是
否具有空闲时间,以便于我向该医生预约就诊。


第0级
医院开放了一个/appointmentService的Web API,传入日期、医 生姓名等参数,可以得到该时间段内该名医生的空闲时间,该API的一 次HTTP调用如下所示:
POST /appointmentService?action=query HTTP/1.1
{date: "2020-03-04", doctor: "mjones"}
然后服务器会传回一个包含了所需信息的回应:
HTTP/1.1 200 OK
[
{start:"14:00", end: "14:50", doctor: "mjones"}, {start:"16:00", end: "16:50", doctor: "mjones"} ]
得到了医生空闲的结果后,笔者觉得14:00比较合适,于是进行预 约确认,并提交了个人基本信息:
POST /appointmentService?action=comfirm HTTP/1.1
{
appointment: {date: "2020-03-04", start:"14:00", doctor: "mjones"}, patient: {name: icyfenix, age: 30, ......} }
如果预约成功,那我能够收到一个预约成功的响应:
HTTP/1.1 200 OK
{
code: 0, message: "Successful confirmation of appointment" }
如果出现问题,譬如有人在我前面抢先预约了,那么我会在响应 中收到某种错误消息:


HTTP/1.1 200 OK
{
code: 1 message: "doctor not available" }
至此,整个预约服务宣告完成,直接明了,我们采用的是非常直 观的基于RPC风格的服务设计,似乎很容易就解决了所有问题,但真的 是这样吗?
第1级
第0级是RPC的风格,如果需求永远不会变化,那它完全可以良好 地工作下去。但是,如果你不想为预约医生之外的其他操作、为获取 空闲时间之外的其他信息去编写额外的方法,或者改动现有方法的接 口,那还是应该考虑一下如何使用REST来抽象资源。
通往REST的第一步是引入资源的概念,在API中的基本体现是围绕 资源而不是过程来设计服务,说得直白一点,可以理解为服务的 Endpoint应该是一个名词而不是动词。此外,每次请求中都应包含资 源的ID,所有操作均通过资源ID来进行,譬如,获取医生指定时间的 空闲档期:
POST /doctors/mjones HTTP/1.1
{date: "2020-03-04"}
然后服务器传回一组包含了ID信息的档期清单,注意,ID是资源 的唯一编号,有ID即代表“医生的档期”被视为一种资源:
HTTP/1.1 200 OK
[
{id: 1234, start:"14:00", end: "14:50", doctor: "mjones"}, {id: 5678, start:"16:00", end: "16:50", doctor: "mjones"} ]


笔者还是觉得14:00的时间比较合适,于是又进行预约确认,并提 交了个人基本信息:
POST /schedules/1234 HTTP/1.1
{name: icyfenix, age: 30, ......}
后面预约成功或者失败的响应消息在这个级别里面与之前一致, 就不重复了。比起第0级,第1级的特征是引入了资源,通过资源ID作 为主要线索与服务交互,但第1级至少还有三个问题没有解决:一是只 处理了查询和预约,如果临时想换个时间,要调整预约,或者病忽然 好了,想删除预约,这都需要提供新的服务接口;二是处理结果响应 时,只能依靠结果中的code、message这些字段做分支判断,每一套服 务都要设计可能发生错误的code,这很难考虑全面,而且也不利于对 某些通用的错误做统一处理;三是没有考虑认证授权等安全方面的内 容,譬如要求只有登录用户才允许查询医生档期时间,某些医生可能 只对VIP开放,需要特定级别的病人才能预约,等等。
第2级
第1级遗留的三个问题都可以通过引入统一接口来解决。HTTP协议 的七个标准方法是经过精心设计的,只要架构师的抽象能力够用,它 们几乎能涵盖资源可能遇到的所有操作场景。REST的具体做法是:把 不同业务需求抽象为对资源的增加、修改、删除等操作来解决第一个 问题;使用HTTP协议的Status Code,它可以涵盖大多数资源操作可能 出现的异常,也可以自定义扩展,以此解决第二个问题;依靠HTTP Header中携带的额外认证、授权信息来解决第三个问题,这个在实战 中并没有体现,后文会在5.3节中介绍相关内容。
按这个思路,获取医生档期,应采用具有查询语义的GET操作进 行:
GET /doctors/mjones/schedule?date=2020-03-04&status=open HTTP/1.1
然后服务器会传回一个包含了所需信息的回应:


HTTP/1.1 200 OK
[
{id: 1234, start:"14:00", end: "14:50", doctor: "mjones"}, {id: 5678, start:"16:00", end: "16:50", doctor: "mjones"} ]
笔者仍然觉得14:00的时间比较合适,于是进行预约确认,并提交 了个人基本信息,用以创建预约,这是符合POST的语义的:
POST /schedules/1234 HTTP/1.1
{name: icyfenix, age: 30, ......}
如果预约成功,那笔者能够收到一个预约成功的响应:
HTTP/1.1 201 Created
Successful confirmation of appointment
如果出现问题,譬如有人抢先预约了,那么笔者会在响应中收到 某种错误消息:
HTTP/1.1 409 Conflict
doctor not available
第3级
第2级是目前绝大多数系统所到达的REST级别,但仍不是完美的, 至少还存在一个问题:你是如何知道预约mjones医生的档期是需要访 问“/schedules/1234”这个服务Endpoint的?也许你第一时间甚至无 法理解为何我会有这样的疑问,这当然是程序代码写的呀!但REST并 不认同这种已烙在程序员脑海中许久的想法。RMM中的超文本控制、 Fielding论文中的HATEOAS和现在提的比较多的“超文本驱动”,所希 望的是除了第一个请求是由你在浏览器地址栏输入驱动之外,其他的 请求都应该能够自己描述清楚后续可能发生的状态转移,由超文本自 身来驱动。所以,当你输入了查询的指令之后:


GET /doctors/mjones/schedule?date=2020-03-04&status=open HTTP/1.1
服务器传回的响应信息应该包括诸如如何预约档期、如何了解医 生信息等可能的后续操作:
HTTP/1.1 200 OK
{
schedules:[ {
id: 1234, start:"14:00", end: "14:50", doctor: "mjones", links: [ {rel: "comfirm schedule", href: "/schedules/1234"} ] }, {
id: 5678, start:"16:00", end: "16:50", doctor: "mjones", links: [ {rel: "comfirm schedule", href: "/schedules/5678"} ] } ], links: [ {rel: "doctor info", href: "/doctors/mjones/info"} ] }
如果做到了第3级REST,那服务端的API和客户端也是完全解耦 的,此时如果你要调整服务数量,或者对同一个服务做API升级时将会 变得非常简单。


2.2.4 不足与争议
以下是笔者所见过的关于REST能否在实践中真正良好应用的部分 争议问题,笔者将自己的观点总结如下。
1)面向资源的编程思想只适合做CRUD,面向过程、面向对象编程 才能处理真正复杂的业务逻辑。
这是遇到最多的一个问题。HTTP的四个最基础的命令POST、GET、 PUT和DELETE很容易让人直接联想到CRUD操作,以至于在脑海中自然产 生了直接的对应。REST所能涵盖的范围当然远不止于此,不过要说 POST、GET、PUT和DELETE对应于CRUD其实也没什么不对,只是这个 CRUD必须泛化去理解。这些命令涵盖了信息在客户端与服务端之间流 动的几种主要方式,所有基于网络的操作逻辑,都可以对应到信息在 服务端与客户端之间如何流动来理解,有的场景比较直观,而有的场 景则可能比较抽象。
针对那些比较抽象的场景,如果真不能把HTTP方法映射为资源的 所需操作,REST也并非刻板的教条,用户是可以使用自定义方法的, 按Google推荐的REST API风格,自定义方法应该放在资源路径末尾, 嵌入冒号加自定义动词的后缀。譬如,可以把删除操作映射到标准 DELETE方法上,如果还要提供一个恢复删除的API,那它可能会被设计 为:
POST /user/user_id/cart/book_id:undelete
如果你不想使用自定义方法,那就设计一个回收站的资源,在那 里保留还能被恢复的商品,将恢复删除视为对该资源某个状态值的修 改,映射到PUT或者PATCH方法上,这也是一种完全可行的设计。
最后,笔者再重复一遍,面向资源的编程思想与另外两种主流编 程思想只是抽象问题时所处的立场不同,只有选择不同,没有高下之 分。


·面向过程编程时,为什么要以算法和处理过程为中心,输入数
据,输出结果?当然是为了符合计算机世界中主流的交互方式。
·面向对象编程时,为什么要将数据和行为统一起来、封装成对
象?当然是为了符合现实世界的主流的交互方式。
·面向资源编程时,为什么要将数据(资源)作为抽象的主体,
把行为看作统一的接口?当然是为了符合网络世界的主流的交互方
式。
2)REST与HTTP完全绑定,不适合应用于要求高性能传输的场景 中。
笔者很大程度上赞同此观点,但并不认为这是REST的缺陷,正如 锤子不能当扳手用并不是锤子的质量有问题。面向资源编程与协议无 关,但是REST(特指Fielding论文中所定义的REST,而不是泛指面向 资源的思想)的确依赖着HTTP协议的标准方法、状态码、协议头等各 个方面。HTTP并不是传输层协议,它是应用层协议,如果仅将HTTP用 于传输是不恰当的。对于需要直接控制传输,如二进制细节、编码形 式、报文格式、连接方式等细节的场景,REST确实不合适,这些场景 往往存在于服务集群的内部节点之间,这也是之前笔者曾提及的, REST和RPC尽管应用确有所重合,但重合范围的大小就是见仁见智的事 情。
3)REST不利于事务支持。
这个问题首先要看你怎么看待“事务(Transaction)”这个概 念。如果“事务”指的是数据库那种狭义的刚性ACID事务,那除非完 全不持有状态,否则分布式系统本身与此就是有矛盾的(CAP不可兼 得),这是分布式的问题而不是REST的问题。如果“事务”是指通过 服务协议或架构,在分布式服务中,获得对多个数据同时提交的统一 协调能力(2PC/3PC),譬如WS-AtomicTransaction、WSCoordination这样的功能性协议,REST是不支持的,假如你理解了这 样做的代价,仍坚持要这样做的话,Web Service是比较好的选择。如 果“事务”只是指希望保障数据的最终一致性,说明你已经放弃刚性 事务了,这才是分布式系统中的正常交互方式,使用REST肯定不会有


什么阻碍,更谈不上“不利于”。当然,对此REST也并没有什么帮 助,这完全取决于你的系统的事务设计,我们在第3章中再详细讨论。
4)REST没有传输可靠性支持。
是的,并没有。在HTTP中发送一个请求,你通常会收到一个与之 相对的响应,譬如HTTP/1.1 200 OK或者HTTP/1.1 404 Not Found等。 但如果你没有收到任何响应,那就无法确定消息是没有发送出去,抑 或是没有从服务端返回,这其中的关键差别是服务端是否被触发了某 些处理?应对传输可靠性最简单粗暴的做法是把消息再重发一遍。这 种简单处理能够成立的前提是服务应具有幂等性(Idempotency),即 服务被重复执行多次的效果与执行一次是相等的。HTTP协议要求GET、 PUT和DELETE应具有幂等性,我们把REST服务映射到这些方法时,也应 当保证幂等性。对于POST方法,曾经有过一些专门的提案,如 POE(POST Once Exactly),但并未得到IETF的认可。对于POST的重 复提交,浏览器会出现相应警告,如Chrome中“确认重新提交表单” 的提示,对于服务端,就应该做预校验,如果发现可能重复,则返回 HTTP/1.1 425 Too Early。另外,Web Service中有WSReliableMessaging功能协议用于支持消息可靠投递。类似的,由于 REST没有采用额外的Wire Protocol,所以除了事务、可靠传输这些功 能以外,一定还可以在WS-*协议中找到很多REST不支持的特性。
5)REST缺乏对资源进行“部分”和“批量”处理的能力。
这个观点笔者是认同的,这很可能是未来面向资源的思想和API设 计风格的发展方向。REST开创了面向资源的服务风格,但它并不完 美。以HTTP协议为基础给REST带来了极大的便捷(不需要额外协议, 不需要重复解决一堆基础网络问题,等等),但也使HTTP本身成了束 缚REST的无形牢笼。这里仍通过具体例子来解释REST这方面的局限 性。譬如你仅仅想获得某个用户的姓名,如果是RPC风格,可以设计一 个“getUsernameById”的服务,返回一个字符串,尽管这种服务的通 用性实在称不上“设计”二字,但确实可以工作;而如果是REST风 格,你将向服务端请求整个用户对象,然后丢弃掉返回结果中该用户 除用户名外的其他属性,这便是一种过度获取(Overfetching)。 REST的应对手段是通过位于中间节点或客户端的缓存来解决这种问 题,但此缺陷的本质是由于HTTP协议完全没有对请求资源的结构化描 述能力(但有非结构化的部分内容获取能力,即今天多用于断点续传 的Range Header),所以返回资源的哪些内容、以什么数据类型返回


等,都不可能得到协议层面的支持,要做就只能自己在GET方法的 Endpoint上设计各种参数来实现。另外一方面,与此相对的缺陷是对 资源的批量操作的支持,有时候我们不得不为此而专门设计一些抽象 的资源才能应对。譬如你准备给某个用户的名字增加一个“VIP”前 缀,提交一个PUT请求修改这个用户的名称即可,而你要给1000个用户 加VIP前缀时,如果真的去调用1000次PUT,浏览器会回应HTTP/1.1 429 Too Many Requests。此时,你就不得不先创建一个任务资源(如 名为“VIP-Modify-Task”),把1000个用户的ID交给这个任务,然后 驱动任务进入执行状态。又譬如你去网店买东西,下单、冻结库存、 支付、加积分、扣减库存这一系列步骤会涉及多个资源的变化,你可 能面临不得不创建一种“事务”的抽象资源,或者用某种具体的资源 (譬如“结算单”)贯穿这个过程的始终,每次操作其他资源时都带 着事务或者结算单的ID。HTTP协议由于本身的无状态性,会相对不适 合(并非不能够)处理这类业务场景。
目前,一种理论上较优秀的可以解决以上这几类问题的方案是 GraphQL,它是由Facebook提出并开源的一种面向资源API的数据查询 语言,如同SQL一样,挂了个“查询语言”的名字,但其实CRUD都做。 比起依赖HTTP无协议的REST,GraphQL可以说是另一种有协议的、更彻 底地面向资源的服务方式。然而凡事都有两面性,离开了HTTP,它又 面临几乎所有RPC框架所遇到的那个如何推广交互接口的问题。


第3章 事务处理
事务处理几乎在每一个信息系统中都会涉及,它存在的意义是为 了保证系统中所有的数据都是符合期望的,且相互关联的数据之间不 会产生矛盾,即数据状态的一致性(Consistency)。按照数据库的经 典理论,要达成这个目标,需要三方面共同努力来保障。
·原子性(Atomic):在同一项业务处理过程中,事务保证了对
多个数据的修改,要么同时成功,要么同时被撤销。
·隔离性(Isolation):在不同的业务处理过程中,事务保证了各
业务正在读、写的数据相互独立,不会彼此影响。
·持久性(Durability):事务应当保证所有成功被提交的数据修
改都能够正确地被持久化,不丢失数据。
以上四种属性即事务的“ACID”特性,但笔者对这种说法其实不 太认同,因为这四种特性并不正交,A、I、D是手段,C是目的,前者 是因,后者是果,弄到一块去完全是为了拼凑个单词缩写。
事务的概念虽然最初起源于数据库系统,但今天已经有所延伸, 不再局限于数据库本身了。所有需要保证数据一致性的应用场景,包 括但不限于数据库、事务内存、缓存、消息队列、分布式存储,等 等,都有可能用到事务,后文里笔者会使用“数据源”来泛指所有这 些场景中提供与存储数据的逻辑设备,但是上述场景所说的事务和一 致性含义可能并不完全一致,说明如下。
·当一个服务只使用一个数据源时,通过A、I、D来获得一致性
是最经典的做法,也是相对容易的。此时,多个并发事务所读写的数
据能够被数据源感知是否存在冲突,并发事务的读写在时间线上的最
终顺序是由数据源来确定的,这种事务间一致性被称为“内部一致
性”。
·当一个服务使用到多个不同的数据源,甚至多个不同服务同时
涉及多个不同的数据源时,问题就变得困难了许多。此时,并发执行


甚至是先后执行的多个事务,在时间线上的顺序并不由任何一个数据
源来决定,这种涉及多个数据源的事务间一致性被称为“外部一致
性”[1]。
外部一致性问题通常很难使用A、I、D来解决,因为这样需要付出 很大甚至不切实际的代价;但是外部一致性又是分布式系统中必然会 遇到且必须要解决的问题,为此我们要转变观念,将一致性从“是或 否”的二元属性转变为可以按不同强度分开讨论的多元属性,在确保 代价可承受的前提下获得强度尽可能高的一致性保障,也正因如此, 事务处理才从一个具体操作上的“编程问题”上升成一个需要全局权 衡的“架构问题”。
人们在探索这些解决方案的过程中,产生了许多新的思路和概 念,有一些概念看上去并不那么直观,在本章,笔者会通过同一个场 景事例讲解如何在不同的事务方案中贯穿、理顺这些概念。
额外知识
场景事例
Fenix’s Bookstore是一个在线书店。当一本书被成功售出时,需
要确保以下三件事情被正确地处理:
·用户的账号扣减相应的商品款项;
·商品仓库中扣减库存,将商品标识为待配送状态;
·商家的账号增加相应的商品款项。
接下来,笔者将逐一介绍在“单个服务使用单个数据源”“单个 服务使用多个数据源”“多个服务使用单个数据源”以及“多个服务 使用多个数据源”下,可以采用哪些手段来保证数据在以上场景中被 正确地读写。
[1] 外 部 一 致 性 的 定 义 起 源 于 Google 的 Spanner 的 论 文 , 地 址 为
https://cloud.google.com/spanner/docs/true-time-external-consistency。


3.1 本地事务
本地事务(Local Transaction)其实应该翻译成“局部事务”才 好与稍后的“全局事务”相对应,不过现在“本地事务”的译法似乎 已经成为主流,这里也就不去纠结名称了。本地事务是指仅操作单一 事务资源的、不需要全局事务管理器进行协调的事务。在没有介绍什 么是“全局事务管理器”前,很难从概念入手去讲解“本地事务”, 所以这里先暂且将概念放下,等读完3.2节后再来对比理解。
本地事务是一种最基础的事务解决方案,只适用于单个服务使用 单个数据源的场景。从应用角度看,它是直接依赖于数据源本身提供 的事务能力来工作的,在程序代码层面,最多只能对事务接口做一层 标准化的包装(如JDBC接口),并不能深入参与到事务的运作过程 中,事务的开启、终止、提交、回滚、嵌套、设置隔离级别,乃至与 应用代码贴近的事务传播方式,全部都要依赖底层数据源的支持才能 工作,这一点与后续介绍的XA、TCC、SAGA等主要靠应用程序代码来实 现的事务有着十分明显的区别。举个例子,假设你的代码调用了JDBC 中的Transaction::rollback()方法,方法的成功执行也并不一定代表 事务就已经被成功回滚,如果数据表采用的引擎是MyISAM,那 rollback()方法便是一项没有意义的空操作。因此,我们要想深入讨 论本地事务,便不得不越过应用代码的层次,去了解一些数据库本身 的事务实现原理,弄明白传统数据库管理系统是如何通过ACID来实现 事务的。
如今研究事务的实现原理,必定会追溯到ARIES理论[1] (Algorithms for Recovery and Isolation Exploiting Semantic, ARIES),直接翻译过来是“基于语义的恢复与隔离算法”。
ARIES是现代数据库的基础理论,就算不能称所有的数据库都实现 了ARIES,至少可以称现代的主流关系型数据库(Oracle、MS SQLServer、MySQL/InnoDB、IBM DB2、PostgreSQL,等等)在事务实 现上都深受该理论的影响。在20世纪90年代,IBM Almaden研究院总结 了研发原型数据库系统“IBM System R”的经验,发表了ARIES理论中
最主要的三篇论文[2],其中“ARIES:A Transaction Recovery Method Supporting Fine-Granularity Locking and Partial
Rollbacks Using Write-Ahead Logging”[3]着重解决了ACID的两个


属性——原子性(A)和持久性(D)在算法层面上的实现问题。而另 一篇“ARIES/KVL:A Key-Value Locking Method for Concurrency Control of Multiaction Transactions Operating on B-Tree
Indexes”[4]则是现代数据库隔离性(I)奠基式的文章。下面,我们 先从原子性和持久性说起。
[1] ARIES 理 论 :
https://en.wikipedia.org/wiki/Algorithms_for_Recovery_and_Isolation_Expl
oiting_Semantics。
[2] 这个系列的第三篇是“ARIES/lM:An Efficient and High Concurrency
Index Management Method Using Write-Ahead Logging” , 本 文 不 会 涉
及。
[3] 下 载 地 址 :
https://cs.stanford.edu/people/chrismre/cs345/rl/aries.pdf。
[4] 下载地址:http://vldb.org/conf/1990/P392.PDF。


3.1.1 实现原子性和持久性
原子性和持久性在事务里是密切相关的两个属性:原子性保证了 事务的多个操作要么都生效要么都不生效,不会存在中间状态;持久 性保证了一旦事务生效,就不会再因为任何原因而导致其修改的内容 被撤销或丢失。
众所周知,数据必须要成功写入磁盘、磁带等持久化存储器后才 能拥有持久性,只存储在内存中的数据,一旦遇到应用程序忽然崩 溃,或者数据库、操作系统一侧崩溃,甚至是机器突然断电宕机等情 况就会丢失,后文我们将这些意外情况都统称为“崩溃”(Crash)。 实现原子性和持久性的最大困难是“写入磁盘”这个操作并不是原子 的,不仅有“写入”与“未写入”状态,还客观存在着“正在写”的 中间状态。由于写入中间状态与崩溃都不可能消除,所以如果不做额 外保障措施的话,将内存中的数据写入磁盘,并不能保证原子性与持 久性。下面通过具体事例来说明。
按照前面预设的场景事例,从Fenix’s Bookstore购买一本书需 要修改三个数据:在用户账户中减去货款、在商家账户中增加货款、 在商品仓库中标记一本书为配送状态。由于写入存在中间状态,所以 可能出现以下情形。
·未提交事务,写入后崩溃:程序还没修改完三个数据,但数据
库已经将其中一个或两个数据的变动写入磁盘,若此时出现崩溃,一
旦重启之后,数据库必须要有办法得知崩溃前发生过一次不完整的购
物操作,将已经修改过的数据从磁盘中恢复成没有改过的样子,以保
证原子性。
·已提交事务,写入前崩溃:程序已经修改完三个数据,但数据
库还未将全部三个数据的变动都写入磁盘,若此时出现崩溃,一旦重
启之后,数据库必须要有办法得知崩溃前发生过一次完整的购物操
作,将还没来得及写入磁盘的那部分数据重新写入,以保证持久性。
由于写入中间状态与崩溃都是无法避免的,为了保证原子性和持 久性,就只能在崩溃后采取恢复的补救措施,这种数据恢复操作被称