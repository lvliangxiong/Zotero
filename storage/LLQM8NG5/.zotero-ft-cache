MACHINE
LEARNING
机器学习
周志华著
清华大学出版社
北京


内容简介
机器学习是计算机科学的重要分支领域.本书作为该领域的入门教材,在内容上尽可能涵盖机器学习基础
知识的各方面.全书共1 6 章,大致分为3 个部分:第 1 部 分 (第 1〜 3 章 )介绍机器学习的基础知识;第 2 部
分 (第 4〜 1 0 章)讨论一些经典而常用的机器学习方法(决策树、神经网络、支持向量机、贝叶斯分类器、集
成学习、聚类、降维与度量学习);第 3 部 分 (第 U 〜 1 6 章 )为进阶知识,内容涉及特征选择与稀疏学习、 计算学习理论、半监督学习、概率图模型、规则学习以及强化学习等.每章都附有习题并介绍了相关阅读材料,
以便有兴趣的读者进一步钻研探索. 本书可作为高等院校计算机、自动化及相关专业的本科生或研究生教材,也可供对机器学习感兴趣的研究
人员和工程技术人员阅读参考.
本书封面贴有清华大学出版社防伪标签,无标签者不得销售.
版权所有,侵权必究.侵权举报电话:010-62782989 13701121933
图书在版编目(CIP)数据
机器学习/周志华著•-北京:清华大学出版社,2016
ISBN 978-7-302-42328-7
I . 1机... I I . 1周... IU .1机器学习 W.1TP181
中国版本图书馆C I P 数据核字(2015)第 287090号
责任编辑:薛 慧 封面设计:何凤霞 责任校对:刘玉霞 责任印制:宋 林
出版发行:清华大学出版社
网 tit:http://www.tup.com.cn, http://www.wqbook.com
地 址:北京清华大学学研大厦A 座 邮 编:100084
社 总 机:010-62770175 邮 购:010-62786544
投稿与读者月艮务:010-62776969, c-service@tup.tsinghua.edu.cn
质量反馈:010・62772015, zhiliang@tup.tsinghua.edu.cn 印 装 者:北京亿浓世纪彩色印刷有限公司 经 销:全国新华书店
开 本: 210mmx 235mm BP 张:27.75 字 数: 626千字
版 次: 2016年 1 月 第 1 版 印 次: 2016年 1 月 第 1 次印刷
印 数: 1 〜 5000 定 价:88.00 元
产品编号:064027-01


-XZ- — »
刖B
这是一本面向中文读者的机器学习教科书,为了使尽可能多的读者通过本书对机器学习有所了
解 ,作 者 试 图 尽 可 能 少 地 使 用 数 学 知 识 .然 而 ,少 量 的 概 率 、统 计 、代 数 、优 化 、逻辑知识似乎不可
避 免 .因 此 ,本书更适合大学三年级以上的理工科本科生和研究生,以及具有类似背景的对机器学习
感兴趣的人士.为方便读者,本书附录给出了一些相关数学基础知识简介.
全 书 共 1 6 章,大体上可分为3 个部分:第 1 部分包括第1〜 3 章,介绍机器学习基础知识;第2 部
分 包 括 第 4 - 1 0 章,介绍一些经典而常用的机器学习方法;第 3 部 分 包 括 第 11〜 1 6 章,介绍一些进阶
知 识 .前 3 章之外的后续各章均相对独立,读者可根据自己的兴趣和时间情况选择使用.根据课时情
况,一个学期的本科生课程可考虑讲授前9 章 或 前 1 0 章;研究生课程则不妨使用全书.
书中除第1 章外,每章都给出了十道习题.有的习题是帮助读者巩固本章学习,有的是为了引导读
者扩展相关知识.一学期的一般课程可使用这些习题,再辅以两到三个针对具体数据集的大作业.带
星号的习题则有相当难度,有些并无现成答案,谨供富有进取心的读者启发思考.
本书在内容上尽可能涵盖机器学习基础知识的各方面,但作为机器学习入门读物且因授课时间的
考 虑 ,很 多 重 要 、前 沿 的 材 料 未 能 覆 盖 ,即 便 覆 盖 到 的 部 分 也 仅 是 管 中 窥 豹 ,更 多 的 内 容 留 待 读 者 在
进阶课程中学习.为便于有兴趣的读者进一步钻研探索,本书每章均介绍了一些阅读材料,谨供读者
参考.
笔者以为,对学科相关的重要人物和事件有一定了解,将会增进读者对该学科的认识.本书在每
章最后都写了一个与该章内容相关的小故事,希望有助于读者增广见闻,并且在紧张的学习过程中稍
微放松调剂一下.
书中不可避免地涉及大量外国人名,若全部译为中文,则读者在日后进一步阅读文献时或许会对
不 少 人 名 产 生 陌 生 感 ,不 利 于 进 一 步 学 习 .因 此 ,本 书 仅 对 一 般 读 者 耳 熟 能 详 的 名 字 如 “图 灵 ”等加
以直接使用,对故事中的一些主要人物给出了译名,其他则保持外文名.
机器学习发展极迅速,目前已成为一个广袤的学科,罕有人士能对其众多分支领域均有精深理解.
笔者自认才疏学浅,仅略知皮毛,更兼时间和精力所限,书中错谬之处在所难免,若蒙读者诸君不吝告
知 ,将不胜感激.
周志华
2015年 6 月




序言
在 人 工 智 能 界 有 一 种 说 法 ,认 为 机 器 学 习 是 人 工 智 能 领 域 中 最 能 够 体 现 智 能 的 一 个 分 支 .从 历 史
来 看 ,机 器 学 习 似 乎 也 是 人 工 智 能 中 发 展 最 快 的 分 支 之 一 .在 二 十 世 纪 八 十 年 代 的 时 候 ,符号学习可
能 还 是 机 器 学 习 的 主 流 ,而 自 从 二 十 世 纪 九 十 年 代 以 来 ,就 一 直 是 统 计 机 器 学 习 的 天 下 了 .不 知 道 是
否 可 以 这 样 认 为 :从 主 流 为 符 号 机 器 学 习 发 展 到 主 流 为 统 计 机 器 学 习 ,反映了机器学习从纯粹的理论
研 究 和 模 型 研 究 发 展 到 以 解 决 现 实 生 活 中 实 际 问 题 为 目 的 的 应 用 研 究 ,这是科学 研 究 的 一 种 进 步 .有
关 机 器 学 习 的 专 著 国 内 出 版 的 不 是 很 多 .前 两 年 有 李 航 教 授 的 《统 计 学 习 方 法 》 出版,以简要的方式
介 绍 了 一 批 重 要 和 常 用 的 机 器 学 习 方 法 .此 次 周 志 华 教 授 的 鸿 篇 巨 著 《机 器 学 习 》则全面而详细地介
绍 了 机 器 学 习 的 各 个 分 支 ,既 可 作 为 教 材 ,又 可 作 为 自 学 用 书 和 科 研 参 考 书 .
翻 阅 书 稿 的 过 程 引 起 了 一 些 自 己 的 思 考 ,平 时 由 于 和 机 器 学 习 界 的 朋 友 接 触 多 了 ,经常获得一些
道 听 途 说 的 信 息 以 及 专 家 们 对 机 器 学 习 现 状 及 其 发 展 前 途 的 评 论 .在 此 过 程 中 ,难免会产生一些自己
的 疑 问 .我 借 此 机 会 把 它 写 下 来 放 在 这 里 ,算 是 一 种 “外行 求 教 机 器 学 习 ”.
问题一:在 人 工 智 能 发 展 早 期 ,机 器 学 习 的 技 术 内 涵 几 乎 全 部 是 符 号 学 习 .可 是 从 二 十 世 纪 九 十
年 代 开 始 ,统计 机 器 学 习 犹 如 一 匹 黑 马 横 空 出 世 ,迅速压倒并取代了符号学习的地位.人们可能会问:
在满目的统计学 习 期 刊 和 会 议 文 章 面 前 ,符号学习是否被彻底忽略了?它还能成为机器学习的研究对
象 吗 ?它 是 否 将 继 续 在 统 计 学 习 的 阴 影 里 生活并苟延残喘?对这个问题有 三 种 可 能 的 答 案 :一是告诉
符 号 学 习 :“你 就 是 该 退 出 历 史 舞 台 ,认 命 吧 !”二 是 告 诉 统 计 学 习 :“你 的 一 言 堂 应 该 关 门 了 !”单纯
的统计 学 习 已 经 走 到 了 尽 头 ,再 想 往 前 走 就 要 把 统 计 学 习 和 符 号 学 习 结 合 起 来 .三 是 事 物 发 展 总 会 有
“三 十 年 河 东 ,三 十 年 河 西 ,,的现象,符 号 学 习 还 有 “翻 身 ,,的日子.第一种观点我没有听人明说过,
但是我想恐怕有可能已经被许多人默认了.第二种观点我曾听王珏教授多次说过.他并不认为统计学
习 会 衰 退 ,而 只 是 认 为 机 器 学 习 已 经 到 了 一 个 转 折 点 ,从 今 往 后 ,统计学习应该和知识的利用相结合,
这 是 一 种 “螺 旋 式 上 升 ,进 入 更 高 级 的 形 式 ”,否 则 ,一统计学习可能会停留于现状而止步不前,王珏教
授 还 认 为 :进 入 转 折 点 的 标 志 就 是 K o ller等 的 《概 率 图 模 型 》一 书 的 出 版 .至 于 第 三 种 观 点 ,恰好我
收到老 朋 友 ,美 国 人 工智能资深学者、俄 亥 俄 大 学 Chandrasekaran教授的来信,他正好谈起符号智能
被 统 计 智 能 “打 压 ”的现象,并 且 正 好 表 达 了 河 东 河 西 的 观 点 .我 请 求 他 允 许 我 把 这 段 话 引 进 正 在 撰
写 的 序 言 中 ,他 爽 快 地 同 意 了 ,仅 仅 修 改 了 几 处 私 人 通 信 的 口 吻 .全 文 如 下 :“最近几年,.人工智能在
很 大 程 度 上 集 中 于 统 计 学 和 大 数 据 .我 同 意 由 于 计 算 能 力 的 大 幅 提 高 ,这 些 技 术 曾 经 取 得 过 某 些 令
人 印 象 深 刻 的 成 果 .但 是 我 们 完 全 有 理 由 相 信 ,虽 然 这 些 技 术 还 会 继 续 改 进 、提 高 ,总有一天这个领
域 (指 A I)会 对 它 们 说 再 见 ,并 转 向 更 加 基 本 的 认 知 科 学 研 究 .尽 管 钟 摆 的 摆 回 去 还 需 要 一 段 时 间 ,我


机器学习
相 信 定 有 必 要 把 统 计 技 术 和 对 认 知 结 构 的 深 刻 理 解 结 合 起 来 看 来 ,C h a n d ra se k a raii教授也并不认
为若干年以后A I 真会回到河西,他的意见和王珏教授的意见基本一致,但不仅限于机器学习,而是涉
及整个人工智能领域.只是王珏教授强调知识,而 Chandrasekaran教授强调更加基本的“认知”.
问题二:王珏教授认为统计机器学习不会“一路顺风”的判据是:统计机器学习算法都是基于样
本数据独立同分布的假设.但是自然界现象千变万化,王 珏 教 授 认 为 “哪有那么多独立同分布?”这
就引来了下一个问题:“独立同分布”条件对于机器学习来讲真是必需的吗?独立同分布的不存在一
定是一个不可逾越的障碍吗?无独立同分布条件下的机器学习也许只是一个难题,而不是不可解问
题 .我 有 一 个 “胡思乱想”,认为前些时候出现的“迁移学习”也许会对这个问题的解决带来一线曙
光 .尽 管 现 在 的 迁 移 学 习 还 要 求 迁 移 双 方 具 备 “独 立 同 分 布 ”条 件 ,但是不同分布之间的迁移学习,
同分布和异分布之间的迁移学习也许迟早会出现?
问题三:近年来出现了一些新的动向,例 如 “深度学习”、 “无终止学习”等等,社会上给予了
特别关注,尤其是深度学习.但它们真的代表了机器学习的新的方向吗?包括本书作者周志华教授在
内的一些学者认为:深度学习掀起的热潮也许大过它本身真正的贡献,在理论和技术上并没有太多的
创新,只不过是由于硬件技术的革命,计算机的速度大大提高了,使得人们有可能采用原来复杂度很
高的算法,从而得到比过去更精细的结果.当然这对于推动机器学习应用于实践有很大意义.但我们
不禁要斗胆问一句:深度学习是否又要取代统计学习了?事实上,确有专家已经感受到来自深度学习
的压力,指出统计学习正在被深度学习所打压,正如我们早就看到的符号学习被统计学习所打压.不
过我觉得这种打压还远没有强大到像统计学习打压符号学习的程度.这一是因为深度学习的“理论创
新 ”还不明显;二是因为目前的深度学习主要适合于神经网络,在各种机器学习方法百花盛开的今天,
它的应用范围还有限,还不能直接说是连接主义方法的回归;三是因为统计学习仍然在机器学习中被
有效地普遍采用,“得道多助”,想抛弃它不容易.
问题四:机器学习研究出现以来,我们看到的主要是从符号方法到统计方法的演变,用到的数学主
要是概率统计.但是,数学之大,就像大海.难道只有统计方法适合于在机器学习方面应用吗? 当然,
我们也看到了一些其他数学分支在机器学习上的应用的好例子,例如微分几何在流形学习上的应用,
微分方程在归纳学习上的应用.但如果和统计方法相比,它们都只能算是配角.还有的数学分支如代
数可能应用得更广,但在机器学习中代数一般是作为基础工具来使用,例如矩阵理论和特征值理论.
又如微分方程求解最终往往归结为代数问题求解.它们可以算是幕后英雄:“出头露面的是概率和统
计 ,埋 头 苦 干 的 是 代 数 和 逻 辑 ”. 是 否 可 以 想 象 以 数 学 方 法 为 主 角 ,以统 计 方法为配角的机器学习理
论呢?在这方面,流 形 学 习 已 经 “有点意思”T , 而彭实戈院士的倒排随机微分方程理论之预测金融
走势,也许是用高深数学推动新的机器学习模式的更好例子.但是从宏观的角度看,数学理论的介入
程 度 还 远 远 不 够 .这 里 指 的 主 要 是 深 刻 的 、现 代 的 数 学 理 论 ,我 们 期 待 着 有 更 多 数 学 家 的 参 与 ,开辟
机器学习的新模式、新理论、新方向.


序 言 iii
问题五:上一个问题的延续:符号机器学习时代主要以离散方法处理问题,统计机器学习时代主
要以连续方法处理问题.这两种方法之间应该没有一条鸿沟.流形学习中李群、李代数方法的引入给
我们以很好的启示.从微分流形到李群,再从李群到李代数,就是一个沟通连续和离散的过程.然而,
现有的方法在数学上并不完美.浏览流形学习的文献可知,许多论文直接把任意数据集看成微分流形,
从而就认定测地线的存在并讨论起降维来了.这样的例子也许不是个别的,足可说明数学家介入机器
学习研究之必要.
问题六:大数据时代的出现,有没有给机器学习带来本质性的影响?理论上讲,似 乎 “大数据”给
统 计 机 器 学 习 提 供 了 更 多 的 机 遇 ,因 为 海 量 的 数 据 更 加 需 要 统 计 、抽 样 的 方 法 .业 界 人 士 估 计 ,大数
据 的 出 现 将 使 人 工 智 能 的 作 用 更 加 突 出 .有 人 把 大 数 据 处 理 分 成 三 个 阶 段 :收 集 、分 析 和 预 测 . 收 集
和分析的工作相对来说已经做得相当好了,现在关注的焦点是要有科学的预测,机器学习技术在这里
不 可 或 缺 .这 一 点 大 概 毋 庸 置 疑 .然 而 ,同样 是 使 用 统 计 、抽 样 方 法 ,同样是收集、分 析 和 预 测 ,大数
据时代使用这类方法和以前使用这类方法有什么本质的不同吗?量变到质变是辩证法的一个普遍规
律 . 那 么 ,从前大数据时代到大数据时代,数理统计方法有没有发生本质的变化?反映到它们在机器学
习上的应用有无本质变化?大数据时代正在呼唤什么样的机器学习方法的产生?哪些机器学习方法
又是由于大数据研究的驱动而产生的呢?
以上这些话也许说得远了,我们还是回到本书上来.本书的作者周志华教授在机器学习的许多领
域都有出色的贡献,是中国机器学习研究的领军人物之一,在国际学术界有着很高的声誉.他在机器
学习的一些重要领域,例如集成学习、半监督学习、多示例和多标记学习等方面都做出了在国际上有
重要影响的工作,其中一些可以认为是中国学者在国际上的代表性贡献.除了自身的学术研究以外,
他在推动中国的机器学习发展方面也做了许多工作.例如他和不久前刚过世的王珏教授从2002年开
始 ,组 织 了 系 列 化 的 “机器学习及其应用”研讨会.初在复旦,后移至南大举行,越办越兴旺,从单一
的专家报告发展到专家报告、学生论坛和张贴论文三种方式同时举行,参会者从数十人发展到数百
人 ,活动搞得有声有色,如火如荼.最近更是把研讨会推向全国高校轮流举行.他和王珏教授紧密合
作 ,南北呼应,人 称 “南周北王”.王珏教授的离去使我们深感悲伤.令我们欣慰的是国内不但有周志
华教授这样的机器学习领军人物,而且比周教授更年轻的许多机器学习青年才俊也成长起来了.中国
的机器学习大有希望.
怯饮妗
中国科学院数学与系统科学研究院
2015年 8 月于北京




主要符号表
X
X
X
A
I
彳
V
D
H
H
£
(丁,,,)
(•;・;•)
(•产
{,••}
I{ ... } I
II- UP
P ( ) I •)
P《),P《I •)
后・~引川)]
sup(-)
口(•)
sign。
标量
向量
变量集
矩阵
单位阵
样本空间或状态空间
概率分布
数 据 样 本 (数据集)
假设空间
假设集
学习算法
行向量
列向量
向量或矩阵转置
集合
集合{•...}中元素个数
“ 范数,p 缺省时为L 2 范数
概率质量函数,条件概率质量函数
概率密度函数,条件概率密度函数
函 数 / (.)对 •在 分 布 T)下的数学期望;意义明确时将 省 略 。 和(或).
上确界
指 示 函 数 ,在 •为真和假时 分 别 取 值 为 1,0
符 号 函 数 ,在 •< 0, = 0, > 0 时分别取值为—1,0,1




目录
第 1 章 绪 论 ............................ 1
1.1 引 言 ......................... 1
1.2 基本术语 .......................................................2
1 . 3 假设空间 .......................................................4
1.4 归纳偏好 .......................................................6
1 . 5 发 展 历 程 ......................................................10
1 . 6 应用现状 ......................................................13
1 . 7 阅 读 材 料 ...... ............... 16
习题 ............................................................... 19
参考文 献 ................................. 20
休息一会 儿 ........................... 22
第 2 章 模型评估与选择........................... 23
2 . 1 经验误差与过拟合 ........................................ 23
2 . 2 评 估 方 法 ......................................................24
2 . 3 性 能 度 量 ......................................................28
2.4 比较检验 .......................... 37
2 . 5 偏 差 与 方 差 ................................................... 44
2.6 阅 读 材 料 ........................................ ... ........ 46
习题 ............................................................... 48
参考文献 ........................................................... 49
休息一会儿 ...................................................... 51
第 3 章 线 性 模 型 ............ 53
3.1 基本形式 ...................................... 53
3 . 2 线性回归 ......................................................53
3.3 对数几率回归 ....................... 57
3 . 4 线 性 判 别 分 析 ..................... 60
3 . 5 多分类学习 ....................................................63


X 机器学习
3 . 6 类 别 不 平 衡 问 题 ................. 66
3.7 阅 读 材 料 ......................... 67
习题 ................................................................69 参考文献 .......................................... 70 休息一会儿 ......................................................... 72
第 4 章 决 策 树 ........................................................ 73
4 . 1 基本流程 ..................................................... 73
4 . 2 划 分 选 择 ..................................................... 75
4 . 3 剪枝处理 ........................ 79
4 . 4 连 续 与 缺 失 值 .................. 83
4 . 5 多 变 量 决 策 树 ............................... 88
4 . 6 阅读材料 ..................................................... 92
习题 ........ 93 参考文 献 ......................................... 94 休息一 会儿 ....................................................... 95
第 5 章 神 经 网 络 .. .... ............. 97
5 . 1 神经元模型 ................................................... 97
5 . 2 感 知 机 与 多 层 网 络 ..................................... .... 98
5 . 3 误差逆传播算法 ......................................... 101
5 . 4 全局最小与局部极小 .................. 106
5 . 5 其 他 常 见 神 经 网 络 ............................................ 108
5 . 6 深度学习 .................................................... 113
5 . 7 阅读材料 .................................................... 115
习题 ................................ 116 参考文献 .......................................................... 117 休息一会儿 ....................................................... 120
第 6 章 支 持 向 量 机 ................................................... 121
6 . 1 间隔与支持向量 ................................ :.............121
6 . 2 对偶问题 ........ 123
6 . 3 核 函 数 ....................................................... 126
6.4 软间隔与正则化 ................ 129
6.5 支持向量回归 ...... 133


目 录 xi
6 . 6 核 方 法 .. .................................................... 137
6.7 阅读材料 ..................................................... 139
习题 .............................................................. 141
参考文献 .......................................................... 142 休息一会儿 ........................................................ 145
第 7 章 贝叶斯分类器............................................... 147
7.1 贝叶斯决策论 .................................. 147
7 . 2 极 大 似 然 估 计 .................................................149
7 . 3 朴 素 贝 叶 斯 分 类 器 ............................................. 150
7 . 4 半 朴 素 贝 叶 斯 分 类 器 .......................................... 154
7.5 贝叶斯网 ..................................................... 156
7.6 EM 算 法 ..................................................... 162
7.7 , 阅读材料 ................................................... 164
习题 .............................................................. 166 参考文献 ................................................ 167 休息一会儿 ........................................................ 169
第 8 章 集 成 学 习 ............... 171
8 . 1 个 体 与 集 成 ...................................................171
8.2 Boosting ..................................................................................................... 173
8.3 Bagging与随机森林 ........................................... 178
8.4 结合策略 ..................... ....1 8 1
8.5 多 样 性 ..................... 185
8.6 阅读材料 ..................................................... 190
习题 .............................................................. 192 参考文献 .......................................................... 193
休息一会儿 ........................................................ 196
第 9 章 聚 类 .............................................. 197
9 . 1 聚类任务 .....................................................197
9 . 2 性能度量 .....................................................197
9.3 距离计算 ................... 199
9.4 原型聚类 ................................... 202
9 . 5 密度聚类 ..................... 211


xii 机器学习
9 . 6 层次聚类 ............................... 214
9 . 7 阅读材料 .......................... 217
习 题 ........................................................... 220 参考文献 ................................ 221 休息一会儿 ........................................................ 224
第 1 0 章 降 维 与 度 量 学 习 ........ .............. 225
10.1 k近邻学习 ..................... 225
10.2 低维嵌入 ..................... 226
10.3 主 成 分 分 析 ........... 229
1 0 . 4 核 化 线 性 降 维 ............. 232
1 0 . 5 流形学习 ............................. 234
10.6 度 量 学 习 ..................... 237
10.7 阅读材料 ................................................... 240
习 题 ...............................................................242
参考文献 ......................... 243 休息一会儿 ..................................... 246
第 I I 章 特征选择与稀疏学习................... 247
1 1 . 1 子集搜索与评价 .......... 247
11.2 过滤式选择 .............................. 249
1 1 . 3 包 裹 式 选 择 ..................... 250
11.4 嵌入式选择与L i正则化 ...... 252
11.5 稀疏表示与字典学习 ........... 254
1 1 . 6 压缩感知 ................................................... 257
11.7 阅读材料 .............. .260
习题 .............................................................. 262
参 考 文 献 ........................ 263 休 息 一 会 儿 ... .......................... 266
第 1 2 章 计 算 学 习 理 论 .............................. 267
12.1 基础知识 ....................... 267
12.2 PAC学习 .................. 268
1 2 . 3 有限假设空间 .......... 270
12.4 VC 维 ....................................................... 273


目 录 xiii
12.5 Rademacher复杂度 ...................... 279
1 2 . 6 稳定性 ..................................................... 284
12.7 阅读材料 .................................................... 287
习题 .............................................................. 289 参考文献 ....................................................... ...2 9 0 休息一会儿 ........................................................ 292
第 1 3 章 半 监 督 学 习 ..................................................293
13.1 未标记样本 ................................................. 293
1 3 . 2 生 成 式 方 法 ................................................. 295
13.3 半监督SVM ........................................................................................ 298
13.4 图半监督学习 ................................................300
1 3 . 5 基于分歧的方法 ......... 304
13.6 半监督聚类 ..................................................307
13.7 阅 读 材 料 .................................................... 311
习题 .............................................................. 313 参考文献 .................. 314 休息一会儿 ........................................................ 317
第 1 4 章 概 率 图 模 型 ,.................................................319
1 4 . 1 隐马尔可夫模型 ............................................. 319
14.2 马尔可夫随机场 ............................................. 322
1 4 . 3 条 件 随 机 场 ................................................. 325
1 4 . 4 学习与推断 ................................................. 328
1 4 . 5 近似推断 ................................................... 331
14.6 话题模型 ................................................. 337
14.7 阅读材料 ................ 339
习 题 .............................................................. 341 参考文献 ....................... 342 休息一会儿 ........................................................ 345
第 1 5 章 规 则 学 习 .................................................... 347
15.1 基本概念 ................................................... 347
1 5 . 2 序贯覆盖 ................................................... 349
1 5 . 3 剪枝优化 ................................................... 352


xiv 机器学习
15.4 一阶规则学习 ............................................... 354
1 5 . 5 归纳逻辑程序设计 ............. 357
15.6 阅 读 材 料 ........................ 363
习 题 ........................................ :............. 365
参考文献 ............ 366
休息一会儿 ................ 369
第 1 6 章 强 化 学 习 ............. 371
16.1 任务与奖赏 ..................... 371
16.2 K -摇臂赌博机 ......................... 373
1 6 . 3 有模型学习 ................... ....3 7 7
16.4 免模型学习 ................................... 382
1 6 . 5 值 函 数 近 似 ................................................. 388
1 6 . 6 模仿学习 ................................................... 390
1 6 . 7 阅读材料 ............ 393
习题 ............... 394
参考文献 .......................................... 395 休息一会儿 ........................................................ 397
附 录 ...........................:............................ 399
A 矩阵 .......................................................... 399
B 优 化 .......................................................... 403
C 概率分布 ....... 409
后 记 .................. 417
索 引 ................................................................. 419


第1章 绪 论
[Mitchell, 1997]给出了 一 个 更 形 式 化 的 定 义 :假 设 用 P 来评估计算机程序 在 某 任 务 类 T 上的性能, 若一个程序通过利用经验 E 在 T 中任务上获得了性 能 改 善 ,则 我 们 就 说 关 于 T 和尸,该 程 序 对E 进行 了学习.
例如[Hand et al., 2001].
1 . 1 弓I言
傍晚小街路面上沁出微雨后的湿润,和煦的细风吹来,抬头看看天边的晚
霞,嗯,明天又是一个好天气.走到水果摊旁,挑了个根蒂蜷缩、敲起来声音浊
响的青绿西瓜,一边满心期待着皮薄肉厚瓢甜的爽落感,一边愉快地想着,这学
期狠下了工夫,基础概念弄得清清楚楚,算法作业也是信手拈来,这门课成绩一
定差不了!
希望各位在学期结束时有这样的感觉.作为开场,我们先大致了解一下什
么 是 “机器学习”(machine learning).
回头看第一段话,我们会发现这里涉及很多基于经验做出的预判.例如,为
什么看到微湿路面、感到和风、看到晚霞,就认为明天是好天呢?这是因为在
我们的生活经验中已经遇见过很多类似情况,头一天观察到上述特征后,第二
天 天 气 通 常 会 很 好 .为 什 么 色 泽 青 绿 、根 蒂 蜷 缩 、敲 声 浊 响 ,就能 判 断 出 是 正
熟 的好瓜? 因 为 我 们 吃 过 、看 过 很 多 西 瓜 ,所 以 基 于 色 泽 、根 蒂 、敲声这几个
特征我们就可以做出相当好的判断.类似的,我们从以往的学习经验知道,下足
了工夫、弄清了概念、做好了作业,自然会取得好成绩.可以看出,我们能做出
有效的预判,是因为我们已经积累了许多经验,而通过对经验的利用,就能对新
情况做出有效的决策.
上面对经验的利用是靠我们人类自身完成的.计算机能帮忙吗?
机器学习正是这样一门学科,它致力于研究如何通过计算的手段,利用经
验来改善系统自身的性能.在计算机系统中,“经 验 ”通 常 以 “数 据 ”形式存
在,因此,机器学习所研究的主要内容,是 关 于 在 计 算机上从数据中产生“模
型 " (model)的算法,即 “学习算法” l(earning algorithm). 有了学习算法,我
们把经验数据提供给它,它就能基于这些数据产生模型;在面对新的情况时(例
如 看 到 一 个 没 剖 开 的 西 瓜 ),模 型 会 给 我 们 提 供 相 应 的 判 断 (例 如 好 瓜 ). 如 果 说
计 算 机 科 学 是 研 究 关 于 “算 法 ” 的学问,那 么 类 似 的 ,可 以 说 机 器学习是研究
关 于 “学习算法”的学问.
本 书 用 “模型”泛指从数据中学得的结果.有文献用“模型”指全局性结
果(例如一棵决策树),而 用 “模式”指局部性结果(例如一条规则).


2 第 1章 绪 论
1 .2 基本术语
有时整个数据集亦称一 个 “样本 ”,因为它可看 作对样本空间的一个采样; 通 过 上 下 文 可 判 断 出 “样 本”是指单个示例还是数 据集.
训 练 样 本 亦 称 “训练示 伤 (training instance)或 “训练例”.
学习算法通常有参数需 设置,使用不同的参数值 和(或)训 练 数 据 ,将产生 不同的结果.
将 “ label” 译 为 “标 记 ” 而 非 “标签”,是考 虑 到 英 文 中 “ label” 既可 用作名词、也可用作动词.
要 进 行 机 器 学 习 ,先 要 有 数 据 . 假 定 我 们 收 集 了 一 批 关 于 西 瓜 的 数 据 ,例
如(色泽= 青绿;根蒂= 蜷缩;敲声= 浊响),(色泽= 乌黑;根蒂= 稍蜷;敲声 =沉
闷),(色泽= 浅白;根蒂= 硬 挺 ;敲 声 =清 脆 ),... ..., 每对括号内是一条记录,
意 思 是 “取值为
这 组 记 录 的 集 合 称 为 一 个 “数据集”(data set), 其中每条记录是关于一
个事件或对象(这里是一个西瓜)的描述,称 为 一 个 “示 例 ” i(nstance)或 “样
本 " (sample). 反映事件或对象在某方面的表现或性质的事项,例 如 “色 泽 ”
“根蒂” “敲 声 " 称 为 “属 性 " (attribute)或 “特征” f(eature); 属性上的取
值,例 如 “青绿” " 乌 黑 " 称 为 “属性值”时 tribute value). 属性张成的空
间 称 为 “属性空间" (attribute space)、 “样本空间”(sample space)或 “输入
空间”.例 如 我 们 把 “色 泽 ” “根蒂” “敲声”作为三个坐标轴,则它们张成
一个用于描述西瓜的三维空间,每个西瓜都可在这个空间中找到自己的坐标位
置.由于空间中的每个点对应一个坐标向量,因此我们也把一个示例称为一个
“特征向量” f(eature vector).
一 般 地 ,令 0 = {叫,g , ... ,宓 鬲 表 示 包 含 皿 个 示 例 的 数 据 集 ,每个
示 例 由 d 个 属 性 描 述 (例 如 上 面 的 西瓜数据使用了 3 个属性),则每个示例
Xi = (C订;电2;... ;B d)是 d 维样本空间%中的一个向量,g E 工 其 中 Xij是
g 在 第 j 个属性上的取值(例 如 上 述 第 3 个 西 瓜 在 第 2 个 属 性 上 的 值 是 “硬
挺 ”),d 称为样本g 的 “维 数 " (dimensionality).
从 数 据 中 学 得 模 型 的 过 程 称 为 “学 习 ” l(earning)或 “训 练 ” t(raining),
这 个 过 程 通 过 执 行 某 个 学 习 算 法 来 完 成 . 训 练 过 程 中 使 用 的 数 据 称 为 “训练
数 据 " t(raining data), 其中每个样本称为一个“训练样本" t(raining sample),
训练样本组成的集合称为“训 练 集 " t(raining set). 学得模型对应了关于数据
的某种潜在的规律,因 此 亦 称 “假 设 " (hypothesis); 这种潜在规律自身,则称
为 “真相”或 “真实”(ground-truth), 学习过程就是为了找出或逼近真相.本
书 有时将模型称为“学习器” l(earner), 可看作学习算法在给定数据和参数空
间上的实例化.
如果希望学得一个能帮助我们判断没剖开的是不是“好 瓜 ”的模型,仅
有前面的示例数据显然是不够的.要建立这样的关于“预 测 ”(prediction)的
模型,我们需获得训练样本的“结果”信息,例 如 “((色泽= 青绿;根蒂= 蜷缩;
敲 声 =浊 响 ),好瓜)”. 这里关于示例结果的信息,例 如 “好 瓜 ”,称 为 “标
记 " l(abel); 拥有了标记信息的示例,则 称 为 “样 例 " (example). 一般地,用


1 . 2 基本术语 3
若将标记看作对象本身 的一部分,则 “样 例 ”有 时 也 称 为 “样本”.
亦 称 “负类”.
亦 称 “测 试 示 例 ” (testing in s ta n c e )或 “测 试例”.
否则标记信息直接形成 了簇划分;但也有例外情 况,参 见 1 3 .6 节.
亦 称 “有导师学习”和 “无导师学习”.
更确切地说,是 “未见 示 例 " (unseen instance).
现实任务中样本空间的 规模通常很大(例如2 0 个 属性,每个属性有1 0 个可 能取值,则样本空间的规 模 已 达 1020).
(g,纳)表示第i个样例,其 中 班 G ,是 示 例 Xi的标记,J 是所有标记的集合,
亦 称 “标记空间”(label space)或 “输出空间”.
若我们欲预测的是离散值,例 如 “好 瓜 ” “坏 瓜 ”,此类学习任务称为
“分 类 " (classification);若 欲预测的是连续值,例 如 西 瓜 成 熟 度 0.95、0.37,
此 类 学 习 任 务 称 为 “回 归 ”(re g re s s io n ).对 只 涉 及 两 个 类 别 的 “二分
类 " (binary classifcation)任务,通常称其中一个类为“正类”(positive class),
另 一 个 类 为 “反 类 ”(negative c la s s );涉 及 多 个 类 别 时 ,则 称 为 “多 分
类 " (multi-class classification)任 务 一 般 地 ,预 测 任 务 是 希 望 通 过 对 训 练
集 {(叫,阳),(政,故),... ,(宓g % n ) }进行学习,建立一个从输入空间% 到输出
空 间 y 的 映 射 / :* 1 ” 对二分类任务,通 常 令 y = {- i , + i }或 {o, 1};对
多分类任务,IV > 2 ; 对回归任务,y = 胆肽为实数集.
学得模型后,使用其进行预测的过程称为“测试”(testin g ),被预测的样本
称 为 “测试样本”(testing sam ple).例如在学得了后,对测试例必可得到其预
测标记g =
我们还可以对西瓜做“聚 类 " (clustering),即将训练集中的西瓜分成若干
组,每 组 称 为 一 个 “簇 ”(cluster);这些自动形成的簇可能对应一些潜在的概念
划分,例 如 “浅色瓜” “深 色 瓜 " 甚 至 “本地瓜” “外地瓜”.这样的学习过
程有助于我们了解数据内在的规律,能为更深入地分析数据建立基础.需说明
的是,在聚类学习中,“浅色瓜” “本地瓜”这样的概念我们事先是不知道的,
而且学习过程中使用的训练样本通常不拥有标记信息.
根据训练数据是否拥有标记信息,学习任务可大致划分为两大类: “监督
学 习 “(supervised learning)和 “无 监 督 学 习 "(unsupervised learning),分类
和回归是前者的代表,而聚类则是后者的代表.
需注意的是,机器学习的目标是使学得的模型能很好地适用于“新 样 本 "
而不是仅仅在训练样本上工作得很好;即便对聚类这样的无监督学习任务,我
们也希望学得的簇划分能适用于没在训练集中出现的样本.学得模型适用于
新样本的能力,称 为 “泛 化 " (generalization)能力.具有强泛化能力的模型能
很 好 地 适 用 于 整 个 样 本 空 间 .于 是 ,尽 管 训 练 集 通 常 只 是 样 本 空 间 的 一 个 很 小
的采样,我们仍希望它能很好地反映出样本空间的特性,否则就很难期望在训
练集上学得的模型能在整个样本空间上都工作得很好.通常假设样本空间中全
体样本服从一个未知“分 布 " (d i s t r i b u t i o n ) 我们获得的每个样本都是独立
地从这个分布上采样获得的,即 “独立同分布" (independent and identically
distributed,简 称 汨 (4) .一 般 而 言 ,训练样本越多,我们得到的关于V 的信息


4 第1章 绪 论
越多,这样就越有可能通过学习获得具有强泛化能力的模型.
1 .3 假设空间
归纳(induction)与演绎(deduction)是科学推理的两大基本手段.前者是从
特 殊 到 一 般 的 “泛化”(generalization)过程,即从具体的事实归结出一般性规
律;后者则是从一般到特殊的“特 化 ”(specialization)过程,即从基础原理推演
出 具 体 状 况 . 例 如 ,在 数 学 公 理 系 统 中 ,基 于 一 组 公 理 和 推 理 规 则 推 导 出 与 之
相洽的定理,这是演绎;而 “从样例中学习”显然是一个归纳的过程,因此亦称
“归纳学习 ”(inductive learning).
归纳学习有狭义与广义之分,广义的归纳学习大体相当于从样例中学习,
而狭义的归纳学习则要求从训练数据中学得概念(concept),因 此 亦 称 为 “概念
学 习 ”或 “概念形成”.概念学习技术目前研究、应用都比较少,因为要学得
泛 化 性 能 好 且 语义明确的概念实在太困难了,现 实 常 用 的 技 术 大 多 是 产 生 “黑
箱 ”模型.然而,对概念学习有所了解,有助于理解机器学习的一些基础思想.
概念学习中最基本的是布尔概念学习,即 对 “是 ” “不是”这样的可表示
为 0/1布尔值的目标概念的学习.举一个简单的例子,假定我们获得了这样一
个训练数据集:
表 L 1 西瓜数据集
编号色泽根蒂敲声好瓜 1 2
3 4
黑绿黑绿
乌青乌青
稍硬蜷蜷
蜷挺缩缩
沉闷 清脆 浊响 浊响
否否是是
这里要学习的目标是“好 瓜 ”.暂 且 假 设 “好瓜”可 由 “色泽” “根蒂”
“敲 声 ”这三个因素完全确定,换言之,只要某个瓜的这三个属性取值明确了,
我们就能判断出它是不是好瓜.于是,我 们 学 得 的 将 是 “好瓜是某种色泽、某
种根蒂、某种敲声的瓜”这样的概念,用布尔表达式写出来则是“好 瓜 分 (色 电了呼常会普 泽=?) A (根蒂=?) A (敲声= ? ) " ,这 里 表 示 尚 未 确 定 的 取 值 ,而 我 们 的 任
合范或 务就是通过对表1 .1 的训练集进行学习,把 确 定 下 来 .
读者可能马上发现,表 1 .1 第一行: “(色泽二青绿)A (根 蒂 =蜷 缩 )A (敲
声 =浊 响 )”不就是好瓜吗?是的,但这是一个已见过的瓜,别忘了我们学习的
目 的 是 “泛化”,即通过对训练集中瓜的学习以获得对没见过的瓜进行判断的


1 . 3 假设空间 5
“记 住 ” 训 练 样 本 ,就 是 所 谓 的 “机 械 学 习 ” [Cohen and Feigenbaum, 1 9 8 3 ],或 称 “死 记 硬 背 式 学习” ,参 见 L 5 节.
这里我们假定训练样 本 不 含 噪 声 ,并 且 不 考 虑 “非 青 绿 ”这 样 的 「4 操 作.由于训练集包含正例, 因 此 0 假设自然不出现.
能 力 . 如 果 仅 仅 把 训 练 集 中 的 瓜 “记 住 ”,今后再见到一模一样的瓜当然可判
断,但是,对没见过的瓜,例如“(色 泽 =浅 白 )A (根蒂= 蜷缩)A (敲声= 浊响)”
怎么办呢?
我们可以把学习过程看作一个在所有假设(hypothesis)组成的空间中进行
搜索的过程,搜索目标是找到与训练集“匹配”(班)的假设,即能够将训练集中
的瓜判断正确的假设.假设的表示一旦确定,假设空间及其规模大小就确定了.
这里我们的假设空间由形如“(色泽= ? )A (根蒂= ? )A (敲声= ? )" 的可能取值
所 形 成 的 假 设 组 成 .例 如 色 泽 有 “青 绿 ” “乌 黑 ” “浅白”这三种可能取值;
还需考虑到,也 许 “色 泽 ”无论取什么值都合适,我 们 用 通 配 符 来 表 示 ,
例 如 “好 瓜 》 (色泽= *)A (根蒂= 蜷缩)A (敲声= 浊响)”,即 “好瓜是根蒂蜷
缩 、敲声浊响的瓜,什么色泽都行”. 此外,还需考虑极端情况:有 可 能 “好
瓜 ”这个概念根本就不成立,世 界 上 没 有 “好瓜 ”这 种 东西;我们用0 表示这
个假设.这样,若 “色泽” “根蒂” “敲 声 ”分别有3 、2 、2 种可能取值,则我
们面临的假设空间规模大小为4 x 3 x 3 + 1 = 37. 图 1.1直观地显示出了这个
西瓜问题假设空间.
1 (色 泽 = * ;根蒂 = * ;敲 f = * )]
| (色 泽 = 青 绿 ;根 蒂 = * ;敲 产 | (色 泽 = 乌 黑 ;根 蒂 = * ;敲 声 = 可 ...
| (色 泽 = 青 绿 ;根 蒂 = 蜷 缩 ;敲 声 = * ? || (色 泽 = 青 绿 ;根 蒂 = 硬 挺 ;敲 声 = * 5 ] ...
| (色 泽 = 青 绿 ;根 蒂 二蜷 缩 ;敲 声 = 浊 响 )|| (色 泽 = 青 绿 ;根 蒂 = 蜷 缩 ;敲 声 = 沉 闷 )|
有 许 多 可 能 的 选 择 ,如 在路径上自顶向下与自底 向 上 同 时 进 行 ,在 操 作 上 只删除与正例不一致的假 设等.
图 1 . 1 西瓜问题的假设空间
可以有许多策略对这个假设空间进行搜索,例如自顶向下、从一般到特殊,
或 是 自 底 向 上 、从 特 殊 到 一 般 ,搜 索 过 程 中 可 以 不 断 删 除 与 正 例 不 一 致 的 假
设 、和 (或)与 反 例一致的假设.最终将会获得与训练集一致(即对所有训练样本
能够进行正确判断)的假设,这就是我们学得的结果.
需注意的是,现实问题中我们常面临很大的假设空间,但学习过程是基于
有限样本训练集进行的,因此,可能有多个假设与训练集一致,即存在着一个与
训 练 集 一 致 的 “假设集合”,我 们 称 之 为 “版本空间”(version space). 例如,
在西瓜问题中,与 表 1.1训练集所对应的版本空间如图1.2所示.


6 第1章 绪 论
图 1 . 2 西瓜问题的版本空间
尽 可 能 特 殊 即 “适用情 形 尽 可 能 少 ”;尽 可 能 一 般 即 “适 用 情 形 尽 可 能 多”.
对 “根蒂”还 是 对 “敲 声” 更重视,,看起来和属 性 选 择 ,亦 称 “特 征 选
择 ” f(eature selection)有 关,但需注意的是,机器学 习中的特征选择仍是基于 对训练样本的分析进行的, 而在此处我们并非基于特 征 选 择 做 出 对 “根蒂”的 重视;这 里 对 “根 蒂 ” 的 信赖可视为基于某种领域 知识而产生的归纳偏好. 关于特征选择方面的内容 参 见 第 11章.
1 .4 归纳偏好
通过学习得到的模型对应了假设空间中的一个假设.于是,图 1 .2 的西瓜
版 本 空 间 给 我 们 带 来 一 个 麻 烦 :现 在 有 三 个 与 训 练 集 一 致 的 假 设 ,但 与 它 们
对应的模型在面临新样本的时候,却会产生不同的输出.例如,对 (色泽= 青绿;
根蒂= 蜷缩;敲声= 沉闷)这个新收来的瓜,如 果 我 们 采 用 的 是 “好 瓜 o (色
泽 = *)A (根蒂= 蜷缩)A (敲声= *)" ,那么将会把新瓜判断为好瓜,而如果采
用了另外两个假设,则判断的结果将不是好瓜.那么,应该采用哪一个模型(或
假设)呢?
若 仅 有 表 1 .1 中的训练样本,则无法断定上述三个假设中哪一个“更好”.
然 而 ,对 于 一 个 具 体 的 学 习 算 法 而 言 ,它 必 须 要 产 生 一 个 模 型 . 这 时 ,学习算
法 本 身 的 “偏 好 ”就会起到关键的作用.例如,若我们 的 算 法 喜 欢 “尽可能特
殊 ”的模型,则它会选择“好 瓜 分 (色泽= *)A (根蒂= 蜷缩)八(敲声= 浊响)”;
但 若 我 们 的 算 法 喜 欢 “尽 可能 一 般 ”的模型,并 且 由 于 某 种 原 因 它 更 “相 信 ”
根 蒂 ,则它会选择“好 瓜 O (色泽= *)A (根蒂= 蜷缩)八(敲声= *)”. 机器学习
算法在学习过程中对某种类型假设的偏好,称 为 “归纳偏好” i(nductive bias),
或 简 称 为 “偏好”.
任何一个有效的机器学习算法必有其归纳偏好,否则它将被假设空间中看
似 在 训 练 集 上 “等效”的假设所迷惑,而无法产生确定的学习结果.可以想象,
如 果 没 有 偏 好 ,我 们 的 西 瓜 学 习 算 法 产 生 的 模 型 每 次 在 进 行 预 测 时 随 机 抽 选
训练集上的等效假设,那 么 对 这 个 新 瓜 “(色 泽 = 青 绿 ;根蒂= 蜷缩;敲 声 =沉
闷)"学 得 模 型 时 而 告 诉 我 们 它 是 好 的 、时而告诉我们它是不好的,这样的学 习结果显然没有意义. .
归 纳 偏 好 的 作 用 在 图 1 .3 这个回归学习图示中可能更直观.这里的每个训
练样本是图中的一个点(对沙),要学得一个与训练集一致的模型,相当于找到一
条 穿 过 所 有 训 练 样 本 点 的 曲 线 .显 然 ,对 有 限 个 样 本 点 组 成 的 训 练 集 ,存在着
很多条曲线与其一致.我们的学习算法必须有某种偏好,才 能 产 出 它 认 为 “正
确 ”的模型.例如,若认为相似的样本应有相似的输出(例如,在各种属性上都


1 . 4 归纳偏好 7
图 L 3 存在多条曲线与有限样本训练集一致
很相像的西瓜,成熟程度应该比较接近),则对应的学习算法可能偏好图L 3 中
比 较 “平滑”的曲线A 而 不 是 比 较 “崎岖”的曲线B.
归纳偏好可看作学习算法自身在一个可能很庞大的假设空间中对假设进
行 选 择 的 启 发 式 或 “价 值 观 ”. 那 么 ,有没有一般性的原则来引导算法确立
“正确的”偏好呢? “奥卡姆剃刀" (Occam's razor)是一种常用的、 自然科学
研究中最基本的原则,即 “若有多个假设与观察一致,则选最简单的那个”.如
果采用这个原则,并 且 假 设 我 们 认 为 “更平滑”意 味 着 “更简单”(例如曲线
A 更易于描述,其方程式是沙= - 疗 + 6)+ 1 , 而 曲 线 B 则要复杂得多),则在
图 1 .3 中我们会自然地偏好“平滑”的曲线A.
然而,奥卡姆剃刀并非唯一可行的原则.退一步说,即便假定我们是奥卡姆
剃刀的铁杆拥龛,也需注意到,奥卡姆剃刀本身存在不同的诠释,使用奥卡姆剃
刀原则并不平凡.例如对我们已经很熟悉的西瓜问题来说,“假 设 1:好 瓜 分
(色泽= *)A (根蒂= 蜷缩)A (敲 声 =浊 响 )”和 假 设 2: “好 瓜 o (色泽= *)A
(根蒂= 蜷缩)八(敲声= *)”这两个假设,哪 一 个 更 “简单”呢?这个问题并不
简单,需借助其他机制才能解决.
事实上,归 纳 偏 好 对 应 了学习算法本身所做出的关于“什么样的模型更
好 ”的假设.在具体的现实问题中,这个假设是否成立,即算法的归纳偏好是否
与问题本身匹配,大多数时候直接决定了算法能否取得好的性能.
让我们再回头看看图1 3 假设学习算法册基于某种归纳偏好产生了对应
于 曲 线 A 的模型,学习算法观基于另一种归纳偏好产生了对应于曲线B 的模 型 . 基 于 前 面 讨 论 的 平 滑 曲 线 的 某 种 “描 述 简 单 性 ”,我们满怀信心地期待算
法 & 比 观 更 好 . 确 实 ,图 L4(a)显示出,与 B 相比,A 与训练集外的样本更一
致;换言之,A 的泛化能力比B 强.


8 第1章 绪 论
图 L 4 没有免费的午餐.(黑点:训练样本;白点:测试样本)
这里只用到一些非常基 础 的 数 学 知 识 ,只准备读 第 1 章 且 有 “数学恐惧” 的读者可以跳过这个部分 而 不 会 影 响 理 解 ,只需相 信 ,上 面 这 个 看 起 来 “匪 夷所思”的结论确实是成 立的.
但是,且慢!虽 然 我 们 希 望 并 相 信 戏 比 现 更 好 ,但 会 不 会 出 现 图 1.4(b)的
情况:与 A 相比,B 与训练集外的样本更一致?
很 遗 感 这 种 情 况 完 全 可 能 出 现 .换 言 之 ,对 于 一 个 学 习 算 法 戏 ,若它在某
些问题上比学习算法备好,则必然存在另一些问题,在 那 里 观 比 好 . 有 趣
的是,这个结论对任何算法均成立,哪怕是把本书后面将要介绍的一些聪明算
法 作 为 册 而 将 “随机胡猜”这样的笨拙算法作为现.惊讶吗?让我们看看下
面这个简短的讨论:
为简单起见,假 设 样 本 空 间 X 和 假 设 空 间H 都 是 离 散 的 .令 P (用X,£.)
代表算法£a 基于训练数据X 产生假设h 的概率,再令/代表我们希望学习的
真 实 目 标 函 数 .戏 的 “训练集外误差”,即 &在 训 练 集 之 外 的 所 有 样 本 上 的
误差为
若 /均 匀 分 布 ,则有一 半 的 / 对 sc的预测与h(x) 不一致.
E 加 (£a|X") = £ E P Q ) 口仇Q ) # 了3))P (4) X,£a) , (1.1)
h xe^-x
其 中 !(•)是指示函数,若•为真则取值I,否则取值0.
考虑二分类问题,且真实目标函数可以是任何函数" 1 {0,1},函数空间
为,{0,1}用 .对 所 有 可 能 的 ; 按均匀分布对误差求和,有
£ E U £ a | X J ) = £ E £ P Q ) 口(2 ) 壬 / (7) ) P 3 X £ )
f f h xex-x
xex-x h f
= E 口 宏 ) £ 口 九 | 不 £ 石 2团
xeX-X h
= ;2闱 £ P Q ) £ P 3 X , 玛)
xex-x h


1 . 4 归纳偏好 9
= 2 图 -1 £ (1.2) xeX-X
式(1.2)显示出,总误差竟然与学习算法无关!对于任意两个学习算法£ Q 和
心 ,我们都有
£ 旦杷(2 |X , / )= £ & 杷 (& | X J ), (1.3)
ff
也就是说,无 论 学 习 算 法 玛 多 聪 明 、学 习 算 法 观 多 笨 拙 ,它们的期望性能竟
严格的NFL定理证明比 然相同!这 就 是 “没有免费的午餐”定 理 (No Free Lunch Theorem ,简 称 NFL
这里的简化论述繁难得多. 定理)[Wolpert, 1996; Wolpert and Macready, 1995].
这下子,读者对机器学习的热情可能被一盆冷水浇透了:既然所有学习算
法的期望性能都跟随机胡猜差不多,那还有什么好学的?
我们需注意到,N F L 定理有一个重要前提:所 有 “问题”出现的机会相
同、或 所 有 问 题 同 等 重 要 .但 实 际 情 形 并 不 是 这 样 .很 多 时 候 ,我们只关注自
己正在试图解决的问题(例如某个具体应用任务),希望为它找到一个解决方案,
至于这个解决方案在别的问题、甚至在相似的问题上是否为好方案,我们并不
关心.根收口,为 了 快 速 从 A 地 到 达 B 地,如果我 们 正 在 考 虑 的 A 地是南京鼓
楼 、B 地是南京新街口,那 么 “骑自行车”是很好的解决方案;这 个 方 案 对 A
地是南京鼓楼、B 地是北京新街口的情形显然很糟糕,但我们对此并不关心.
事实上,上 面 N F L 定理的简短论述过程中假设了 / 的均匀分布,而实际情
形并非如此.例如,回到我们熟悉的西瓜问题,考虑{假 设 1 : 好 瓜 o (色泽= *)
A (根蒂= 蜷缩)八(敲 声 =浊 响 )}和 {假 设 2 : 好 瓜 分 (色泽= *)A (根蒂= 硬挺)
A (敲 声 =清 脆 )}. 从 N F L 定理可知,这两个假设同样好.我们立即会想到符
合条件的例子,对好瓜(色泽= 青绿;,根蒂= 蜷缩;敲声= 浊响)是 假 设 1 更好,而
对好瓜(色泽= 乌黑;根蒂= 硬挺;敲声= 清脆)则 是 假 设 2 更好.看上去的确是
这 样 .然 而 需 注 意 到 ,“(根 蒂 = 蜷 缩 ;敲声= 浊响)”的好瓜很常见,而 “(根
蒂 =硬 挺 ;敲 声 =清 脆 )”的好瓜罕见,甚至不存在.
所以,N F L 定理最重要的寓意,是让我们清楚地认识到,脱离具体问题,空
泛 地 谈 论 “什么学习算法更好”毫无意义,因为若考虑所有潜在的问题,则所
有学习算法都一样好.要谈论算法的相对优劣,必须要针对具体的学习问题;在
某些问题上表现好的学习算法,在另一些问题上却可能不尽如人意,学习算法
自身的归纳偏好与问题是否相配,往往会起到决定性的作用.


10 第 1 章 绪 论
1 .5 发展历程
所 谓 “知识就是力量”.
1965 年,Feigenbaum 主 持研制了世界上第一个专 家 系 统 DENDRAL.
参 见 p.22.
IW M L 后来发展为国际 机 器 学 习 会 议 ICML.
机器学习是人工智能(artificial intelligence)研究发展到一定阶段的必然产
物.二十世纪五十年代到七十年代初,人 工 智 能 研 究 处 于 “推 理 期 ”,那时人们
以为只要能赋予机器逻辑推理能力,机器就能具有智能.这一阶段的代表性工
作 主 要 有 A. Newell和 H. S im o n 的 “逻 辑 理 论 家 "(Logic Theorist)程序以及
此 后 的 “通 用 问 题 求 解 "(General Problem Solving)程 序 等 这些工作在当时
取得了令人振奋的结果.例如,“逻辑理论家”程 序 在 1952年证明了著名数学
家罗素和怀特海的名著《数学原理》中的 3 8 条定理,在 1963年证明了全部52
条定理,特别值得一提的是,定 理 2.85甚至比罗素和怀特海证明得更巧妙.A.
Newell和 H. S im on因为这方面的工作获得了 1975年图灵奖.然而,随着研究
向前发展,人们逐渐认识到,仅具有逻辑推理能力是远远实现不了人工智能的.
E. A. Feigenbaum 等人认为,要使机器具有智能,就必须设法使机器拥有知识.
在他们的倡导下,从二十世纪七十年代中期开始,人工智能研究进入了 “知识
期 ”.在这一时期,大量专家系统问世,在很多应用领域取得了大量成果.E. A.
Feigenbaum 作 为 “知识工程”之 父 在 1994年获得图灵奖.但是,人们逐渐认
识到 ,专 家 系 统 面 临 “知 识 工 程 瓶 颈 ”,简单地说,就是由人来把知识总结出来
再教给计算机是相当困难的.于是,一些学者想到,如果机器自己能够学习知识
该多好!
事实上,图 灵 在 1 9 5 0 年关于图灵测试的 文章中 ,就曾提到了机器学习的可
能;二十世纪五十年代初已有机器学习的相关研究,例 如 A. S am uel著名的跳
棋程序.五十年代中后期,基 于 神 经 网 络 的 “连 接 主 义 "(coimectionism)学习
开始出现,代表性工作有F. R o se n b la tt的感知机(Perceptron)、B. W idrow 的
A daline等.在六七十年代,基 于 逻 辑 表 示 的 “符 号 主 义 "(symbolism)学习技
术蓬勃发展,代表性工作有P. W in sto n 的 “结构学习系统”、R. S. Michalski
等 人 的 “基于逻辑的归纳学习系统”、E .B . H u n t等 人 的 “概念学习系统”
等;以决策理论为基础的学习技术以及强化学习技术等也得到发展,代表性工
作 有 N. J. N ilson的 “学习机器”等;二十多年后红极一时的统计学习理论的
一些奠基性结果也是在这个时期取得的.
1980年夏,在美国卡耐基梅隆大学举行了第一届机器学习研讨会(IWML);
同年, 《策略分析与信息系统》连出三期机器学习专辑;1983年 ,T io g a 出版社
出版了 R. S. Michalski、J. G. Carbonell 和 T. Mitchell 主 编 的 《机器学习:一
种人工智能途径》[Michalski et a l, 1983],对当时的机器学习研究工作进行了
总结;1986年,第一本机器学习专业期刊Machine Learning创刊;1989年,人


1 . 5 发展历程 11
参见第4 章 . ’
这 时 实 际 是 IL P 的前身.
参 见 第 1 5 章.
工智能领域的权威期刊Artificial Intelligence出版机器学习专辑,刊发了当时
一些比较活跃的研究工作,其 内容后来出现在J. G. Carbonell主 编 、M IT 出
版 社 1990年 的 《机器学习:范型与方法》[Carbonell, 1990]一书中.总的来看,
二十世纪八十年代是机器学习成为一个独立的学科领域、各种机器学习技术
百花初绽的时期.
R. S. Michalski等 人 [Michalski et al., 1983]把机器学习研究划分为“从样
例中学习” “在问题求解和规划中学习” “通过观察和发现学习” “从指令
中学习”等种类;E. A. Feigenbaum等 人 在 著 名 的 《人工智能手册》(第三卷)
[Cohen and Feigenbaum, 1983]中,则把机器学习划分为“机械学习” “示教
学习” “类比学习”和 “归纳学习”.机 械 学 习 亦 称 “死记硬背式学习”,即
把外界输入的信息全部记录下来,在需要时原封不动地取出来使用,这实际上
没有进行真正的学习,仅是在进行信息存储与检索;示教学习和类比学习类似
于 R. S. Michalski等 人 所 说 的 “从指令中学习”和 “通过观察和发现学习”;
归 纳 学 习 相 当 于 “从样例中学习”,即从训练样例中归纳出学习结果.二十世
纪八十年代以来,被研究最多、应 用 最 广 的 是 “从样例中学习”(也就是广义
的归纳学习),它涵盖了监督学习、无监督学习等,本书大部分内容均属此范畴.
下面我们对这方面主流技术的演进做一个简单回顾.
在二十世 纪 八 十 年 代 , “从 样 例 中 学 习 ”的一大主流是符号主义学习,
其代表包括决策树(decision tree)和基于逻辑的学习.典型的决策树学习以信
息 论 为 基 础 ,以 信 息 嫡 的 最 小 化 为 目 标 ,直 接 模 拟 了 人 类 对 概 念 进 行 判 定 的
树形流程.基于逻辑的学习的著名代表是归纳逻辑程序设计 I(nductive Logic
Program m ing,简 称 ILP), 可看作机器学习与逻辑程序设计的交叉,它使用一
阶逻辑(即谓词逻辑)来进行知识表示,通过修改和扩充逻辑表达式(例 如 Prolog
表达式)来完成对数据的归纳.符号主义学习占据主流地位与整个人工智能领域
的发展历程是分不开的.前面说过,人工智能在二十世纪五十到八十年代经历
了 “推理期”和 “知识期”,在 “推理期”人们基于符号知识表示、通过演绎
推理技术取得了很大成就,而 在 “知识期”人们基于符号知识表示、通过获取
和利用领域知识来建立专家系统取得了大量成果,因此,在 “学习期”的开始,
符号知识表示很自然地受到青睐.事实上,机器学习在二十世纪八十年代正是
被 视 为 “解决知识工程瓶颈问题的关键”而走上人工智能主舞台的.决策树学
习技术由于简单易用,到今天仍是最常用的机器学习技术之一. I L P 具有很强
的知识表示能力,可以较容易地表达出复杂数据关系,而且领域知识通常可方
便地通过逻辑表达式进行描述,因此,I L P 不仅可利用领域知识辅助学习,还可


12 第 1 章 绪 论
参 见 第 5 章.
参 见 第 6 章.
参 见 习 题 6.5.
通过学习对领域知识进行精化和增强;然而,成也萧何、败也萧何,由于表示能
力太强,直接导致学习过程面临的假设空间太大、复杂度极高,因此,问题规模
稍大就难以有效进行学习,九十年代中期后这方面的研究相对陷入低潮.
二十世纪九十年代中期之前,“从样例中学习”的另一主流技术是基于神
经网络的连接主义学习.连接主义学习在二十世纪五十年代取得了大发展,但
因为早期的很多人工智能研究者对符号表示有特别偏爱,例 如 图 灵 奖 得 主 H.
Sim on曾断言人工智能是研究“对智能行为的符号化建模”,所以当时连接主
义的研究未被纳入主流人工智能研究范畴.尤其是连接主义自身也遇到了很大
的障碍,正如图灵奖得主M. Minsky和 S. P a p e rt在1969年指出,(当时的)神经
网络只能处理线性分类,甚 至 对 “异或”这么简单的问题都处理不了. 1983年,.
J. J. Hopfield利用神经网络求解“流动推销员问题”这个著名的N P 难题取得
重大进展,使得连接主义重新受到人们关注.1986年,D. E. R um elhart等人重
新发明了著名的B P 算法,产生了深远影响.与符号主义学习能产生明确的概
念 表 示不同,连接主义学习产生的是“黑箱”模型,因此从知识获取的角度来
看,连接主义学习技术有明显弱点;然而,由于有B P 这样有效的算法,使得它
可以在很多现实问题上发挥作用.事实上,BP 一直是被应用得最广泛的机器
学 习 算 法 之 一 .连 接 主 义 学 习 的 最 大 局 限 是 其 “试 错 性 ”;简 单 地 说 ,其学习过
程涉及大量参数,而参数的设置缺乏理论指导,主 要 靠 手 工 “调参”;夸张一点
说,参数调节上失之毫厘,学习结果可能谬以千里.
二十世纪九十年代中期, “统 计 学 习 ”(statistical learning)闪亮登场并
迅速占据主流舞台,代表性技术是支持向量机(Support Vector M achine,简称
SVM)以 及 更 一 般 的 “核 方 法 ”(kernel m e th o d s).这方面的研究早在二十世
纪六七十年代就已开始,统 计 学 习 理 论 [Vapnik, 1998]在那个时期也已打下
了基础,例 如 V. N. Vapnik在 1963年提出了 “支 持 向 量 ”概念,他 和 A. J.
Chervonenkis在 1968年提 出 V C 维,在 1974年提出了结构风险最小化原则等.
但直到九十年代中期统计学习才开始成为机器学习的主流,一方面是由于有效
的 支 持 向 量 机 算 法 在 九 十 年 代 初 才 被 提 出 ,其 优 越 性 能 到 九 十 年 代 中 期 在 文
本分类应用中才得以显现;另一方面,正是在连接主义学习技术的局限性凸显
之后,人们才把目光转向了以统计学习理论为直接支撑的统计学习技术.事实
上,统计学习与连接主义学习有密切的联系.在支持向量机被普遍接受后,核技
巧(kernel tric k )被人们用到了机器学习的几乎每一个角落,核方法也逐渐成为
机器学习的基本内容之一.
有趣的是,二十一世纪初,连接主义学习又卷土重来,掀 起 了 以 “深度学


1 . 6 应用现状 13
参见5.6节. 习” 为名的热潮.所谓深度学习,狭 义 地 说 就 是 “很多层”的神经网络.在若
干 测 试 和 竞 赛 上 ,尤 其 是 涉 及 语 音 、 图像 等 复 杂 对 象 的 应 用 中 ,深 度 学习技术
取得了优越性能.以往机器学习技术在应用中要取得好性能,对使用者的要求
较 高 ;而 深度学 习技 术涉 及的模 型复杂 度非常高 ,以 至 于 只 要 下 工 夫 “调 参 ”,
把参数调节好,性能往往就好.因此,深度学习虽缺乏严格的理论基础,但它显
著降低了机器学习应用者的门槛,为机器学习技术走向工程实践带来了便利.
那么,它为什么此时才热起来呢?有两个基本原因:数据大了、计算能力强了.
“过拟合,,参见第2 章.深度学习模型拥有大量参数,若数据样本少,则 很 容 易 “过拟合”;如此复杂的
模型、如此大的数据样本,若缺乏强力计算设备,根本无法求解.恰由于人类进
入了 “大数据时代”,数据储量与计算设备都有了大发展,才使得连接主义学
习技术焕发又一春.有趣的是,神经网络在二十世纪八十年代中期走红,与当时
In te lx 8 6 系列微处理器与内存条技术的广泛应用所造成的计算能力、数据访
存效率比七十年代有显著提高不无关联.深度学习此时的状况,与彼时的神经
网络何其相似.
需说明的是,机器学习现在已经发展成为一个相当大的学科领域,本节仅
是管中窥豹,很多重要技术都没有谈及,耐心的读者在读完本书后会有更全面
的了解.
1 .6 应用现状
在过 去 二 十 年 中 ,人 类 收 集 、存 储 、传 输 、处理数据的能力取得了飞速提
升,人类社会的各个角落都积累了大量数据,亟需能有效地对数据进行分析利
用的计算机算法,而机器学习恰顺应了大时代的这个迫切需求,因此该学科领
域很自然地取得巨大发展、受到广泛关注.
今 天 ,在计算机 科学 的 诸 多 分 支 学 科 领 域 中 ,无 论 是 多 媒 体 、 图形学,还是
网 络 通 信 、软 件 工 程 ,乃 至 体 系 结 构 、芯 片 设 计 ,都能找 到 机 器 学 习 技 术 的 身
影,尤其是在计算机视觉、 自然语言处理等“计算机应用技术”领域,机器学
习已成为最重要的技术进步源泉之一.
机 器 学 习 还 为 许 多 交叉学科提供了重要的技术支撑.例如,“生物信息
学 ”试图利用信息技术来研究生命现象和规律,而基因组计划的实施和基因药
物 的 美 好愿景让人们为之心潮澎湃.生物信息学研究涉及从“生命现象”到
“规律发现”的整个过程,其间必然包括数据获取、数据管理、数据分析、仿
真实验等环节,而 “数据分析”恰是机器学习技术的舞台,各种机器学习技术
已经在这个舞台上大放异彩.


14 第 1 章 绪 论
NASA-JPL的全称是美 国航空航天局喷气推进实 验室,著 名 的 “勇气”号 和 “机遇”号火星机器人 均是在这个实验室研制的.
DARPA的全称是美国 国防部先进研究计划局, 互联网、全球卫星定位系 统 等 都 源 于 DARPA启动 的研究项目.
机器学习提供数据分析 能力,云计算提供数据处 理 能 力 ,众 包 提 供 数 据 标 记能力.
“数据挖掘”这个词很 早就在统计学界出现并略 带贬义,这是由于传统统 计学研究往往醉心于理论 的优美而忽视实际效用. 但 最 近 情 况 发 生 变 化 ,越 来越多的统计学家开始关 注 现 实 问 题 ,进入 机 器 学 习和数据挖掘领域.
事实上,随 着 科 学 研 究 的 基 本 手 段 从 传 统 的 “理论+ 实 验 ”走向现在的
“理论+ 实验十计算”,乃 至 出 现 “数据科 学 ”这样的提法,机器学习的重要
性日趋显著,因 为 “计算”的目的往往是数据分析,而数据科学的核心也恰是
通 过 分 析 数 据 来 获 得 价 值 .若 要 列 出 目 前 计 算 机 科 学 技 术 中 最 活 跃 、最受瞩
目的研究分支,那 么 机 器 学 习 必 居 其 中 .2001年,美 国 N A S A -JP L 的科学家
在 Science杂 志 上 专 门 撰 文 [Mjolsness and DeCoste, 2001]指出,机器学习对
科学研究的整个过程正起到越来越大的支撑作用,其进展对科技发展意义重大.
2003年,D A R P A 启 动 P A L 计划,将机器学习的重要性上升到美国国家安全的
高度来考虑.众所周知,美国最尖端科技的研究通常是由N A S A 和 D A R PA 推
进的,而这两大机构不约而同地强调机器学习的重要性,其意义不言而喻.
2 0 0 6 年 ,卡 耐 基 梅 隆 大 学 宣 告 成 立 世 界 上 第 一 个 “机 器 学 习 系 ”,机器学
习领域奠基人之一 T. M itchell教授出任首任系主任.2012年 3 月,美国奥巴马
政 府 启 动 “大数据研究与发展计划”,美国国家科学基金会旋即在加州大学伯
克利分校启动加强计划,强调要深入研究和整合大数据时代的三大关键技术:
机器学习、云计算、众包(crow dsourcing).显然,机器学习在大数据时代是必
不可少的核心技术,道 理很简单:收集、存 储 、传 输 、管理大数据的目的,是为
了 “利用”大数据,而如果没有机器学习技术分析数据,则 “利用”无从谈起.
谈到对数据进行分析利用,很 多 人 会 想 到 “数据挖掘”(data m in in g ),这
里简单探讨一下数据挖掘与机器学习的联系.数据挖掘领域在二十世纪九十年
代 形 成 ,它 受 到 很 多 学 科 领 域 的 影 响 ,其 中 数 据 库 、机 器 学 习 、统 计学无疑影
响 最 大 [Zhou, 2003 .]数据挖掘是从海量数据中发掘知识,这就必然涉及对“海
量 数 据 ”的 管 理 和 分 析 .大 体 来 说 ,数 据 库 领 域 的 研 究 为 数 据 挖 掘 提 供 数 据 管
理技术,而机器学习和统计学的研究为数据挖掘提供数据分析技术.由于统计
学界的研究成果通常需要经由机器学习研究来形成有效的学习算法,之后再进
入数据挖掘领域,因此从这个意义上说,统计学主要是通过机器学习对数据挖
掘发挥影响,而机器学习领域和数据库领域则是数据挖掘的两大支撑.
今天,机器学习已经与普通人的生活密切相关.例如在天气预报、能源勘
探 、环境监测等方面,有效地利用机器学习技术对卫星和传感器发回的数据进
行分析,是提高预报和检测准确性的重要途径;在商业营销中,有效地利用机器
学习技术对销售数据、客户信息进行分析,不仅可帮助商家优化库存降低成本,
还有助于针对用户群设计特殊营销策略;......下面再举几例:
众 所 周 知 ,谷 歌 、百 度 等 互 联 网 搜 索 引 擎 已 开 始 改 变 人 类 的 生 活 方 式 ,例
如很多人已习惯于在出行前通过互联网搜索来了解目的地信息、寻找合适的


1 . 6 应用现状 15
例如著名机器学习教科 书 [Mitchell, 1997] 4.2 节介 绍了二十世纪九十年代早 期利用神经网络学习来控 制 自 动 驾 驶 车 的 ALVINN 系统.
酒店、餐 馆 等 .美 国 《新闻周刊》 曾对谷歌有一句话评论:“它使任何人离任
何问题的答案间的距离变得只有点击一下鼠标这么远」 显然,互联网搜索是
通过分析网络上的数据来找到用户所需的信息,在这个过程中,用户查询是输
入 、搜索结果是输出,而要建立输入与输出之间的联系,内核必然需要机器学
习 技 术 .事 实 上 ,互 联 网 搜 索 发 展 至 今 ,机 器 学 习 技 术 的 支 撑 居 功 至 伟 .到 了 今
天,搜索的对象、 内容日趋复杂,机器学习技术的影响更为明显,例如在进行
“图片搜索”时,无论谷歌还是百度都在使用最新潮的机器学习技术.谷歌、
百 度 、脸 书 、雅 虎 等 公 司 纷 纷 成立专攻机器学习技术的研究团队,甚至直接以
机器学习技术命名的研究院,充分体现出机器学习技术的发展和应用,甚至在
一定程度上影响了互联网产业的走向.
再举一例.车祸是人类最凶险的杀手之一,全世界每年有上百万人丧生车
轮 ,仅 我 国 每 年 就 有 约 十 万 人 死 于 车 祸 .由 计 算 机 来 实 现 自 动 汽 车 驾 驶 是 一 个
理想的方案,因为机器上路时可以确保不是新手驾驶、不会疲劳驾驶,更不会
酒后驾驶,而且还有重要的军事用途.美国在二十世纪八十年代就开始进行这
方面研究.这里最大的困难是无法在汽车厂里事先把汽车上路后所会遇到的所
有情况都考虑到、设计出处理规则并加以编程实现,而只能根据上路时遇到的 情 况 即 时 处 理 .若 把 车 载 传 感 器 接 收 到 的 信 息 作 为 输 入 ,把 方 向 、刹 车 、油门
的控制行为作为输出,则这里的关键问题恰可抽象为一个机器学习任务.2004
年 3 月,在 美 国 D A R PA 组织的自动驾驶车比赛中,斯坦福大学机器学习专家
S. T h ru n 的小组研制的参赛车用6 小 时 5 3 分钟成功走完了 132英里赛程获得
冠军.比赛路段是在内华达州西南部的山区和沙漠中,路况相当复杂,在这样的
路段上行车即使对经验丰富的人类司机来说也是一个挑战.S. T h ru n 后来到谷
歌领导自动驾驶车项目团队.值得一提的是,自动驾驶车在近几年取得了飞跃
式 发 展 ,除谷歌外,通 用 、奥 迪 、大 众 、宝 马 等 传 统 汽 车公司均 投入巨 资进行
研发,目前已开始有产品进入市场.2011年 6 月,美国内华达州议会通过法案,
成 为 美 国 第 一 个 认 可 自 动 驾 驶 车 的 州 ,此 后 ,夏 威 夷 州 和 佛 罗 里 达 州 也 先 后 通
过类似法案.自动驾驶汽车可望在不久的将来出现在普通人的生活中,而机器
学习技术则起到了 “司机”作用.
机 器 学 习 技 术 甚 至 已 影 响 到 人 类 社 会 政 治 生 活 .2 0 1 2 年 美 国 大 选 期 间 ,奥
巴马麾下有一支机器学习团队,他们对各类选情数据进行分析,为奥巴马提示
下一步竞选行动.例如他们使用机器学习技术分析社交网络数据,判断出在总
统候选人第一次辩论之后哪些选民会倒戈,并根据分析的结果开发出个性化宣
传策略,能为每位选民找出一个最有说服力的挽留理由;他们基于机器学习模


16 第 1 章 绪 论
W EKA是著名的免费 机 器 学 习 算 法 程 序 库 ,由 新 西 兰 W aikato大学研 究 人 员 基 于 J A V A 开发: h ttp ://w w w .cs.wai kato. a c .n z/m l/w e ka /.
型的分析结果提示奥巴马应去何处开展拉票活动,有些建议甚至让专业竞选顾
问 大吃一惊,而 结 果 表 明 去 这 些 地 方 大 有 收 获 .总 统 选 举 需 要 大 量 金 钱 ,机器
学 习 技 术 在 这 方 面 发 挥 了 奇 效 . 例 如 ,机 器 学 习 模 型 分 析 出 ,某 电 影 明 星 对 某
地区某年龄段的特定人群很有吸引力,而这个群体很愿意出高价与该明星及奥
巴马共进晚餐... ...果 然 ,这 样 一 次 筹 资 晚 宴 成 功 募 集 到 1 5 0 0 万 美 元 ;最 终 ,借
助机器学习模型,奥巴马筹到了创纪录的1 0 亿美元竞选经费.机器学习技术不
仅 有 助 于 竞 选 经 费 “开源”,还 可 帮 助 “节 流 ”,例如机器学习模型通过对不
同群体选民进行分析,建议购买了一些冷门节目的广告时段,而没有采用在昂
贵 的 黄 金 时 段 购 买 广 告 的 传 统 做 法 ,使 得 广 告 资 金 效 率 相 比 2 0 0 8 年竞选提高
了 1 4 % ;......胜选后, 《时代》周刊专门报道了这个被奥巴马称为“竞选核武
器 ”、由半监督学习研究专家R. G h a n i领导的团队.
值得一提的是,机器学习备受瞩目当然是由于它已成为智能数据分析技术
的创新源泉,但机器学习研究还有另一个不可忽视的意义,即通过建立一些关
于学习的计算模型来促进我们理解“人类如何学习”.例 如 ,P. K anerva在二
十世纪八 十 年 代 中 期 提 出 SDM (Sparse Distributed Memory)模 型 [Kanerva,
1988]时并没有刻意模仿脑生理结构,但后来神经科学的研究发现,S D M 的稀
疏编码机制在视觉、听觉、嗅觉功能的脑皮层中广泛存在,从而为理解脑的某
些功能提供了一定的启发.自然科学研究的驱动力归结起来无外是人类对宇宙
本源、万物本质、生命本性、 自我本识的好奇,而 “人类如何学习”无疑是一
个有关自我本识的重大问题.从这个意义上说,机器学习不仅在信息科学中占
有重要地位,还具有一定的自然科学探索色彩.
1 .7 阅读材料
[Mitchell, 1997]是 第 一 本 机 器 学 习 专 门 性 教 材 ,[Duda et al., 2001; Al
paydin, 2004; Flach, 2012]都是出色的入门读物. [Hastie et al., 2009]是很好
的进阶读物,[Bishop, 2006]也很有参考价值,尤其适合于贝叶斯学习偏好者.
S[halev-Shwartz and Ben-David, 2014]则适合于理论偏好者. [W itten et al.,
2011]是 基 于 W E K A 撰写的入门读物,有助于初学者通过W E K A 实践快速掌
握常用机器学习算法.
本 书 1 .5 和 1 .6 节 主 要 取 材 于 [周志华, 2007 .] 《机器学习:一种人工智能
途径》[Michalski et al., 1983]汇集了 2 0 位学者 撰 写 的 1 6 篇文章,是机器学习
早期最重要的文献.该书出版后产生了很大反响,Morgan K aufm ann出版社后
来 分 别 于 1986年 和 1990年出版了该书的续篇,编 为 第 二 卷 和 第 三 卷 .《人工


1 . 7 阅读材料 17
深度学习参见5 .6 节.
规则学习参见第15章.
集成学习参见第8 章.
智能手册》系列是图灵奖得主E. A. Feigenbaum与不同学者合作编写而成,该
书 第 三 卷 [Cohen and Feigenbaum, 1983]对机器学习进行了讨论,是机器学习
早期的重要文献. [Dietterich, 1997]对机器学习领域的发展进行了评述和展望.
早期的很多文献在今天仍值得重视,一些闪光的思想在相关技术进步后可能焕
发新的活力,例 如 近 来 流 行 的 “迁 移 学 习 "(transfer learning) [Pan and Yang,
2010],恰 似 “类比学习”(learning by analogy)在统计学习技术大发展后的升
级版;红 极 一 时 的 “深 度 学 习 "(deep learning)在思想上并未显著超越二十世
纪八十年代中后期神经网络学习的研究.
机 器 学 习 中 关 于 概 念 学 习 的 研 究 开 始 很 早 ,从 中 产 生 的 不 少 思 想 对 整 个
领 域 都 有 深 远 影 响 .例 如 作 为 主 流 学 习 技 术 之 一 的 决 策 树 学 习 ,就 起 源 于 关
于 概 念 形 成 的 树 结 构 研 究 [Hunt and Hovland, 1963]. [Winston, 1970]在著
名 的 “积木世界”研究中,将概念学习与基于泛化和特化的搜索过程联系起
来. [Simon and Lea, 1974]较早提出了 “学 习 ”是在假设空间中搜索的观点.
[Mitchell, 1977]稍后提出了版本空间的概念.概念学习中有很多关于规则学习
的内容.
奥卡姆剃刀原则主张选择与经验观察一致的最简单假设,它在自然科学如
物理学、天文学等领域中是一个广为沿用的基础性原则,例如 哥 白 尼 坚 持 “日
心 说 ”的理由之一就是它比托勒密的“地 心 说 ”更简单且符合天文观测.奥
卡姆剃刀在机器学习领域也有很多追随者[Blumer et al., 1996].但机器学习
中 什 么 是 “更简单的”这个问题一直困扰着研究者们,因此,对奥卡姆剃刀在
机器学习领域的作用一直存在着争议[Webb, 1996; Domingos, 1999].需注意
的是,奥卡姆剃刀并非科学研究中唯一可行的假设选择原则,例如古希腊哲学
家伊壁鸠鲁(公元前341年-前270年 )提 出 的 “多 释 原 则 "(principle of multiple
explanations),主张保留与经验观察一致的所有假设[Asmis, 1984],这与集成
学习(ensemble learning)方面的研究更加吻合.
机 器 学 习 领 域 最 重 要 的 国 际 学 术 会 议 是 国 际 机 器 学 习 会 议 (IC M L )、 国际
神经信息处理系统会议(NIPS)和国际学 习 理 论 会 议 (C O L T ),重要的区域性会
议 主 要 有 欧 洲 机 器 学 习 会 议 (ECML)和 亚 洲 机 器 学 习 会 议 (A C M L );最重要的
国际学术期刊是 Journal ofMachine Learning Research 和 Machine Learning.
人工智能领域的重要会议如UCAL A A A I以及重要期刊如Artificial Intelli
gence> Journal ofArtificial Intelligence Research1 数据挖掘领域的重要会议
如 KDD、ICDM 以及重要期刊如 A C M Transactions on Knowledge Discovery
from Data、Data Mining and Knowledge Discovery,计算机视觉与模式识别


18 第 1 章 绪 论
领域的重要会议如C V P R 以及重要期刊如IEEE Transactions on Pattern
Analysis and Machine 7n力eZgevice,神经网络领域的重要期刊如Neural Com
putation> IEEE Transactions on Neural Networks and Learning Systems 等
也经常发表机器学习方面的论文.此外,统计学领域的重要期刊如Annals of
Statistics等也常有关于统计学习方面的理论文章发表.
国内不少书籍包含机器学习方面的内容,例如[陆汝铃,1 9 9 6 ] .[李航, 2012]
是以统计学习为主题的读物.国内机器学习领域最主要的活动是两年一次
的中国机器学习大会(CCML)以 及 每 年 举 行 的 “机器学习及其应用”研讨
会(M LA);很多学术刊物都经常刊登有关机器学习的论文.


习题 19
习题
1.1 表 1 .1 中若只包含编号为1 和 4 的两个样例,试给出相应的版本空间.
1.2 与使用单个合取式来进行假设表示相比,使 用 “析合范式”将使得假 析合范式即多个合取式
的析取. 设空间具有更强的表示能力.例如
好 瓜 什 ((色 泽 = *)A (根蒂= 蜷缩)A (敲声= *))
V ((色泽=乌黑)八(根蒂= *)A (敲声= 沉闷)}
会 把 “(色 泽 =青 绿 )A (根蒂= 蜷缩)A (敲 声 =清 脆 )”以 及 “(色 泽 =
提示:注意冗余情况, 如 (A = a)V (A = *) 与 (4 = *)等价.
乌黑)A (根蒂= 硬挺)A (敲声=沉 闷 )”都 分 类 为 “好瓜”.若使用最
多包含k 个合取式的析合范式来表达表1.1西瓜分类问题的假设空
间,试估算共有多少种可能的假决
即不存在训练错误为0 的假设.
1.3 若数据包含噪声,则假设空间中有可能不存在与所有训练样本都一致
的假设.在此情形下,试设计一种归纳偏好用于假设选择.
1.4 * 本 章 1.4节 在 论 述 “没有免费的午餐”定理时,默认使用了 “分类错 误率,,作为性能度量来对分类器进行评估.若换用其他性能度量2 ,则
式 (1.1)将改为
% e (£ a |X ,/)= £ £ P Q )4 (h Q )J Q ))P /(l |X ,£ a ),
h xeX -X
试 证 明 “没有免费的午餐定理”仍成立.
1.5 试述机器学习能在互联网搜索的哪些环节起什么作用.


20 第 1 章 绪 论
参考文献
陆汝铃.(1996).人 工 智 能 (下 册 ).科学出版社,北京.
周志华.(2007). “机器学习与数据挖掘中国计算机学会通讯,3(12):35-44.
李航.(2012).统计学习方法.清华大学出版社,北京.
Alpaydin, E. (2004). Introduction to Machine Learning. MIT Press, Cambridge,
MA.
Asmis, E. (1984). Epicurus Scientific Method. Cornell University Press, Ithaca,
NY.
Bishop, C. M. (2006). Pattern Recognition and Machine Learning. Springer,
New York, NY.
Blumer, A., A. Ehrenfeucht, D. Haussler, and M. K. Warmuth. (1996). uOc
cam's razor? Information Processing Letters, 24(6):377-380.
Carbonell, J. G., ed. (1990). Machine Learning: Paradigms and Methods. MIT
Press, Cambridge, MA.
Cohen, P. R. and E. A. Feigenbaum, eds. (1983). The Handbook of Artificial
Intelligence^ volume 3. William Kaufmann, New York, NY.
Dietterich, T. G. (1997), “Machine learning research: Four current directions.55
A I Magazine118(4):97-136.
Domingos, P. (1999). “The role of Occam's razor in knowledge discovery." Data
Mining and Knowledge Discovery^ 3(4):409-425.
Duda, R. O., P. E. Hart, and D. G. Stork. (2001). Pattern Classification^ 2nd
edition. John Wiley & Sons, New York, NY.
Flach, P. (2012). Machine Learning: The Art and Science of Algorithms that
Make Sense of Data. Cambridge University Press, Cambridge, UK.
Hand, D., H. Mannila, and P. Smyth. (2001). Principles of Data Mining. MIT
Press, Cambridge, MA.
Hastie, T., R. Tibshirani, and J. Friedman. (2009). The Elements of Statistical
Learning)2nd edition. Springer, New York, NY.
Hunt, E. G. and D. I. Hovland. (1963). aProgramming a model of human con
cept formation.,5 In Computers and Thought (E. Feigenbaum and J. Feldman,
eds.), 310-325, McGraw Hill, New York, NY.


参考文献 21
Kanerva, P. (1988). Sparse Distributed Memory. MIT Press, Cambridge, MA.
Michalski, R. S., J. G. Carbonell, and T. M. Mitchell, eds. (1983). Machine
Learning: An Artificial Intelligence Approach. Tioga, Palo Alto, CA.
Mitchell, T. (1997). Machine Learning. McGraw Hill, New York, NY.
Mitchell, T. M. (1977). “Version spaces: A candidate elimination approach to
rule le a rn in g .In Proceedings of the 5th International Joint Conference on
Artificial Intelligence (IJCAI)1 305-310, Cambridge, MA.
Mjolsness, E. and D. DeCoste. (2001). “Machine learning for science: State of
the art and future prospects? Science^ 293(5537):2051-2055.
Pan, S. J. and Q. Yang. (2010). “A survey of transfer learning.” IEEE Trans
actions on Knowledge and Data Engineering^ 22(10):1345-1359.
Shalev-Shwartz, S. and S. Ben-David. (2014). Understanding Machine Learn
ing. Cambridge University Press, Cambridge, UK.
Simon, H. A. and G. Lea. (1974). “Problem solving and rule induction: A
unified view." In Knowledge and Cognition (L. W. Gregg, ed.), 105-127,
Erlbaum, New York, NY.
Vapnik, V. N. (1998). Statistical Learning Theory. Wiley, New York, NY.
Webb, G. I. (1996), “Further experimental evidence against the utility of Oc
cam^ razor.,, Journal of Artificial Intelligence Research1 43:397-417.
Winston, P. H. (1970). “Learning structural descriptions from examples.” Tech
nical Report AI-TR-231, AI Lab, MIT, Cambridge, MA.
Witten, I. H., E. Frank, and M. A. Hall. (2011). Data Mining: Practical Ma
chine Leaving Tools and Techniques^ 3rd edition. Elsevier, Burlington, MA.
Wolpert, D. H. (1996). “The lack of a priori distinctions between learning al
gorithms.55 Neural Computation1 8(7):1341-1390.
Wolpert, D. H. and W. G. Macready. (1995). "No free lunch theorems for
search.” Technical Report SFI-TR-05-010, Santa Fe Institute, Sante Fe,
NM.
Zhou, Z.-H. (2003). uThree perspectives of data minmg.^^ Artificial Intelligence1
143(1):139-146.


22 第 1 章 绪 论
休息一会儿
这个跳棋程序实质上使 用 了 强 化 学 习 技 术 ,参见 第 16章.
小故事: “机器学习”名字的由来
1952 年,阿 瑟 . 萨 缪 尔 (Arthur Samuel, 1901—1990)
在 IB M 公司研制了 一个西洋跳棋程序,这个程序具有自
学习能力,可通过对大量棋局的分析逐渐辨识出当前局面
下 的 “好棋”和 “坏棋”,从而不断提高弈棋水平,并很
快就下赢了萨缪尔自己. 1956年,萨 缪 尔 应 约 翰 ・麦卡锡
(John McCarthy, “人工智能之父”,1971年图灵奖得主)之邀,在标志着人
工智能学科诞生的达特茅斯会议上介绍这项工作.萨缪尔发明了 “机器学习”
这个词,将 其 定 义 为 “不显式编程地赋予计算机能力的研究领域”.他 的 文
章 “Some studies in machine learning using the game of checkers” 1959 年在
IBM Journal正式发表后,爱 德 华 • 费 根 鲍 姆 (Edward Feigenbaum, “知识工
程 之 父 " 1994年图灵奖得主)为编写其巨著Computers and Thought,在 1961
年邀请萨缪尔提供一个该程序最好的对弈实例.于是,萨缪尔借机向康涅狄格
州的跳棋冠军、 当时全美排名第四的棋手发起了挑战,结果萨缪.尔程序获胜,
在当时引起轰动.
事实上,萨缪尔跳棋程序不仅在人工智能领域产生了重大影响,还影响到
整个计算机科学的发展.早期计算机科学研究认为,计算机不可能完成事先没
有显式编程好的任务,而萨缪尔跳棋程序否证了这个假设.另外,这个程序是最
早在计算机上执行非数值计算任务,的程序之一,其逻辑指令设计思想极大地影
响了 IB M 计算机的指令集,并很快被其他计算机的设计者采用.


第2 章模型评估与选择
精度常写为百分比形式 (1 一 言 )x 100%.
这 里 所 说 的 “误差”均 指误差期望.
在后面的章节中将介绍 不同的学习算法如何最小 化经验误差.
过 拟 合 亦 称 “过配”.
欠 拟 合 亦 称 “欠配”.
学 习 能 力 是 否 “过于强 大”,是 由 学 习 算 法 和 数 据内涵共同决定的.
2 .1 经验误差与过拟合
通 常 我 们 把 分 类 错 误 的 样 本 数 占 样 本 总 数 的 比 例 称 为 “错 误 率 ”(error
r a te ) ,即如果在m 个样本中有a 个样本分类错误,则错误率E = a / m ; 相应的,
1 —a / m 称 为 “精度”(accuracy),即 “精度= 1—错误率”.更一般地,我们把
学 习 器 的 实 际 预 测 输 出 与 样 本 的 真 实 输 出 之 间 的 差 异 称 为 “误 差 ”(error),
学 习 器 在 训 练 集 上 的 误 差 称 为 “训 练 误 差 ”(training error)或 “经验误
差 ”(empirical e rro r),在 新 样 本 上 的 误 差 称 为 “泛 化 误 差 ”(generalization
e r r o r ) .显然,我们希望得到泛化误差小的学习器.然而,我们事先并不知道新
样本是什么样,实际能做的是努力使经验误差最小化.在很多情况下,我们可以
学得一个经验误差很小、在训练集上表现很好的学习器,例如甚至对所有训练
样本都分类正确,即分类错误率为零,分类精度为100% ,但这是不是我们想要
的学习器呢?遗憾的是,这样的学习器在多数情况下都不好.
我 们 实 际 希 望 的 ,是 在 新 样 本 上 能 表 现 得 很 好 的 学 习 器 .为 了 达 到 这 个
目的,应该从训练样本中尽可能学出适用于所有潜在样本的“普 遍 规 律 " 这
样 才 能 在 遇 到 新 样 本 时 做 出 正 确 的 判 别 .然 而 ,当 学 习 器 把 训 练 样 本 学 得 “太
好 ”了的时候,很可能已经把训练样本自身的一些特点当作了所有潜在样本都
会具有的一般性质,这样就会导致泛化性能下降.这种现象在机器学习中称为
“过拟合" (overfitting).与 “过拟合”相 对 的 是 “欠拟合" (im derRtting),这
是指对训练样本的一般性质尚未学好.图2 .1 给出了关于过拟合与欠拟合的一
个便于直观理解的类比.
有多种因素可能导致过拟合,其中最常见的情况是由于学习能力过于强大,
以 至 于 把 训 练 样 本 所 包 含 的 不 太 一 般 的 特 性 都 学 到 了 ,而 欠 拟 合 则 通 常 是 由
于学习能力低下而造成的.欠拟合比较容易克服,例如在决策树学习中扩展分
支 、在神经网络学习中增加训练轮数等,而过拟合则很麻烦.在后面的学习中
我们将看到,过拟合是机器学习面临的关键障碍,各类学习算法都必然带有一
些针对过拟合的措施;然而必须认识到,过拟合是无法彻底避免的,我们所能做
的 只 是 “缓解”,或者说减小其风险.关于这一点,可大致这样理解:机器学习
面临的问题通常是N P 难甚至更难,而有效的学习算法必然是在多项式时间内


24 第 2 章 模 型 评 估 与 选 择
新 样采
过拟合模型分类结果: f 不是树叶 (误 以 为 树 叶 必 须 有 锯 齿 )
.欠拟合模型分类结果: 是树叶 (误 以 为 绿 色 的 都 是 树 叶 )
图 2.1 过 拟合、欠拟合的直观类比
运行完成,若可彻底避免过拟合,则通过经验误差最小化就能获最优解,这就意
味着我们构造性地证明了 “P =N P” ;因此,只 要 相 信 “P * NP” ,过拟合就
不可避免.
在现实任务中,我们往往有多种学习算法可供选择,甚至对同一个学习算
法 ,当使用 不 同 的 参 数 配 置 时 ,也 会 产 生 不 同 的 模 型 .那 么 ,我们该选用哪一个
学习算法、使用哪一种参数配置呢?这 就 是 机 器 学 习 中 的 “模 型 选 择 ”(model
s e le c t io n )问 题 .理 想 的 解 决 方 案 当 然 是 对 候 选 模 型 的 泛 化 误 差 进 行 评 估 ,然后
选择泛化误差最小的那个模型.然而如上面所讨论的,我们无法直接获得泛化
误差,而训练误差又由于过拟合现象的存在而不适合作为标准,那么,在现实中
如何进行模型评估与选择呢?
2 . 2 评估方法
在现实任务中往往还会 考 虑 时 间 开 销 、存储开 销 、可解释性等方面的因 素,这里暂且只考虑泛化 误差.
通常,我们可通过实验测试来对学习器的泛化误差进行评估并进而做出选
择 .为 此 需 使 用 一 个 “测试集”(testing set)来测试学习器对新样本的判别能
力,然后以测试集上的“测试误差”(testing error)作为泛化误差的近似.通常
我们假设测试样本也是从样本真实分布中独立同分布采样而得.但需注意的
是,测试集应该尽可能与训练集互斥,即测试样本尽量不在训练集中出现、未
在训练过程中使用过.
测试样本为什么要尽可能不出现在训练集中呢?为理解这一点,不妨考虑
这样一个场景:老师出了 1 0 道习题供同学们练习,考试时老师又用同样的这10
道题作为试题,这个考试成绩能否有效反映出同学们学得好不好呢?答案是否
定的,可能有的同学只会做这1 0 道题却能得高分.回到我们的问题上来,我们


2 . 2 评估方法 25
参 见 习 题 2.1.
同时可得估计结果的标 准差.
希望得到泛化性能强的模型,好比是希望同学们对课程学得很好、获得了对所
学 知 识 “举一反三”的能力;训练样本相当于给同学们练习的习题,测试过程
则 相 当 于 考 试 .显 然 ,若测试样本被用作训练了,则 得 到 的 将 是 过 于 “乐 观 ”的
估计结果.
可是,我 们 只 有 一 个 包 含 m 个 样 例 的 数 据 集 0 = {(11,阴),(也 欤 ),... ,
既要训练,又要测试,怎样才能做到呢?答案是:通 过 对 。 进行适当
的处理,从中产生出训练集S 和测试集T . 下面介绍几种常见的做法.
2 .2 .1 留出法
“留出法”(hold-out)直接将数据集。 划分为两个互斥的集合,其中一个
集合作为训练集S , 另一个作为测试集T , 即 0 = S U T, S n T = 0 . 在 S 上训
练出模型后,用 T 来评估其测试误差,作为对泛化误差的估计.
以二分类任务为例,假定D 包 含 1000个样本,将其划分为S 包 含 700个样
本,T 包 含 300个样本,用 S 进行训练后,如果模型在T 上 有 9 0 个样本分类错
误,那么其错误率为(90/300) x 100% = 3 0 % ,相应的,精 度 为 1 - 30% = 70%.
需 注 意 的 是 ,训 练 /测 试 集 的 划 分 要 尽 可 能 保 持 数 据 分 布 的 一 致 性 ,避免
因 数 据 划 分 过 程 引 入 额 外 的 偏 差 而 对 最 终 结 果 产 生 影 响 ,例 如 在 分 类 任 务 中
至 少 要 保 持 样 本 的 类 别 比 例 相 似 .如 果 从 采 样 (sam pling)的角度来看待数据
集的划分过程,则保留类别比例的采样方式通常称为“分 层 采 样 "(stratified
sam p lin g ).例如通 过 对D 进行分层采样而获得含70% 样本的训练集S 和含
30% 样本的测试集T,若D 包含5 0 0 个正例、5 0 0 个反例,则分层采样得到的
S 应 包 含 3 5 0 个正例、3 5 0 个反例,而 T 则 包 含 150个 正 例 和 150个反例;若
S 、T 中样本类别比例差别很大,则误差估计将由于训练/测试数据分布的差异
而产生偏差.
另一个需注意的问题是,即便在给定训练/测试集的样本比例后,仍存在多
种划分方式对初始数据集。 进行分割.例如在上面的例子中,可以 把 0 中的样
本排序,然 后 把 前 3 5 0 个正例放到训练集中,也可以把最后3 5 0 个正例放到训
练集中,......这些不同的划分将导致不同的训练/测试集,相应的,模型评估的
结果也会有差别.因此,单次使用留出法得到的估计结果往往不够稳定可靠,在
使用留出法时,一般要采用若干次随机划分、重复进行实验评估后取平均值作
为 留 出 法 的 评 估 结 果 .例 如 进 行 1 0 0 次随机划分,每次产生一个训练/测试集用
于实验评估,1 0 0 次 后 就 得 到 1 0 0 个 结 果 ,而 留 出 法 返 回 的 则 是 这 1 0 0 个结果的
平均.
此外,我 们 希 望 评 估 的 是 用 。 训练出的模型的性能,但留出法需划分训


26 第 2 章模型评估与选择
可 从 “偏 差 -方 差 ” (参 见 2 .6 节)的角度来理解: 测 试 集 小 时 ,评 估 结 果 的 方差较大;训 练 集 小 时,评 估结果的偏差较大.
一 般 而 言 ,测 试 集 至 少 应 含 3 0 个 样 例 [Mitchell, 1997].
亦 称 “ k 倍交叉验证”.
练/测试集,这就会导致一个窘境:若 令训练集S 包含绝大多数样本,则训练出
的模型可能更接近于用D 训练出的模型,但 由 于T 比较小,评估结果可能不够
稳定准确;若令测试集T 多包含一些样本,则 训 练 集 S 与 。 差别更大了,被评
估的模型与用D 训练出的模型相比可能有较大差别,从而降低了评估结果的保
真性(fid elity).这个问题没有完美的解决方案,常见做法是将大约2 / 3 〜 4 / 5 的
样本用于训练,剩余样本用于测试.
2 . 2 . 2 交叉验证法
“交叉验证法”(cross validation)先 将 数 据 集 D 划 分 为 k 个大小相似的
互斥子集,即 。 = U 。2 u ... u Ok, R n . ♦ = 0 (分多j ) 每 个 子 集 Di都
尽可能保持数据分布的一致性,即 从 。 中 通 过 分 层 采 样 得 到 .然 后 ,每次用
k - 1 个子集的并集作为训练集,余下的那个子集作为测试集;这样就可获得k
组训练/测试集,从 而 可 进 行k 次训练和测试,最 终 返 回 的 是 这k 个测试结果
的 均 值 .显 然 ,交 叉 验 证 法 评 估 结 果 的 稳 定 性 和 保 真 性 在 很 大 程 度 上 取 决 于 k
的取值,为强调这一点,通常把交叉验证法称为“k 折交叉验证”(k-fold cross
validation), k 最 常 用 的取值是1 0 , 此 时 称 为 1 0 折交叉验证;其 他 常 用 的 k 值
有 5 、2 0 等 . 图 2 .2 给出了 1 0 折交叉验证的示意图.
|。 V
2 |。3 |。4 |。5 |。6 |。7 |。8 |。9 回 。|
训车集
|。1 | 。2 | 。3 | 。4 巨5 | 。6 | 。7 | 。8同
|。2 |。3 |。4 |。5 |。6 |。7 回 回 ]
回 |。3 回 |。5 |。6 |。7 回 回 问
洌|试* |功 0 | — >测试 结 果 ]
S — >测 试 结 果 2
••
•・
1 — >测 试 结 果 10
I 平 均 返回
一结果
图 2.2 10折交叉验证示意图
“1 0 次 1 0 折 交 叉 验 证 法 ” 与 "100次留出 法 ”都是进行了 1 0 0 次训 练/测试.
与留出法相似,将 数 据 集 。 划 分 为 k 个子集同样存在多种划分方式.为
减小因样本划分不同而引入的差别,k 折交叉验证通常要随机使用不同的划分
重 复 p 次,最终的评估结果是这p 次 k 折交叉验证结果的均值,例如常见的有
“ 1 0 次 1 0 折交叉验证”.
假 定 数 据 集D 中 包 含m 个样本,若 令 k = 小 ,则得到了交叉验证法的一
个特例:留一法(Leave-One-Out,简 称 L O O ).显然,留一法不受随机样本划分


2 . 2 评估方法 27
参见习题2 2
NFL定 理 参 见 1 .4 节.
关于样本复杂度与泛化 性 能 之 间 的 关 系 ,参见第 1 2 章.
Bootstrap本 意 是 “解靴 带” ;这 里 是 在 使 用 德 国 1 8 世 纪 文 学 作 品 《吹牛 大王历险记》 中解靴带自 助 的 典 故 ,因此本书译为 “自助法” .自 助 采 样 亦 称 “可 重 复 采 样 ” 或 “有 放回采样”.
e 是自然常数.
“\”表示集合减法.
集 成 学 习 参 见 第 8 章.
方式的影响,因为m 个样本只有唯一的方式划分为m 个子集— 每个子集包含
一个样本;留一法使用的训练集与初始数据集相比只少了一个样本,这就使得
在绝大多数情况下,留一法中被实际评估的模型与期望评估的用D 训练出的模
型 很 相 似 .因 此 ,留 一 法 的 评 估 结 果 往 往 被 认 为 比 较 准 确 .然 而 ,留一法也有其
缺陷:在数据集比较大时,训 练 M 个模型的计算开销可能是难以忍受的(例如数
据 集 包 含 1 百万个样本,则 需 训 练 1 百万个模型),而这还是在未考虑算法调参
的情况下.另外,留一法的估计结果也未必永远比其他评估方法准确;“没有免
费的午餐”定理对实验评估方法同样适用.
2 .2 .3 自助法
我们希望评估的是用0 训练出的模型.但在留出法和交叉验证法中,由于
保留了一部分样本用于测试,因此实际评估的模型所使用的训练集比。 小,这
必然会引入一些因训练样本规模不同而导致的估计偏差.留一法受训练样本规
模变化的影响较小,但计算复杂度又太高了.有没有什么办法可以减少训练样
本规模不同造成的影响,同时还能比较高效地进行实验估计呢?
“自助法”(bootstrapping)是一个比较好的解决方案,它直接以自助采样
法(bootstrap sampling)为 基 础 [Efron and Tibshirani, 1993].给定包含 m 个样
本 的 数据集。 ,我 们 对 它 进 行 采 样 产 生 数 据 集 每 次 随 机 从 。 中挑选一个
样本,将其拷贝放入少 ,然后再将该样本放回初始数据集D 中,使得该样本在
下次采样时仍有可能被采到;这个过程重复执行m 次后,我们就得到了包含m
个样本的数据集D , 这就是自助采样的结果.显然,0 中有一部分样本会在D f
中多次出现,而另一部分样本不出现.可以做一个简单的估计,样 本在馆次采
样中始终不被采到的概率是(1 - * ) 7 取极限得到
/ 1\ m 1
lim 1 — 1 - a 0.368 , (2.1)
7nl8 \ m J e
即通过自助采样,初始 数 据 集 。 中 约 有 36.8% 的样本未出现在采样数据集D f
中.于是我们可将。 用作训练集,0 \ D 用作测试集;这样,实际评估的模型与
期望评估的模型都使用馆个训练样本,而我们仍有数据总量约1 / 3 的、没在训
练集中出现的样本用于测试.这样的测试结果,亦 称 “包外估计”(out-of-bag
estimate).
自助法在数据集较小、难以有效划分训练/测试集时很有用;此外,自助法
能从初始数据集中产生多个不同的训练集,这对集成学习等方法有很大的好处.
然 而 ,自 助 法 产 生 的 数 据 集 改 变 了 初 始 数 据 集 的 分 布 ,这 会 引 入 估 计 偏 差 .因


28 第 2 章 模型评估与选择
例 如 大 型 “深度学习” 模型甚至有上百亿个参数.
此,在初始数据量足够时,留出法和交叉验证法更常用一些.
2.2.4调参与最终模型
大多数学习算法都有些参数(parameter)需要设定,参数配置不同,学得模
型的性能往往有显著差别.因此,在进行模型评估与选择时,除了要对适用学习
算法进行选择,还需对算法参数进行设定,这 就 是 通 常 所 说 的 “参数调节”或
简 称 “调 参 " (parameter tuning).
读者可能马上想到,调参和算法选择没什么本质区别:对每种参数配置都
训练出模型,然后把对应最好模型的参数作为结果.这样的考虑基本是正确的,
但有一点需注意:学习算法的很多参数是在实数范围内取值,因此,对每种参数
配置都训练出模型来是不可行的.现实中常用的做法,是对每个参数选定一个
范围和变化步长,例如在 0[,0.2]范 围 内 以 0.05为步长,则实际要评估的候选参
数 值 有 5 个,最终是从这5 个候选值中产生选定值.显然,这样选定的参数值往
往 不 是 “最 佳 ”值,但这是在计算开销和性能估计之间进行折中的结果,通过
这个折中,学习过程才变得可行.事实上,即便在进行这样的折中后,调参往往
仍很困难.可以简单估算一下:假定算法有3 个参数,每个参数仅考虑5 个候选
值,这样对每一组训练/测试集就有53 = 125个模型需考察;很多强大的学习算
法有大量参数需设定,这将导致极大的调参工程量,以至于在不少应用任务中,
参数调得好不好往往对最终模型性能有关键性影响.
给 定 包 含 馆 个 样 本 的 数 据 集 。 ,在模型评估与选择过程中由于需要留出
一部分数据进行评估测试,事实上我们只使用了一部.分数据训练模型.因此,在
模型选择完成后,学习算法和参数配置已选定,此时应该用数据集。 重新训练
模型.这个模型在训练过程中使用了所有m 个样本,这才是我们最终提交给用
户的模型.
另外,需注意的是,我们通常把学得模型在实际使用中遇到的数据称为测
试 数 据 ,为 了 加 以 区 分 ,模 型 评 估 与 选 择 中 用 于 评 估 测 试 的 数 据 集 常 称 为 “验
证 集 " (validation set).例如,在研究对比不同算法的泛化性能时,我们用测试
集上的判别效果来估计模型在实际使用时的泛化能力,而把训练数据另外划分
为训练集和验证集,基于验证集上的性能来进行模型选择和调参.
2 . 3 性能度量
对学习器的泛化性能进行评估,不仅需要有效可行的实验估计方法,还需
要有衡量模型泛化能力的评价标准,这就是性能度量(performance measure).


2 . 3 性能度量 29
聚类的性能度量参见第 9 章.
性能度量反映了任务需求,在对比不同模型的能力时,使用不同的性能度量往
往会导致不同的评判结果;这 意 味 着 模 型 的 “好 坏 ”是相对的,什么样的模型
是好的,不仅取决于算法和数据,还决定于任务需求.
在预测任务中,给定样例集。 = { 3 1 ,即),3 2 用2), . . . ,3 加 %n)},其 中 Vi
是 示 例 X i 的真实标记.要评估学习器/ 的性能,就要把学习器预测结果/((9)
与真实标记g 进行比较.
回归任务最常用的性能度量是“均 方 误 差 "(mean squared error)
1m
E (/ ;0 = 万 £ ( 〃 ◎ ) —纳)2 ・ (2)2) i=l
更一般的,对 于 数 据 分 布 。 和 概 率 密 度 函 数 2(•),均方误差可描述为
E 5 0 ) = / ( / Q ) - g)2 p(x)dx . (2.3)
本节下面主要介绍分类任务中常用的性能度量.
2 .3 .1 错误率与精度
本 章 开 头 提 到 了 错 误 率 和 精 度 ,这 是 分 类 任 务 中 最 常 用 的 两 种 性 能 度 量 ,
既适用于二分类任务,也适用于多分类任务.错误率是分类错误的样本数占样
本总数的比例,精度则是分类正确的样本数占样本总数的比例.对样例集。,分
类错误率定义为 l m
. (2 4・)
精度则定义为
1m
acc(f; D) = - (xi) = yi) (2.5)
i=l
=
更一般的,对于数据分布V 和概率密度函数◎(•),错误率与精度可分别描
述为
石(/;。) = / I ( / ( « ) * y) p (x)d x , (2.6)


30 第 2 章 模型评估与选择
查 准 率 亦 称 “准确率” , 查 全 率 亦 称 “召回率” .
acc(/; P ) = / 1 ( / (a?) = y)p(x)dx (2.7)
J 〜0
2 .3 .2 查准率、查全率与F l
错误率和精度虽常用,但并不能满足所有任务需求.以西瓜问题为例,假定
瓜农拉来一车西瓜,我们用训练好的模型对这些西瓜进行判别,显然,错误率衡
量 了 有 多 少 比 例 的 瓜 被 判 别 错 误 . 但 是 若 我 们 关 心 的 是 “挑 出 的西瓜中有多少
比例是好瓜”,或 者 “所有好瓜中有多少比例被挑了出来”,那么错误率显然
就不够用了,这时需要使用其他的性能度量.
类 似 的 需 求 在 信 息 检 索 、Web搜 索 等 应 用 中 经 常 出 现 ,例 如 在 信 息 检 索
中,我 们 经 常 会 关 心 “检 索 出 的 信 息 中 有 多 少 比 例 是 用 户 感 兴 趣 的 ” “用
户 感 兴 趣 的 信 息 中 有多少被检索出来了”. “查准 率 ”(precision)与 “查全
率 ”(recall)是更为适用于此类需求的性能度量.
对 于 二 分 类 问 题 ,可 将 样 例 根 据 其 真 实 类 别 与 学 习 器 预 测 类 别 的 组 合 划
分为真正例(true positive)> 假正例(false positive)> 真反例(true negative)>
假反例(false negative)四种情形,令 T P 、F P 、T N 、F N 分别表示其对应的
样例数,则 显 然 有 T P + F P + T N + F N = 样 例 总 数 .分 类 结 果 的 “混淆矩
阵 " (confusion matrix)如表 2.1 所示.
表 2 . 1 分类结果混淆矩阵
真实情况 预测结果
正例 反例
正例 TP (真正例) F N (假反例)
反例 F P (假正例) T N (真反例)
(2.8)
(2) 9)
查 准 率P 与查全率R 分别定义为
L 丁尸 TP + FP 1
TP = TP + FN .
查 准 率 和 查 全 率 是 一 对 矛 盾 的 度 量 .一 般 来 说 ,查 准 率 高 时 ,查 全率往往
偏低;而查全率高时,查准率往往偏低.例如,若希望将好瓜尽可能多地选出来,
则可通过增加选瓜的数量来实现,如果将所有西瓜都选上,那么所有的好瓜也


2 . 3 性能度量 31
以信息检索应用为例, 逐条向用户反馈其可能感 兴 趣 的 信 息 ,即可计算出 查 全 率 、查准率.
亦 称 “P R 曲 线 ” 或 “ PR 图” .
必然都被选上了,但这样查准率就会较低;若希望选出的瓜中好瓜比例尽可能
高,则可只挑选最有把握的瓜,但这样就难免会漏掉不少好瓜,使得查全率较
低.通常只有在一些简单任务中,才可能使查全率和查准率都很高.
在很多情形下,我们可根据学习器的预测结果对样例进行排序,排在前面
的 是 学 习 器 认 为 “最 可 能 ”是正例的样本,排 在 最 后 的 则 是 学 习 器 认 为 “最
不 可 能 ”是 正 例 的 样 本 .按 此 顺 序 逐 个 把 样 本 作 为 正 例 进 行 预 测 ,则每次可以
计算出当前的查全率、查准率.以查准率为纵轴、查全率为横轴作图,就得到
了查准率-查全率曲线,简 称 “P -R 曲线〃,显示该曲线的图称为“P -R 图”.图
2 .3 给出了一个示意图.
为 绘 图 方 便 和 美 观 ,示 意图显示出单调平滑曲线; 但 现 实 任 务 中 的 P -R 曲线 常 是 非 单 调 、不平滑的, 在很多局部有上下波动.
P - R 图直观地显示出学习器在样本总体上的查全率、查准率.在进行比较
时,若一个学习器的P - R 曲线被另一个学习器的曲线完全“包住”,则可断言
后者的性能优于前者,例 如 图 2 .3 中学习器A 的性能优于学习器C ; 如果两个
学习器的P - R 曲线发生了交叉,例 如 图 2 .3 中 的 A 与 B , 则难以一般性地断言
两者孰优孰劣,只能在具体的查准率或查全率条件下进行比较.然而,在很多情
形下,人们往往仍希望把学习器A 与 B 比出个高低.这时一个比较合理的判据
是 比 较 P - R 曲线下面积的大小,它在一定程度上表征了学习器在查准率和查全
率 上取得相对“双高”的比例.但这个值不太容易估算,因此,人们设计了一些
综合考虑查准率、查全率的性能度量.
“平衡点”(Break-Event P o in t,简 称 B E P )就是这样一个度量,它 是 “查
准率= 查全率,,时的取值,例 如 图 2 .3 中学习器C 的 B E P 是 0 .6 4 ,而 基 于 BEP
的比较,可认为学习器A 优 于 B .


32 第 2 章 模 型 评 估 与 选 择
但 B E P 还 是 过 于 简 化 了 些 ,更 常 用 的 是 F 1 度量:
2x P x R _ 2 x TP
P + R = 样 例 总 数 + T P —T N ' (2.10)
在 一 些 应 用 中 ,对 查 准 率 和 查 全 率 的 重 视 程 度 有 所 不 同 .例 如 在 商 品 推 荐
人£ 率与查 系 统 中 ,为 了 尽 可 能 少 打 扰 用 户 ,更 希 望 推 荐 内 容 确 是 用 户 感 兴 趣 的 ,此 时 查 准
全军的调和平均(harmonic mean)定义的: 率 更 重 要 ;而 在 逃 犯 信 息 检 索 系 统 中 ,更 希 望 尽 可 能 少 漏 掉 逃 犯 ,此 时 查 全 率 更
工 」 .化+与.
F1 2 \P R )
则是加权调和平均:
重 要 .F 1 度 量 的 一 般 形 式 — 冲 , 能让我们表达出对查准率/查全率的不同偏
好 ,它 定 义 为
=(1 + 俨 )x P x R
3 = (尸 X 尸)+ R , (2.11)
其 中 B > 0 度 量 了 查 全 率 对 查 准 率 的 相 对 重 要 性 [VanRijsbergen, 1979]. B = 1
与算术平均(挈 )和几 时 退 化 为 标 准 的 F 1 ; ^ > 1 时 查 全 率 有 更 大 影 响 ;B < 1 时 查 准 率 有 更 大 影 响 . 何平均( )相比,调 和平均更重视较小值• 很 多 时 候 我 们 有 多 个 二 分 类 混 淆 矩 阵 ,例 如 进 行 多 次 训 练 /测 试 ,每 次 得 到
一 个 混 淆 矩 阵 ;或 是 在 多 个 数 据 集 上 进 行 训 练 /测 试 ,希 望 估 计 算 法 的 “全 局 ”
性 能 ;甚 或 是 执 行 多 分 类 任 务 ,每 两 两 类 别 的 组 合 都 对 应 一 个 混 淆 矩 阵 ;•... ・
总之,我们希望在n 个二分类混淆矩阵上综合考察查准率和查全率.
一种直接的做法是先在各混淆矩阵上分别计算出查准率和查全率,
记 为 (马 , 再 计 算 平 均 值 ,这 样 就 得 到 “宏 查 准
率 ” (m acro-?)、 “宏 查 全 率 ”(macro-五), 以 及 相 应 的 “宏 F l ” (m acro-Fl):
]n
macro-P = — 舄 , (2.12)
n 22=―1
] 71
macro-7^ = — Ri , (2.13)
n Z广=1
2 x macro-P x macro-1?
m acro-Fl = ------------- ------ ------ - -
macro-P + macro-E ,(2.14)
还 可 先 将 各 混 淆 矩 阵 的 对 应 元 素 进 行 平 均 ,得 到 T P 、F P 、T N 、F N 的
平 均 值 ,分 别 记 为 力 、FP. TN. F N , 再 基 于 这 些 平 均 值 计 算 出 “微 查 准
率 ”(micro-尸)、 “微 查 全 率 ” (micro-R)和 “微 F l " (m icro-Fl):
mii T P + F P (2) 15)


2 . 3 性能度量 33
micro-JZ = T P
TP^rFN
micro-Fl = 2 x micro-F x micro-R
micro-P + micro
(2.16)
(2) 17)
2.3.3 R O C 与 A U C
神经网络参见第5 章.
很多学习器是为测试样本产生一个实值或概率预测,然后将这个预测值与
一个分类阈值(threshold)进行比较,若大于阈值则分为正类,否 则 为 反 类 .例
如,神经网络在一般情形下是对每个测试样本预测出一个[0.0,1.0]之间的实值,
然后将这个值与0 . 5 进行比较,大 于 0 . 5 则判为正例,否则为反例.这个实值或
概率预测结果的好坏,直接决定了学习器的泛化能力.实际上,根据这个实值或
概 率 预 测 结 果 ,我 们 可 将 测 试 样 本 进 行 排 序 ,“最 可 能 ”是正例的排在最前面,
“最 不 可 能 ”是 正 例 的 排 在 最 后 面 .这 样 ,分 类 过 程 就 相 当 于 在 这 个 排 序 中 以
某 个 “截断点”(cut point)将样本分为两部分,前一部分判作正例,后一部分则
判作反例.
在不同的应用任务中,我们可根据任务需求来采用不同的截断点,例如若
我 们 更 重 视 “查准率”,则可选择排序中靠前的位置进行截断;若 更 重 视 “查
全 率 ”,则 可 选 择 靠 后 的 位 置 进 行 截 断 .因 此 ,排序本身的质量好坏,体现了综
合 考 虑 学 习 器 在 不 同 任 务 下 的 “期 望 泛 化 性 能 ”的好坏,或 者 说 , “一般情况
下 ”泛化性能的好坏.R O C 曲线则是从这个角度出发来研究学习器泛化性能
的有力工具.
R O C 全 称 是 “受试者工作特征 ”(Receiver Operating Characteristic) ®
线,它 源 于 “二 战 ”中用于敌机检测的雷达信号分析技术,二十世纪六七十
年 代 开 始 被 用 于 一 些 心 理 学 、医学检测应用中,此后被引入机器学习领域
[Spackman, 1 9 8 9 ] . 与 2.3.2节 中 介 绍 的 P - R 曲线相似,我们根据学习器的预
测 结 果 对 样 例 进 行 排 序 ,按 此 顺 序 逐 个 把 样 本 作 为 正 例 进 行 预 测 ,每 次 计 算
出两个重要量的值,分别以它们为横、纵坐标作图,就得到了 “R O C 曲线”.
与 P - R 曲线使用查准率、查全率为纵、横轴不同,R O C 曲 线 的 纵 轴 是 “真正
例 率 ”(True Positive R a t e , 简称 T P R ) , 横 轴 是 “假 正 例 率 ”(False Positive
R a t e , 简 称 F P R ) , 基 于 表 2 . 1 中的符号,两者分别定义为
T P R = TP
T P + F N (2.18)
F P R = FP
T N + F P (2) 19)


34 第 2章模型评估与选择
显 示 R O C 曲线的图称为“ R O C 图”. 图 2.4(a)给出了一个示意图,显然,
对 角 线 对 应 于 “随机猜测”模型,而 点 (0, 1 ) 则对应于将所有正例排在所有反
例 之 前 的 “理想模型”.
6
4
0
4$0
-° 8
1
0
0.2
0 0.2 0.4 0.6 0.8 1.0 假正例率
(a) R O C 曲线与AUC
0.2 0.6 假正例率
(b)基于有限样例绘制的R O C 曲线 与 AUC
8
6
4
S
0 0
图 2.4 R O C 曲线 与 A U C 示意图
现实任务中通常是利用有限个测试样例来绘制R O C S ,此时仅能获得有
限个(真正例率,假正例率)坐标对,无法产生图2.4(a)中的光滑R O C 曲线,只能
制 髓 7 窘 燃 方 篝 绘制出如图2.4(b)所示的近似R O C 曲线.绘图过程很简单:给 定 m + 个正例和 本书到这里,介绍近;以曲 m ~ 个反例,根据学习器预测结果对样例进行排序,然后把分类阈值设为最大,
黑 式 u言东?更于下 即把所有样例均预测为反例,此时真正例率和假正例率均为0 , 在 坐 标 (0 ,0 )处 ” . 标记一个点.然后,将分类阈值依次设为每个样例的预测值,即依次将每个样例
划分为正例.设前一个标记点坐标为(叫切,当前若为真正例,则对应标记点的
坐标为(叫U+ 熹 );当 前 若 为 假 正 例 ,则 对 应 标 记 点 的 坐 标 为 (力 +土 ,切 ,然
后用线段连接相邻点即得.
进行学习器的比较时,与 P - R 图相似,若 一个学习器的R O C 曲线被另一
个 学 习 器 的 曲 线 完 全 “包 住 "则 可 断 言 后 者 的 性 能 优 于 前 者 ;若两个学习器
的 R O C 曲线发生交叉,则难以一般性地断言两者孰优孰劣.此时如果一定要进
行比较,则较为合理的判据是比较R O C 曲线下的面积,即 AUC (Area Under
ROC C urve),如图 2.4 所示.
从 定 义 可 知 ,A U C 可 通 过 对 R O C 曲 线 下 各 部 分 的 面 积 求 和 而 得 .假
定 R O C 曲 线 是 由 坐 标 为 {(劣1,加),(/2 42), . . . , 伊皿沙恒)}的点按序连接而形
成Q1 = 0, xm = 1 ) ,参 见 图 2.4 (b ),则 A U C 可估算为


2 . 3 性能度量 35
一 般 情 况 下 ,重 要 的 是 代 价 比 值 而 非 绝 对 值 ,例 以口costQi : costio = 5 : 1 与 50 :1 0 所起效果相当.
1 772- 1
AUC = - ( 0 +i — 3 ) ,( % + % + 1 ) . (2.20) 2=1
形式化地看,A U C 考虑的是样本预测的排序质量,因此它与排序误差有紧
密 联 系 .给 定 m + 个 正 例 和m - 个反例,令 D + 和 D - 分别表示正、反例集合,
则 排 序 “损失”(loss)定义为
5 = - ^ ― E E fi (/3+) < /3-)) + # ( / 2 = /1 ) ) ) ,
mm
x+eD+x-eD- ' 2 7
(2.21)
即考虑每一对正、反例,若正例的预测值小于反例,则 记 一 个 “罚分”,若相
等,则 记 0 .5 个 “罚分”.容 易 看 出 ,£r a n k 对 应 的 是 R O C 曲线之上的面积:若
一个正例在R O C 曲线上对应标记点的坐标为(g g ) , 则1恰是排序在其之前的
反例所占的比例,即假正例率.因此有
AUC = l-4 a n fc . (2.22)
2 .3 .4 代价敏感错误率与代价曲线
在现实任务中常会遇到这样的情况:不同类型的错误所造成的后果不同.
例如在医疗诊断中,错误地把患者诊断为健康人与错误地把健康人诊断为患者,
看起来都是犯了 “一次错误”,但后者的影响是增加了进一步检查的麻烦,前
者的后果却可能是丧失了拯救生命的最佳时机;再如,门禁系统错误地把可通
行人员拦在门外,将使得用户体验不佳,但错误地把陌生人放进门内,则会造成
严重的安全事故.为权衡不同类型错误所造成的不同损失,可 为 错 误 赋 予 “非
均等代价“(unequal cost).
以 二 分 类 任 务 为 例 ,我 们 可 根 据 任 务 的 领 域 知 识 设 定 一 个 “代价矩
阵 " (cost matrix),如 表 2.2所示,其 中 costij表 示 将 第i类样本预测为第j 类
样本的代价.一般来说,c o s % = 0 ; 若 将 第 0 类 判 别 为 第 1 类所造成的损失更
大,则 costoi > cos^io;损失程度相差越大,COS力01与 cost10 值的差别越大.
表 2 . 2 二分类代价矩阵
真实类别 预测类别
第0 类 第1类
第 0 类 0 costoi
第 1 类 costio 0


36 第 2 章 模型评估与选择
回顾前面介绍的一些性能度量可看出,它们大都隐式地假设了均等代价,
例 如 式 (2.4)所 定 义 的 错 误 率 是 直 接 计 算 “错 误 次 数 ”,并没有考虑不同错误会
造成不同的后果.在非均等代价下,我们所希望的不再是简单地最小化错误次
数,而 是 希 望 最 小 化 “总体代价”(total c o s t) .若 将 表 2 .2 中 的 第 0 类作为正
类 、第 1 类作为反类,令 。+ 与 分 别 代 表 样 例 集 D 的正例子集和反例子
集,则 “代价敏感”(cost-sensitive)错误率为
E (于;D; cost) = — ( £ II ( / ( g ) * yi) x costQ1
TTb \\XiED+
+ E U(/ ( g ) * yi) x cos力10 j . (2.23)
类 似 的 ,可 给 出 基 于 分 布 定 义 的 代 价 敏 感 错 误 率 ,以 及其 他 一 些 性 能 度 量
如精度的代价敏感版本.若令cos%•中的分、3・取值不限于。、1 , 则可定义出多
分类任务的代价敏感性能度量.
参见习题2 7
在非均等代价下,R O C 曲线不能直接反映出学习器的期望总体代价,而
“代价曲线”(cost curve)则可达到该目的.代价曲线图的横轴是取值为 0[,1]
的正例概率代价
P(-\-)cost = p X cost01
p X costoi + (1 —P) X COS力10 (2.24)
" 规 范 化 " (normaliza tion) 是将不同变化范围的 值映射到相同的固定范围 中,常 见 的 是 0[,1],此时亦 称 “归一 化 ”. 参 见 习 题 2.8.
其 中 P 是样例为正例的概率;纵轴是取值为 0[J ]的归一化代价
_ FNR x p x costoi + FPR x (1 —p) x cost^Q
COStn o r m = " -; 73 \ 
p X costoi + (1 —p) X COStxQ (2.25)
其 中 F P R 是式(2.19)定义的假正例率,FNR = 1 - T P R 是假反例率.代价曲线
的绘制很简单:R O C 曲线上每一点对应了代价平面上的一条线段,设 R O C 曲
线上点的坐标为(T PR ,FPR ),则可相应计算出F N R ,然后在代价平面上绘制
一 条 从 (0 ,F P R )到 (1,F N R )的线段,线段下的面积即表示了该条件下的期望
总体代价;如 此 将 R O C 曲线上的每个点转化为代价平面上的一条线段,然后
取所有线段的下界,围成的面积即为在所有条件下学习器的期望总体代价,如
图 2.5所示.


2 . 4 比较检验 37
1.0
O. 5
FP R
代价曲线
期望总体代价
FNR
0 0.5 1.0
正例概率代价 、
图 2 . 5 代价曲线与期望总体代价
2 .4 比较检验
有 了 实 验 评 估 方法和性能度量,看起来就能对学习器的性能进行评估比较
了:先 使 用 某 种 实 验 评 估 方 法 测 得 学 习 器 的 某 个 性 能 度 量 结 果 ,然后对这些结
果 进 行 比 较 .但 怎 么 来 做 这 个 “比较”呢?是 直 接 取 得 性 能 度 量 的 值 然 后 “比
大 小 ”吗?实 际 上 ,机 器 学 习 中 性 能 比 较 这 件 事 要 比 大 家 想 象 的 复 杂 得 多 .这
里 面 涉 及 几 个 重 要 因素:首先,我们希望比较的是泛化性能,然而通过实验评估
方 法 我们获得的是测试集上的性能,两者的对比结果可能未必相同;第 二 ,测试
集 上 的 性 能 与 测 试 集本 身 的 选 择 有 很 大 关 系 ,且不论使用不同大小的测试集会
得 到 不 同 的 结 果 ,即便用相同大小的测试集,若包含的测试样例不同,测试结果
也 会 有 不 同 ;第 三 ,很多机器学习算法本身有一定的随机性,即便用相同的参数
设 置 在 同 一 个 测 试 集上多次 运 行 ,其 结 果 也 会 有 不 同 .那 么 ,有没有适当的方法
对学习器的性能进行比较呢?
统 计 假 设 检 验 (hypothesis test)为 我 们 进 行 学 习 器 性 能 比 较 提 供 了 重 要 依
据 .基 于 假 设 检 验 结 果 我 们 可 推 断 出 ,若 在 测 试 集 上 观 察 到 学 习 器 A 比 B 好,
则 A 的泛化性能是否在统计意义上优于B , 以及这个结论的把握有多大.下面
支曲胱E 鬻 介 我们先介绍两种最基本的假设检验,然后介绍几种常用的机器学习性能比较方
可参见[Wellek, 2010].
法 .为 便 于 讨 论 ,本 节 默 认 以 错 误 率 为 性 能 度 量 ,用 6 表示.
2.4.1 假设检验
假 设 检 验 中 的 “假 设 ”是对学习器泛化错误率分 布 的 某 种 判 断 或 猜 想 ,例
如% = 向 ,,.现 实 任 务 中 我 们并不知道学习器的泛化错误率,只能获知其测试错
误 率 4 泛化错误率与测 试 错 误 率 未 必 相 同 ,但 直 观 上 ,二者接近的可能性应比


38 第 2 章 模型评估与选择
较大,相差很远的可能性比较小.因此,可根据测试错误率估推出泛化错误率的
分布.
泛 化 错 误 率 为 €的 学 习 器 在 一 个 样 本 上 犯 错 的 概 率 是 6;测 试 错 误 率 €意味
着 在 m 个测试样本中恰有€x m 个被误分类.假定测试样本是从样本总体分布
中独立采样而得,那 么 泛化错误率为6 的学习器将其中m f 个样本误分类、其
余样本全都分类正确的概率是6m ,(l - 由此可估算出其恰将£ X 馆个
样本误分类的概率如下式所示,这也表达了在包含m 个样本的测试集上,泛化
错 误 率 为 €的学习器被测得测试错误率为6 的概率:
PQ) = ( m
\6 x m (2.26)
给定测试错误率,则 解 H P © e)/de = 0 可知,P(€;c)在 e = 1 时最大,上—可增
大 时 P © 6)减小.这符合二项(binomial)分布,如 图 2.6所示,若 e= 0.3,则 10
个样本中测得3 个被误分类的概率最大.
a 的常用取值有 0.05. 0 . 1 , 图 2.6 中 a 较 大是为了绘图方便.
我 们 可 使 用 “二项检验”(binomial test)来 对 % W 0.3”( 即 “泛化错误率是
否 不 大 于 0 . 3 " )这 样 的 假 设 进 行 检 验 .更 一 般 的 ,考 虑 假 设 % ( 5 ”,则在
1 - a 的概率内所能观测到的最大错误率如下式计算.这里1 - a 反映了结论的
“置信度”(confidence),直观地来看,相 应 于 图 2.6中非阴影部分的范围.
s . t . 是 “subject to” 的 简写,使 左 边 式 子 在 右 边 条件满足时成立.
m /\
6 = m a x c s.t. m jG2(1 —€)M - Z < a . (2.27)
z=eo x m + l ' /


2 . 4 比较检验 39
二项检验的临界值在R 语言中可通过qbinom (1 £())计 算 ,在 Matlab 中是 ic d f ( ‘ B in o m ia l/, 1 a , m , eo).
此时若测试错误率€小于临界值€,则根据二项检验可得出结论:在a 的显著度
下,假 设 7 W 6 ”不能被拒绝,即 能 以 1 - a 的置信度认为,学习器的泛化错误
率 不 大 于 eo;否则该假设可被拒绝,即 在 a 的显著度下可认为学习器的泛化错
误率大 于 e0 .
R 语言是面向统计计 算 的 开 源 脚 本 语 言 ,参见 w w w .r-proje ct.org.
在很多时候我们并非仅做一次留出法估计,而是通过多次重复留出法或是
交 叉 验 证 法 等 进 行 多 次 训 练 /测 试 ,这 样 会 得 到 多 个 测 试 错 误 率 ,此时可使用
((t检 验 " (力-test).假定我们得到了 k 个测试错误率,€1, 熬,则平均测试
错 误 率 〃 和 方 差 。2 为
1k
:£标 , (2.28) 1=1
-1 k
(2.29)
考 虑 到 这 k 个测试错误率可看作泛化错误率e0 的独立采样,则变量
% ( 〃 - €0 )
Tt = --------
a
(2.30)
服从自由度为k — 1 的 1 分布,如 图 2.7所示.
度密率概
Tt
图 2 . 7 1 分布示意图(k = 10)
10
对假设“〃= 5 ”和 显 著 度 以 我们可计算出当测试错误率均值为6 0 时,在
1 - a 概率内能观测到的最大错误率,即临界值.这里考虑双边(two-tailed)假
设,如 图 2.7所示,两 边 阴 影 部 分 各 有 a / 2 的面积;假定阴影部分范围分别为
[-OO,t_a / 2 ] 和 加 /2,OO].若 平 均 错 误 率 〃 与 6 之差|从—引位于临界值范围


40 第 2 章 模型评估与选择
临 界 值 ta / 2 在 R 语言
中可通过q t( l —a /2 ,k 
1 ) 计 算 ,雇 M a tla b 中是
i c d f ( , T, , l - a / 2 , / c - l ) .
[t,Q /2,M 内,则不能拒绝假设〃 = e0 5\ 即可认为泛化错误率为6 , 置信度为
1 - % 否则可拒绝该假设,即在该显著度下可认为泛化错误率与60 有显著不
同.a 常用取值有0 . 0 5 和 0 . 1 . 表 2 . 3 给出了一些常用临界值.
表 2.3 双 边 t检 验 的 常 用 临 界 值
ak
2 5 10 20 30
0.05 12.706 2.776 2.262 2.093 2.045 0.10 6.314 2.132 1.833 1.729 1.699
上面介绍的两种方法都是对关于单个学习器泛化性能的假设进行检验,而
在现实任务中,更多时候我们需对不同学习器的性能进行比较,下面将介绍适
用于此类情况的假设检验方法.
2 .4 .2 交叉验证方检验
对两个学习器A 和 B , 若我们使用k 折交叉验证法得到的测试错误率分
别 为 京 吮 ... , 靖 和 田 或 ,... ,或,其 中 靖 和 e?是在相同 的 第i折训练/测
试集上得到的结果,则 可 用k 折 交 叉 验 证 “成 对 t检 验 " (p a i r e d 力-tests)来进行
比较检验.这里的基本思想是若两个学习器的性能相同,则它们使用相同的训
练/测试集得到的测试错误率应相同,即 镇 = ef.
具体来说,对 k 折 交 叉 验 证 产 生 的 k 对测试错误率:先对每对结果求差,
△°= 蜡 _ 镇 ;若两个学习器性能相同,则差值均值应为零.因此,可根据差值
Z " ... Z 来对“学 习 器 A 与 B 性能相同”这 个假设做t检验,计算出差值
的均值M 和 方 差 在 显 著 度 。下,若变量
Vk/^ Tt = --
a (2.31)
小于临界值加/2, 则假设不能被拒绝,即认为两个学习器的性能没有显著差
别;否则可认为两个学习器的性能有显著差别,且平均错误率较小的那个学习
器性能 较 优 .这 里 加 /2, " 1 是 自 由 度 为 k - 1 的土分布上尾部累积分布为a / 2
的临界值. ’
欲进行有效的假设检验,一个重要前提是测试错误率均为泛化错误率的独
立 采 样 .然 而 ,通常情况下由于样本有限,在使用交叉验证等实验估计方法时,
不同轮次的训练集会有一定程度的重叠,这就使得测试错误率实际上并不独立,
会导致过高估计假设成立的概率.为缓解这一问题,可采用“5 x 2 交叉验证”


2 . 4 比较检验 41
法 [Dietterich, 1998].
5 x 2 交叉验证是做5 次 2 折交叉验证,在每次2 折交叉验证之前随机将数
据打乱,使 得 5 次交叉验证中的数据划分不重复.对两个学习器A 和 B , 第分次
2 折交叉验证将产生两对测试错误率,我们对它们分别求差,得 到 第 1 折上的差
值 和 第 2 折 上 的 差 值 为 缓 解 测 试 错 误 率 的 非 独 立 性 ,我们仅计算第 1
次 2 折交叉验证的两个结果的平均值4 = O.5(A1 + △ 汽 但 对 每 次 2 折实验的 结果都计算出其方差靖= ( △ 卜 号 i p + (田 - 转 町 . 变 量
(2.32)
服从自由度为5 的 t分布,其双边检验的临界值加/2, 5 当 & = 0.05时 为 2.5706,
a = 0.1 时为 2.0150.
2.4.3 McNemar■检验
对二分类问题,使用留出法不仅可估计出学习器A 和 B 的测试错误率,还
可获得两学习器分类结果的差别,即两者都正确、都错误、一个正确另一个错
误的样本数,如 “列联表”(contingency table) 2 .4所示.
表 2 ・ 4 两学习器分类差别列联表
算法B
算法A
正确 错误
正确 600 601
错误 610 611
若 我 们 做 的 假 设 是 两 学 习 器 性 能 相 同 ,则 应 有 eoi = e i o , 那 么 变 量
|eOi - e io |应当服从正态分布,且 均 值 为 1 , 方 差 为 eOi + e10. 因此变量
= ( M — —1产
eoi + eio (2.33)
中 文 称 为 “卡方分布” .
临 界 值 xN 在 R 语 言 中 可 通 过 qchisqd CK, k —1 )计 算 ,在 Matlab 中 是 ic d f (, Ch.isquare, , 1 a,k- 1 ) . 这里的 k = 2 是进行比较的算法个数.
服 从 自 由 度 为 1 的 x 2 分布,即标准正态分布变量的平方.给定显著度必当以
上 变 量 值小于临界值蟾时,不能拒绝假设,即认为两学习器的性能没有显著差
别;否则拒绝假设,即认为两者性能有显著差别,且平均错误率较小的那个学习
器 性 能 较 优 .自 由 度 为 1 的 % 2 检验的临界值当a = 0.05时 为 3.8415, a = 0.1
时为 2.7055.


42 第2 章 模型评估与选择
2.4.4 Friedman检 验 与 Nemenyi后续检验
交 叉 验 证t检 验 和 McNemar检验都是在一个数据集上比较两个算法的 性 能 ,而 在 很 多 时 候 ,我 们 会 在 一 组 数 据 集 上 对 多 不 算 法 进 行 比 较 .当 有 多 个
算法参与比较时,一种做法是在每个数据集上分别列出两两比较的结果,而在
两 两 比 较 时 可 使 用 前 述 方 法 ;另 一 种 方 法 更 为 直 接 ,即 使 用 基 于 算 法 排 序 的
Friedman 检验.
假 定 我 们 用 。1、0 2 、。3 和 。4 四 个 数 据 集 对 算 法 A 、B 、C 进行比较. 首先,使用留出法或交叉验证法得到每个算法在每个数据集上的测试结果,然
后在每个数据集上根据测试性能由好到坏排序,并赋予序值1, 2 , 若算法的
测试性能相同,则平分序值.例如,在 。1 和 。3 上,A 最好 、B 其 次 、C 最差,
而 在 D 2 上,A 最好、B 与 C 性能相同,......, 则可列出表2 .5 ,其中最后一行通
过对每一列的序值求平均,得到平均序值.
表 2 . 5 算法比较序值表
数据集 算 法 A 算 法 B 算 法 C
123 1 2.5 2.5 123 123 平均序值 1 2.125 2.875
然后,使 用 FYiedman检验来判断这些算法是否性能都相同.若相同,则它
们的平均序值应当相同.假定我们在N 个数据集上比较k 个算法,令n 表示第
i个算法的平均序值,为简化讨论,暂不考虑平分序值的情况,则 :服从正态分
布,其均值和方差分别为(k+ 1 )/2 和 (d _ 1 )/1 2 .变量
12N
k{k + 1) 净-处驾 (2.34)
在 k 和 N 都较大时,服从自由度为k - 1 的 f 分布.
然而,上 述 这 样 的 “原 始 FYiedman检验”过于保守,现在通常使用变量
(N —1)我
TF = N(k - 1) - r x 2 , (2.35)


2 . 4 比较检验 43
其 中 由 式 (2.34)得至J!.力 服 从 自 由 度 为 k —1 和 (k —1)(N —1 ) 的 F 分布,
表 2.6给出了一些常用临界值.
表 2 . 6 尸检验的常用临界值
a = 0.05
F 检验的临界值在R 语
言中可通过q f ( l — a ,k 
数据集 个数N
算法个数k
2 3 4 5 6 7 8 9 10
l , ( k —l ) ( N —1 ) ) 计算,在 4 10.128 5.143 3.863 3.259 2.901 2.661 2.488 2.355 2.250 Matlab 中是ic d fC F 7, 1 - 5 7.709 4.459 3.490 3.007 2.711 2.508 2.359 2.244 2.153 8 5.591 3.739 3.072 2.714 2.485 2.324 2.203 2.109 2.032 10 5.117 3.555 2.960 2.634 2.422 2.272 2.159 2.070 1.998 15 4.600 3.340 2.827 2.537 2.346 2.209 2.104 2.022 1.955 20 4.381 3.245 2.766 2.492 2.310 2.179 2.079 2.000 1.935
a = 0.1
数据集 算法个数k
个数N 2 3 4 5 6 7 8 9 10
4 5.538 3.463 2.813 2.480 2.273 2.130 2.023 1.940 1.874 5 4.545 3.113 2.606 2.333 2.158 2.035 1.943 1.870 1.811 8 3.589 2.726 2.365 2.157 2.019 1.919 1.843 1.782 1.733 10 3.360 2.624 2.299 2.108 1.980 1.886 1.814 1.757 1.710 15 3.102 2.503 2.219 2.048 1.931 1.845 1.779 1.726 1.682 20 2.990 2.448 2.182 2.020 1.909 1.826 1.762 1.711 1.668
若 “所有算法的性能相同”这个假设被拒绝,则说明算法的性能显著不
同 .这 时 需 进 行 “后 续 检 验 ”(post-hoc test)来进一步区分各算法.常用的有
N emenyi后续检验.
N e m e n y i 检验计算出平均序值差别的临界值域
。。 = 私 产 | 尹 , (2.36)
界更受值,在 R 语目中可通 表 2.7给出了 a = 0.05和 0.1时常用的qa 值.若两个算法的平均序值之差超出
过q t u k e y Q - a " I n f ) / 了 临 界 值 域 则 以 相 应 的 置 信 度 拒 绝 “两个算法性能相同”这一假设.
s q r t ( 2 ) 计算.
表 2.7 Nemenyi检验中常用的必;值
a 算法个数k
2 3 4 . 5 6 7 8 9 10
0.05 1.960 2.344 2.569 2.728 2.850 2.949 3.031 3.102 3.164 0.1 1.645 2.052 2.291 2.459 2.589 2.693 2.780 2.855 2.920


_____________________ ______________________________._________ ; 第2 章模型评估与选择
以 表 2 . 5 中的数据为例,先根据式(2.34)和 (2.35)计 算 出 rF = 24.429,由表
2 .6可知,它 大 于 a = 0. 0 5 时 的 F 检 验 临 界 值 5.143,因 此 拒 绝 “所有算法性
能 相 同 ”这 个 假 设 .然 后 使 用 N e m e n y i 后 续检验,在 表 2 . 7 中 找 到 k = 3 时
Q0.05 = 2.344,根据式(2.36)计 算 出 临界值域C D = 1.657,由 表 2 . 5 中的平均序
值可知,算 法 A 与 B 的差距,以及算法B 与 C 的差距均未超过临界值域,而算
法 A 与 C 的差距超过临界值域,因此检验结果认为算法A 与 C 的性能显著不
同,而 算 法 A 与 B 、 以及算法B 与 C 的性能没有显著差别.
上述检验比较可以直观地用F Y i e d m a n 检 验 图 显 示 .例 如 根 据 表 2 . 5 的序
值 结 果 可 绘 制 出 图 2 . 8 , 图中纵轴显示各个算法,横轴是平均序值.对每个算法,
用一个圆点显示其平均序值,以圆点为中心的横线段表示临界值域的大小.然
后就可从图中观察,若两个算法的横线段有交叠,则说明这两个算法没有显著
差别,否则即说明有显著差别.从图2 . 8 中可容易地看出,算 法 A 与 B 没有显著
差别,因为它们的横线段有交叠区域,而 算 法 A 显 著 优 于 算 法 C , 因为它们的
横线段没有交叠区域.
临界值域 :
算法A ,——,一:
算法B 平均爆值 1 ・
算法C .
1.0 2.0 3.0
图 2.8 Friedman检验图
2 .5 偏差与方差
对学 习 算 法 除 了 通 过 实 验 估 计 其 泛 化 性 能 ,人 们 往 往 还 希 望 了 解 它 “为什
么 ”具 有 这 样 的 性 能 ."偏 差 -方 差 分 解 " (bias-variance decomposition)是解
释学习算法泛化性能的一种重要工具.
偏差一方差分解试图对学习算法的期望泛化错误率进行拆解.我们知道,算
法在不同训练集上学得的结果很可能不同,即便这些训练集是来自同一个分布. 有丁能出现噪声使得 对测试样本X:令 U D 为8 在数据集中的标记,y 为 x 的真实标记,/ (3) ; 为 训
练 集 。 上学得模型/在况上的预测输出.以回归任务为例,学习算法的期望预


2 . 5 偏差与方差 45
测为
, (2.37)
使用样本数相同的不同训练集产生的方差为
var(x) = E p [(/ Q ; 。) 一f Q ) 丹 , (2.38)
噪声为 s2 = E n \(yD -y)2] . (2.39)
期望输出与真实标记的差别称为偏差(bias),即
bias2(x) = (/(x) —y)2 . (2.40)
为便于讨论,假定噪声期望为零,即 ^ D IVD - 对 = 0 . 通过简单的多项式展开合
并,可对算法的期望泛化误差进行分解:
E(f;D)=ED [ ( ; ( ^ P ) - ^ ) 2]
= 坳 3 0) - / ( « ) + / (7) —必 :
= E n [(/ Q ; D ) - /(x))2 ] + E p [(/(x) - t o )2 ]
由式(2.37),最后项为0. + ED [2 (/ y (9) ) (f Q ) - yD )]
= ED [(/ (况;D) —f Q ) ) 1 + E p 口 (况 )—g + g - t o ) 2 ]
= E n [(/ Q ; D) - f 3 ) 月 + E p [(〃 (9) — - t o ) 2 ]
噪声期望为0,
因此最后项为0. + 2 E P -y)(y- VD)\
= 珈 [(/ (®;D) —/(®))2 ] + (f Q ) -y)2 + ^yD - ?/)2] ,
(2.41)
于是,
E(J; D) = bias1 (□?)+ var (a?) + e2 , (2.42)
也就是说,泛化误差可分解为偏差、方差与噪声之和.
回顾偏差、方 差 、噪声的含义:偏差(2.40)度量了学习算法的期望预测与


46 第 2 章 模型评估与选择
很多学习算法都可控制 训 练 程 度 ,例 如 决 策 树 可 控 制 层 数 ,神 经 网 络 可 控 制 训 练 轮 数 ,集 成 学 习 方 法可控制基学习器个数.
真实结果的偏离程度,即刻画了学习算法本身的拟合能力;方差(2.38)度量了同
样大小的训练集的变动所导致的学习性能的变化,即刻画了数据扰动所造成的
影 响 ;噪 声 ( 2 .3 9 ) 则 表 达 了 在 当 前 任 务 上 任 何 学 习 算 法 所 能 达 到 的 期 望 泛 化 误
差的下界,即刻画了学习问题本身的难度.偏差-方差分解说明,泛化性能是由
学习算法的能力、数据的充分性以及学习任务本身的难度所共同决定的.给定
学习任务,为了取得好的泛化性能,则需使偏差较小,即能够充分拟合数据,并
且使方差较小,即使得数据扰动产生的影响小.
一 般 来 说 ,偏 差 与 方 差 是 有 冲 突 的 ,这 称 为 偏 差 -方 差 窘 境 (bias-variance
dilem m a).图 2.9给出了一个示意图.给定学习任务,假定我们能控制学习算法
的训练程度,则在训练不足时,学习器的拟合能力不够强,训练数据的扰动不足
以使学习器产生显著变化,此时偏差主导了泛化错误率;随着训练程度的加深,
学习器的拟合能力逐渐增强,训练数据发生的扰动渐渐能被学习器学到,方 差 •
逐渐主导了泛化错误率;在训练程度充足后,学习器的拟合能力已非常强,训练
数据发生的轻微扰动都会导致学习器发生显著变化,若训练数据自身的、非全
局的特性被学习器学到了,则将发生过拟合.
训练程度
图 2.9 泛化误差与偏差、方差的关系示意图
2 .6 阅读材料
自助采样法在机器学习中有重要用途,E[fron and Tibshirani, 1993]对此
进行了详细的讨论.
R O C 曲 线 在 二 十 世 纪 八 十 年 代 后 期 被 引 入 机 器 学 习 S[packman, 1989 ,]
A U C 则是从九十年代中期起在机器学习领域广为使用[Bradley, 1997 ,]但利用


2 . 6 阅读材料 47
2 . 3 .4 节仅讨论了基于类 别的误分类代价.
R O C 曲线下面积来评价模型期望性能的做法在医疗检测中早已有之[Hanley
and McNeil, 1983]. [Hand and Till, 2001]将 ROC 曲线从二分类任务推广到多
分类任务. [Fawcett, 2006]综述了 R O C 曲线的用途.
[Drummond and Holte, 2006]发明了代价曲线.需说明的是,机器学习过
程涉及许多类型的代价,除了误分类代价,还有测试代价、标记代价、属性代
价等,即便仅考虑误分类代价,仍可进一步划分为基于类别的误分类代价以及
基于样本的误分类代价.代价敏感学习(cost-sensitive learning) [Elkan, 2001;
Zhou and Liu, 2006]专门研究非均等代价下的学习.
[Dietterich, 1998]指出了常规k 折交叉验证法存在的风险,并提出了 5 x 2
交叉验证法. [Demsar, 2006]讨论了对多个算法进行比较检验的方法.
[Geman et al., 1992]针对回归任务给出了偏差-方差-协方差分解(bias
variance-covariance decomposition),后来被简称为偏差-方差分解.虽然偏差
和方差确实反映了各类学习任务内在的误差决定因素,但式(2.42)这样优美的
形式仅在基于均方误差的回归任务中得以推导出.对分类任务,由于0 / 1 损失
函数的跳变性,理论上推导出偏差-方差分解很困难.已有多种方法可通过实
验对偏差和方差进行估计[Kong and Dietterich, 1995; Kohavi and Wolpert,
1996; Breiman, 1996; Friedman, 1997; Domingos, 2000].


48 第 2 章 模型评估与选择
习题
2.1 数据 集 包 含 1000个样本,其 中 5 0 0 个正例、5 0 0 个反例,将其划分为
包 含 70% 样 本的训练集和30% 样本的测试集用于留出法评估,试估
算共有多少种划分方式.
2.2 数 据 集 包 含 100个样本,其中正、反例各一半,假定学习算法所产生
的模型是将新样本预测为训练样本数较多的类别(训练样本数相同时
进行随机猜测),试 给 出 用 10折交叉验证法和留一法分别对错误率进
行评估所得的结果.
2.3 若学习器A 的 F 1 值比学习器B 高,试 析 A 的 B E P 值是否也比B 高.
2.4 试述真正例率(T P R )、假正例率(F P R )与查准率(P )、查全率(R)之间
的联系.
2.5 试证明式(2.22).
2.6 试述错误率与R O C 曲线的联系.
2.7 试证明任意一条R O C 曲线都有一条代价曲线与之对应,反之亦然.
2.8 M in-m ax规范化和z-score规范化是两种常用的规范化方法.令力和
x 1 分别表示变量在规范化前后的取值,相应的,令 3 n 讪 和 z 俏物表示
规 范 化 前 的 最 小 值和最大值,味而和x fm a x 表示规范化后的最小值和
最大值,Z 和 /分 别 表 示 规 范 化 前 的 均 值 和 标 准 差 ,则 m in-m ax规范
化、z-score规范化分别如式(2)43)和 (2.44)所示.试析二者的优缺点.
x ,= x m, in + X ( x fm a x - x fm i n ) , (2.43) ^m ax - ^m in
, X — X 小一、
X — — :— . (2.44) Ox
2.9 试 述 f 检验过程.
2.10 * 试 述 在 F riedm an检验中使用式(2.34)与(2.35)的区别.


参考文献 49
参考文献
Bradley, A. P. (1997). “The use of the area under the ROC curve in the evalua
tion of machine learning algorithms." Pattern Recognition^ 30(7):1145-1159.
Breiman, L. (1996). “Bias, variance, and arcing classifiers." Technical Report
460, Statistics Department, University of California, Berkeley, CA.
Demsar, J. (2006). ^Statistical comparison of classifiers over multiple data
sets." Journal of Machine Learning Research1 7:1-30.
Dietterich, T. G. (1998). Approximate statistical tests for comparing super
vised classification learning algorithms.^^ Neural Computation1 10(7):1895
1923.
Domingos, P. (2000). “A unified bias-variance decomposition.55 In Proceedings
of the 17th International Conference on Machine Learning (ICML), 231-238,
Stanford, CA.
Drummond, C. and R. C. Holte. (2006). “Cost curves: An improved method
for visualizing classifier performance.^^ Machine Learning165(1):95-130.
Efron, B. and R. Tibshirani. (1993). An Introduction to the Bootstrap. Chap
man & Hall, New York, NY.
Elkan, C. (2001). “The foundations of cost-senstive learn in g .In Proceedings of
the 17th International Joint Conference on Artificial Intelligence (IJCAI),
973-978, Seattle, WA.
Fawcett, T. (2006). "An introduction to ROC a n a ly s is .Pattern Recognition
Letters, 27(8):861-874.
Friedman, J. H. (1997). “On bias, variance, 0/1-loss, and the curse-of
dimensionality/ Data Mining and Knowledge Discovery, 1(1):55-77.
Geman, S., E. Bienenstock, and R. Doursat. (1992). “Neural networks and the
bias/variance dilemma.5, Neural Computation^ 4(l):l-58.
Hand, D. J. and R. J. Till. (2001). “A simple generalisation of the area under
the ROC curve for multiple class classification problems? Machine Learning1
45(2):171-186.
Hanley, J. A. and B. J. McNeil. (1983). “A method of comparing the areas
under receiver operating characteristic curves derived from the same cases.5,
Radiology, 148(3):839-843.


50 第 2 章 模 型 评 估 与 选 择
Kohavi, R. and D. H. Wolpert. (1996). “Bias plus variance decomposition for
zero-one loss functions.5, In Proceeding of the 13th International Conference
on Machine Learning (ICML), 275-283, Bari, Italy.
Kong, E. B. and T. G. Dietterich. (1995). “Error-correcting output coding cor
rects bias and variance.55 In Proceedings of the 12th International Conference
on Machine Learning (ICML), 313-321, Tahoe City, CA.
Mitchell, T. (1997). Machine Learning. McGraw Hill, New York, NY.
Spackman, K. A. (1989). “Signal detection theory: Valuable tools for evaluating
inductive learnmg.^^ In Proceedings of the 6th International Workshop on
Machine Learning (IWML)1 160-163, Ithaca, NY.
Van Rijsbergen, C. J. (1979). Information Retrieval1 2nd edition. Butterworths,
London, UK.
Wellek, S. (2010). Testing Statistical Hypotheses of Equivalence and Noninfe
riority1 2nd edition. Chapman & Hall/CRC, Boca Raton, FL.
Zhou, Z.-H. and X.-Y. Liu. (2006), “On multi-class cost-sensitive learning.^^ In
Proceeding of the 21st National Conference on Artificial Intelligence (AAAI),
567-572, Boston, WA.


休息一会儿 51
休息一会儿
1954年 该 厂 开 始 出 版 《吉 尼 斯 世 界 纪 录 大 全 》 .
小故事:土检验、啤酒、 “学生”与 威 廉•戈瑟特
1 8 9 9 年 ,由 于 爱 尔 兰 都 柏 林 的 吉 尼 斯 啤 酒 厂 热 衷 于 聘
用 剑 桥 、牛津的优秀 毕 业 生 ,学 化 学 的 牛 津 毕 业 生 威 廉 •戈
瑟 特 (William Gosset, 1876— 1937)到该厂就职,希望将他
的生物化学知识用于啤酒生产过程.为降低啤酒质量监控
的成本,戈瑟特发明了力检验法,1908年 在 Biometrika
表 .为 防 止 泄 漏 商 业 机 密 ,戈 瑟 特 发 表 文 章 时 用 了 笔 名 “学生”,于是该方法被
称 为 “学生氏力检验"(S tu d e n t's力-test).
吉 尼 斯 啤 酒 厂 是 一 家 很 有 远 见 的 企 业 ,为 保 持 技 术 人 员 的 高 水 准 ,该
厂 像 高 校 一 样 给 予 技 术 人 员 “学术假”,1906— 1907年 戈 瑟 特 得 以 到 “统
计 学 之 父 ” 卡 尔 • 皮 尔 逊 (Karl Pearson, 1857— 1936)教授在伦敦大学学院
(University College L o n d o n ,简 称 U C L )的实验室访 问 学 习 .因 此 ,很 难 说 t
检 验 法 是 戈 瑟 特 在 啤 酒 厂 还 是 在 U C L 访 学 期 间 提 出 的 ,但 “学 生 ” 与戈
瑟 特 之 间 的 联 系 是 被 U C L 的统计学家们发现的,尤其因为皮尔逊教授恰是
Biometrika 的主编.




第3章线性模型
亦 称 “可理解性”
derstandability).
3 . 1 基本形式
给 定 由 d 个 属 性 描 述 的 示 例 x = (力1;g ;.•.;3 ), 其 中 3 是 a 在 第 i个属
性 上 的 取 值 ,线 性 模 型 (linear m o d e l )试 图 学 得 一 个 通 过 属 性 的 线 性 组 合 来 进 行
预 测 的 函 数 ,即
f(x )= W1X1 + W2X2 + •••+ WdXd + b , (3.1)
一般用向量形式写成
/ (a?)= w T x + b , (3.2)
其 中 3 = (叫;仅2 ;... ;g ). 叨 和 b 学 得 之 后 ,模 型 就 得 以 确 定 .
线 性 模 型 形 式 简 单 、易 于 建 模 ,但 却 蕴 涵 着 机 器 学 习 中 一 些 重 要 的 基 本 思
想 .许 多 功 能 更 为 强 大 的 非 线 性 模 型 (nonlinear m o d 叫 可 在 线 性 模 型 的 基 础 上
通 过 引 入 层 级 结 构 或 高 维 映 射 而 得 .此 外 ,由 于 付 直 观 表 达 了 各 属 性 在 预 测 中
的 重 要 性 ,因 此 线 性 模 型 有 很 好 的 可 解 释 性 (comprehensibility). 例 如 若 在 西 瓜
问 题 中 学 得 “/ 好 瓜 (7) - 0.2 •n 色泽+ 0.5 •/根蒂+ 0.3 •力敲声+ 1 ” ,则 意 味 着 可
通 过 综 合 考 虑 色 泽 、 根 蒂 和 敲 声 来 判 断 瓜 好 不 好 ,其 中 根 蒂 最 要 紧 ,而 敲 声 比
色泽更重要.
本 章 介 绍 几 种 经 典 的 线 性 模 型 .我 们 先 从 回 归 任 务 开 始 ,然 后 讨 论 二 分 类
和多分类任务.
3 . 2 线性回归
给 定 数 据 集 。 = {(% 阴 ),(% 续 ),...,(防 , 斌 }, 其 中 g = 出 1;
& 2 ;...;立德),Vi e 国 " 线 性 回 归 " (linear regression)试 图 学 得 一 个 线 性 模
型以尽可能准确地预测实值输出标记.
我 们 先 考 虑 一 种 最 简 单 的 情 形 :输 入 属 性 的 数 目 只 有 一 个 .为 便 于 讨 论 ,此
时 我 们 忽 略 关 于 属 性 的 下 标 ,即 。 = {(伤,依) 其 中 g e 国 对 离 散 属 性 ,
若 属 性 值 间 存 在 “序 ”(order)关 系 ,可 通 过 连 续 化 将 其 转 化 为 连 续 值 ,例 如 二


54 第3 章线性模型
若将无序属性连续化, 则会不恰当地引入序关系, 对后续处理如距离计算等 造成误导,参 见 9 .3 节.
值 属 性 “身 高 ”的 取 值 “高 ” “矮 ”可 转 化 为 {1.0,0.0),三 值 属 性 “高 度 ”
的 取 值 “高 ” “中 ” “低 ”可 转 化 为 {1.0,0.5,0.0}; 若属性值间不存在序关
系,假 定 有 k 个属性值,则通常转化为k 维 向 量 ,例 如 属 性 “瓜类”的 取 值 “西
瓜 ” “南瓜” “黄 瓜 ”可 转 化 为 (0,0,1), (0,1,0),(1,0,0).
线性回归试图学得
/ ( g ) = wxi + ” 使得 / ( g ) + yi . (3.3)
均方误差亦称平方损失 (square loss).
如 何 确 定 仪 和 b 呢?显然,关键在于如何衡量于(5)与 y 之间的差别.2 .3节
介 绍 过 ,均 方 误 差 (2.2)是回归任务中最常用的性能度量,因此我们可试图让均
方误差最小化,即
w * , fe*表 示 似 和 b 的解.
m
(w*, b*) = arg m i n ( ^ ) - 仇产
(叫b) M
m
= a r g m i n ,2(统 —wxi —b)2 . (3.4) (皿匕)i=l
最小二乘法用途很广, 不仅限于线性回归.
这 里E(w ,b)是关于仪和 b 的凸函数,当它关于“和 b 的导数均为零时,得 到 w 和 b的最优解. 对 区 间 a[,b\上 定 义 的 函 数 f 若它对区间 中 任 意 两 点 Xi,X2均有 了(11+22 ) . “ o Q + A c z ) 则 称 :为 区 间 [a ,b ]! h 的凸'
函数. I I 形曲线的函数如 f3)= x2,通常是凸函数.
对实数集上的函数,可 通过求二阶导数来判别: 若二阶导数在区间上非负, 则 称 为 凸 函 数 ;若 二 阶 导 数在区间上恒大于0 , 则称 为严格凸函数.
均 方 误 差 有 非 常 好 的 几 何 意 义 ,它 对 应 了 常 用 的 欧 几 里 得 距 离 或 简 称 “欧
氏 距 离 "(Euclidean distance).基于均方误差最小化来进行模型求解的方法称
为 “最小二乘法”(least square m e t h o d ) . 在线性回归中,最小二乘法就是试图
找到一条直线,使所有样本到直线上的欧氏距离之和最小.
求 解 位 和 b 使 “ ) = I Z i (纳—际 一 匕产最小化的过程,称为线性回归
模 型 的 最 小 二 乘 “参 数 估 计 " (parameter e s t i m a t i o n ) . 我们可将々纳匕)分别
对 仪 和 b 求导,得到
吗署= 2 卜 玄 嵋 小 , (3.5)
\ i=l z=l /
8 Eg(w b) / , S / A /o A、
b = 2 \ mb - 与 ( 纳 - w x i)\ , (3.6)
然后令式(3.5)和(3.6)为零可得到w 和 b 最优解的闭式(closed-form)解
Em %(电一可 (3.7)


3 . 2 线性回归 55
[ flu 」 一 £ ( 比 - 仪 陶 , (3.8) m 2=1
m
其中土 = * £ ◎为力的均值• i=l
更一般的情形是如本节开头的数据集。,样 本 由 d 个属性描述.此时我们
试图学得
/ ( g ) = w T Xi + A 使得 f{xi)
手称"多变量线性回 这 称 为 “多元线性回归“(multivariate linear regression).
类似的,可利用最小二乘法来对w 和 b 进行估计.为便于讨论,我 们 把 w
和 b 吸收入向量形式w = ( w ; 6),相应的,把 数 据 集D 表示为一个m x ( d + 1 )
大小的矩阵X , 其中每行对应于一个示例,该 行 前 d 个元素对应于示例的d 个
属性值,最后一个元素恒置为1 , 即
G u x12 .•• x ld 1' (x[ 1、
力21 N22 •,• 岔2d 1 = 星 1
・・ ・
•• 17nd 1) \x m V
再把标记也写成向量形式y = (阴;数;...;阴n ) , 则类似于式(3.4),有
w * = arg m i n (g — X w ) T (y — X w ) . (3.9) w
令 E 6= (y - X w ) T (y - X w ) , 对 w 求导得到
器 = 2 X T ( X 由 一y) . (3.10)
令 上 式 为 零 可 得 岱 最 优 解 的 闭 式 解 ,但 由 于 涉 及 矩 阵 逆 的 计 算 ,比单变量情形
要复杂一些.下面我们做一个简单的讨论.
当 X T X 为 满 秩 矩 阵 (full-rank matrix)或 正 定 矩 阵 (positive definite m a
trix) 令式(3.10)为零可得
w * - ( X T X ) - 1 X T ?/ , (3.11)
其 中 ( X T X ) T 是 矩 阵 ( X T X ) 的 逆 矩 阵 .令 a = ( g ,1),则最终学得的多元


56 第 3 章 线 性 模 型
线性回归模型为
例 如 ,生 物 信 息 学 的 基 因芯片数据中常有成千上 万 个 属 性 ,但 往 往 只 有 几 十 、上百个样例.
回 忆 一 下 :解 线 性 方 程 组 时 ,若因变量 过 多,则会 解出多组解.
归 纳 偏 好 参 见 1 .4 节;正 则 化 参 见 6.4 、1 1 .4 节.
“斓 = 公 四 工 为 —1 * % . (3.12)
然而,现实任务中X T X 往往不是满秩矩阵.例如在许多任务中我们会遇到
大量的变量,其数目甚至超过样例数,导 致 X 的列数多于行数,X T X 显然不满
秩.此时可解出多个血它们都能使均方误差最小化.选择哪一个解作为输出,
将由学习算法的归纳偏好决定,常 见 的 做 法 是 引 入 正 则 化 (regularization)项.
线性模型虽简单,却有丰富的变化.例如对于样例Q , y ) , 7 / e R , 当我们希
望 线 性 模 型 ( 3 . 2 ) 的 预 测 值 逼 近 真 实 标 记 少 时 ,就 得 到 了 线 性 回 归 模 型 .为 便 于
观察,我们把线性回归模型简写为
y = w T x + b . (3.13)
可否令模型预测值逼近g 的衍生物呢?譬如说,假设我们认为示例所对应的输
出标记是在指数尺度上变化,那就可将输出标记的对数作为线性模型逼近的目
标 ,即
In?/ = w T x + b . (3.14)
这 就 是 “对数线性回归”(log-linear regression),它实际 上 是 在 试 图 让 6加”+匕
逼近沙・式(3.14)在形式上仍是线性回归,但实质上已是在求取输入空间到输出
空间的非线性函数映射,如 图 3 . 1 所示.这里的对数函数起到了将线性回归模
型的预测值与真实标记联系起来的作用.
图 3 . 1 对数线性回归示意图


3 . 3 对数几率回归 57
g(.)连续且充分光滑. 更一般地,考虑单调可微函数g ( ・),令
y = , (3.15)
这 样 得 到 的 模 型 称 为 “广 义 线 性 模 型 " (generalized linear m o d e l ) , 其中函数 计U M 黑 黑 I S g « ) 称 为 “联系函数”出 位 f u n c t i o n ) , 显然,对数线性回归是广义线性模型在
或极大似然法进行. g 9 ) = In(-)时的特例.
3 .3 对数几率回归
亦称Heaviside函数.
上一节讨论了如何使用线性模型进行回归学习,但若要做的是分类任务该
怎 么 办 ?答 案 蕴 涵 在 式 ( 3 . 1 5 ) 的 广 义 线 性 模 型 中 :只 需 找 一 个 单 调 可 微 函 数 将
分类任务的真实标记y 与线性回归模型的预测值联系起来.
考虑二分类任务,其 输 出 标 记 y G { 0 , 1 } , 而线性回归模型产生的预测值
z = w T x + b 是实值,于是,我们需将实值2 转 换 为 0 / 1 值 .最 理 想 的 是 “单位
阶跃函数“(unit-step function)
{
0, z < Q ;
0.5, z = 0 ;
1, z > 0 ,
(3.16)
即 若 预 测 值 。大 于 零 就 判 为 正 例 ,小 于 零 则 判 为 反 例 ,预测值为临界值零则可
任意判别,如 图 3 . 2 所示.
图 3 . 2 单位阶跃函数与对数几率函数


58 第 3 章 线 性 模 型
简 称 “对率函数”.
注意对数几率函数与 “对数函数” ln (・)不同.
Sigmoid函 数 即 形 似 S 的 函 数 .对 率 函 数 是 Sig moid 函数最重要的代表, 在 第 5 章将看到它在神经 网络中的重要作用.
但 从 图 3 .2 可看出,单位阶跃函数不连续,因此不能直接用作式(3.15)中
的 g—( • ) . 于 是 我 们 希 望 找 到 能 在 一 定 程 度 上 近 似 单 位 阶 跃 函 数 的 “替
代 函 数 ”(surrogate function), 并 希 望 它 单 调 可 微 .对 数 几 率 函 数 (logistic
function)正是这样一个常用的替代函数:
1
广 京 『 (3」7)
从 图 3 .2 可看出,对数几率函数是一种"Sigm oid函 数 " 它 将 z 值转化为一个
接 近 0 或 1 的 g 值,并且其输出值在z = 0 附近变化很陡.将对数几率函数作为
9 一(•)代 入 式 ( 3 .1 5 ) ,得到
y = 1 +二3 ) - (3.18)
类 似 于 式 ( 3 .1 4 ) ,式 (3.18)可变化为
In — = w T x 4- b . (3.19) 1-2/
若 将 y 视为样 本 x 作为正例的可能性,则 1 - g 是其反例可能性,两者的比值
有 文 献 译 为 “逻辑回 归”,但 中 文 “逻 辑 ”与 logistic和 lo g it的含义相 去 甚 远 ,因此本书意译为 “对数几率回归”,简称 “对率回归”.
称 为 “几 率 ”(o d d s),反 映 了 。作为正例的相对可能性.对几率取对数则得到
“对数几率”(log o d d s,亦 称 logit)
. (3.21)
\ —y
由 此 可 看 出 ,式(3.18)实 际 上 是 在 用 线 性 回 归 模 型 的 预 测 结 果 去 逼 近
真 实 标 记 的 对 数 几 率 ,因此,其 对 应 的 模 型 称 为 “对 数 几 率 回 归 " (logistic
regression,亦 称 logit regression).特别需注意到,虽然它的名字是“回归”,但
实际却是一种分类学习方法.这种方法有很多优点,例如它是直接对分类可能
性 进 行 建 模 ,无 需 事 先 假 设 数 据 分 布 ,这 样 就 避 免 了 假 设 分 布 不 准 确 所 带 来 的
问题;它 不 是 仅预测出“类别”,而是可得到近似概率预测,这对许多需利用概
率辅助决策的任务很有用;此外,对率函数是任意阶可导的凸函数,有很好的数
学性质,现有的许多数值优化算法都可直接用于求取最优解.


3 . 3 对数几率回归 59
下面我们来看看如何确定式(3.18)中 的 w 和 6 . 若将式(3.18)中 的 y 视为类
后验概率估计p(g = 1 | 宏),则式(3.19)可重写为
]口呼=:叫一 % + 6. (3.22)
p(y = 0 \x )
显然有
- 1 1况)一 ] + eW Tx + b , (3.23)
4 = ° (五) = 1 + 理 % +b ・ (3 2・4)
于是,我 们 可 通 过 “极 大 似 然 法 ”(maximum likelihood method)来估计 极大似然法参见7.2节, w 和 b 给 定 数 据 集 {(g , 纳)}口L,对 率 回 归 模 型 最 大 化 “对 数 似 然 ”(log
likelihood) m
2(幼 b) = £ Inp(% | w, 6) , (3.25) 2=1
即令每个样本属于其真实标记的概率越大越好.为便于讨论,令 6 = (w ;0 ,
X = (£C;1 ) , 则 w T x + 6 可简写为 /3T X . 再令 01(金;万)= p(y = 1 \ £ ;/3),
po(金;万)= p(y = 0 ]花;6 ) = 1 一01(余;万),则式(3.2 5 ) 中的似然项可重写为
P(yi \ % w, b) = yiP i(xi /;3) + (1 - yi)po (x i /;3) . (3.26)
将 式 (3.26)代 入 ( 3 .2 5 ) ,并根据式 (3.23)和 (3.24)可 知 ,最大 化 式 (3.25)等价于
最小化 m
。(9)=£ 优 色 + m (1 + 产 办 ) ) . (3.27)
Z=1
式(3.27)是 关 于 万 的 高 阶 可 导 连 续 凸 函 数 ,根 据 凸 优 化 理 论 [Boyd and
Vandenberghe, 2004 ,]经 典 的 数 值 优 化 算 法 如 梯 度 下 降 法 (gradient descent
method) >牛顿法(Newton method)等都可求得其最优解,于是就得到
3* = arg min . (3.28)
以牛顿法为例,其 第 t + 1 轮迭代解的更新公式为
" ” -(飘厂鬻, 3


60 第 3 章 线 性 模 型
其 中 关 于 万 的 一 阶 、二阶导数分别为
= 一£ 打 (班 一P i (自;万)),
2=1
一夕1(金;乃)).
(3.30)
(3.31)
3 . 4 线性判别分析
线性判别分析(Linear Discriminant A nalysis,简 称 L D A)是一种经典的线
Fi hZ 性学习方法,在二分类问题上因为最早由 F[isher, 1936]提出,亦 称 “ F isher判
尹」另V分析才再有不同,目U考
假 设 了 各 类 样 本 的 协 方 差 别分析”. 矩阵相同且满秩.
L D A 的思想非常朴素:给定训练样例集,设法将样例投影到一条直线上,
使得同类样例的投影点尽可能接近、异类样例的投影点尽可能远离;在对新样
本进行分类时,将其投影到同样的这条直线上,再根据投影点的位置来确定新
样本的类别.图3 .3 给出了一个二维示意图.
图 3.3 L D A 的 二 维 示 意 图 . “+ ” 、 “- ”分别代表正例和反例,椭圆表示数据簇的 外 轮 廓 ,虚 线 表 示 投 影 ,红 色 实 心 圆 和 实 心 三 角 形 分 别 表 示 两 类 样 本 投 影 后 的 中 心 点 .
给 定 数 据 集 。 = {(即 统 )} Vi e { 0 , 1 } , 令 石 、眼、乂 分 别 表 示 第
分G { 0 , 1 } 类示例的集合、均值向量、协方差矩阵.若将数据投影到直线叨上,
则两类样本的中心在直线上的投影分别为W T M O 和 W T M 1 ;若将所有样本点都
投影到直线上,则两类样本的协方差分别为伊1 2 0 % 和伊丁历也 由于直线是


3 . 4 线性判别分析 61
(3.32)
一维空间,因 此 ty T /z o 、w T / / i > W 丁耳)!!;和 均 为 实 数 .
欲使同类样例的投影点尽可能接近,可以让同类样例投影点的协方差尽可
能小,即也T2()叨 + 叨 1 2 % 尽可能小;而欲使异类样例的投影点尽可能远离,
可以让类中心之间的距离尽可能大,即 ||wT M o - w T Mi||i 同时考虑
二者,则可得到欲最大化的目标
j = ||付丁4 0 ― % T 从1仿
W T S QW + w T E i w
= 也T (从0 — 4 1 ) ( 4 0 — 4 1 ) T ^
w T (So + E i ) w '
定 义 “类内散度矩阵" (within-class scatter matrix)
S w = E o 4- E i
= £ (« - Mo) (a? - MO)T + £ - Mi) - MI )T
X E X Q JCC X I
以 及 “类 间 散 度 矩 阵 "(between-class scatter matrix)
Sb = (Mo - Mi) ( M o - MI )T ,
则式(3.32)可重写为
w T Sw w .
这 就 是 L D A 欲 最 大 化 的 目 标 ,即 S b 与 % 的 “广 义 瑞 利 商 ”(generalized
Rayleigh quotient).
如 何 确 定 w 呢?注意到式(3.35)的分子和分母都是关于w 的二次项,因此
式(3.35)的解与w 的长度无关,只与其方向有关.不失一般性,令 w T S w w = 1, 则式(3.35)等价于 ‘
m i n —w T SftW (3.36)
w
s.t. w T S Wiw = 1 .
由拉格朗日乘子法,上式等价于
(3.33)
(3.34)
(3.35)
若 t u 是 一 个 解 ,则对 于 任 意 常 数 a, a w 也是 式(3.35)的解.
拉格朗日乘子法参见附 录 B.1,
SbW = XSw w , (3.37)


62 第 3 章 线 性 模 型
奇异值分解参见附录 A.3.
参 见 习 题 7.5.
其 中 A 是拉格朗日乘子.注意到Sbw 的方向恒为M 0 - 皿, 不妨令
Sbw = A (/i0 - M i ) , (3.38)
代入式(3.37)即得
w = S ~ 1 (JJ/O - - (3.39)
考 虑 到 数 值 解 的 稳 定 性 ,在 实 践 中 通 常 是 对 Sw 进 行 奇 异 值 分 解 ,即 Sw =
U E V T , 这 里 E 是一个实对角矩阵,其 对 角 线 上 的 元 素 是 Sw 的奇异值,然后
再 由 S U = V E - XU T 得 到 S” .
值得一提的是,L D A 可从贝叶斯决策理论的角度来阐释,并可证明,当两
类数据同先验、满足高斯分布且协方差相等时,L D A 可达到最优分类.
可 以 将 L D A 推广到多分类任务中..假定存在N 个类,且 第 i 类示例数为
团: 我 们 先 定 义 “全局散度矩阵”
St = Sb + Sw
m
= £ 包 —(4) W —4 ) T , (3.40)
其 中 M 是所有示例的均值向量.将类内散度矩阵Sw 重定义为每个类别的散度
矩阵之和,即
N
Sw = S g , (3.41)
2=1
其中
S皿 = £ (1 一 %)Q - % )T . (3.42)
xeX i
由式(3.40)~(3.42)可得
Sb = S2 —Sw
N
= 〉: » j — — 4 ) , • (3.43)
i —l
显然,多分类L D A 可以有多种实现方法:使用Sb, S g St 三者中的任何两
个即可.常见的一种实现是采用优化目标


3 . 5 多分类学习 6 3
降 维 参 见 第 1 0 章.
例如上一节最后介绍的 L D A 推广.
通常称分类学习器为 "分 类 器 " (classifier).
关于多个分类器的集成, 参 见 第 8 章.
O v R 亦称 O v A ( O n e vs. All),但O v A 这个说法不严 格 ,因 为 不 可 能 把 “所有 类 ”作为反类.
亦可根据各分类器的预 测置信度等信息进行集成, 参 见 8 .4节.
tr (W T S6W ) / 、
嘴 % (W TS妙W ) , (3) 44)
其 中 W €肽dx(N-1),任(.)表示矩阵的迹(trace).式(3.44)可通过如下广义特征
值问题求解:
SbW = ASw W . (3.45)
W 的 闭 式 解 则 是 的 N - 1 个最大广义特征值所对应的特征向量组成的
矩阵.
若 将 W 视为一个投影矩阵,则 多 分 类 L D A 将 样本投影到N - 1 维空间,
N - 1 通常远小于数据原有的属性数.于是,可通过这个投影来减小样本点的
维数,且投影过程中使用了类别信息,因此L D A 也常被视为一种经典的监督降
维技术.
3 . 5 多分类学习
现实中常遇到多分类学习任务.有些二分类学习方法可直接推广到多分类,
但在更多情形下,我们是基于一些基本策略,利用二分类学习器来解决多分类
问题.
不 失 一 般 性 ,考 虑 N 个 类 别 C 1 & , ... ,CN , 多分类学习的基本思路是
“拆解法”,即将多分类任务拆为若干个二分类任务求解.具体来说,先对问题
进行拆分,然后为拆出的每个二分类任务训练一个分类器;在测试时,对这些分
类器的预测结果进行集成以获得最终的多分类结果.这里的关键是如何对多分
类任务进行拆分,以及如何对多个分类器进行集成.本节主要介绍拆分策略.
最经典的拆分策略有三种: “一对一”(One vs. O n e , 简 称 O v O ) 、 “一对
其余“(One vs. Rest,简称 O v R ) 和 "多 对 多 " (Many vs. M a n y , 简称 M vM).
给定数据集。 = {(«1, t/1), («2, ?/2), ..., Vm)}, Vi G ... ,CN }.
O v O 将 这 N 个类别两两配对,从而产生N(N - 1)/2个二分类任务,例如O v O
将为区分类别必 和 G 训练一个分类器,该分类器把。 中 的 C e 类样例作为正
例,g 类样例作为反例.在测试阶段,新样本将同时提交给所有分类器,于是我
们将得到N ( N - 1)/2个分类结果,最终结果可通过投票产生:即把被预测得最
多的类别作为最终分类结果.图3.4给出了一个示意图.
O v R 则是每次将一个类的样例作为正例、所有其他类的样例作为反例来
训 练 N 个分类器.在测试时若仅有一个分类器预测为正类,则对应的类别标记
作为最终分类结果,如 图 3.4所示.若有多个分类器预测为正类,则通常考虑各


64 第 3 章 线 性 模 型
属于类Q 的样例集合
数 据 集 C ] 。 2 0 3 。4
用于训练的
+
两类样例
回叵叵叵
w
叵
。/
公来哭预测
分类器结果
釐 霸 )今于1 T C ,
今于2 T C3
今 /3 1 G
今 力 T C3
国 )=为T 。2
“十
用于训练的 两类样例
I(G I 匕虞豆侬|;)
(a |
分 类 器 2S 用禾 合 力 T “一 ”
今 f2 T “一”
最终 结果
T 。3 (叵 晦缪透|)令 f4 T “ 一”
最终 结果
。3
分于6 T 0 3
。 3 豳)今 / 3 1 “ + ”
图 3.4 O v O 与 O v R 示意图
分类器的预测置信度,选择置信度最大的类别标记作为分类结果.
容易看出,O v R 只 需 训 练 N 个分类器,而 O v O 需 训 练 N (N - 1)/ 2 个分
类器,因此,OvO的存储开销和测试时间开销通常比O v R 更大.但在训练时,
O v R 的每个分类器均使用全部训练样例,而 O v O 的每个分类器仅用到两个类
的样例,因此,在类别很多时,O v O 的训练时间开销通常比O v R 更小.至于预
测性能,则取决于具体的数据分布,在多数情形下两者差不多.
M vM 是绛次将若干个类作为正类,若干个其他类作为反类.显然,O vO 和
O v R 是 M vM 的 特 例 .M v M 的正、反类构造必须有特殊的设计,不能随意选
取.这里我们介绍一种最常用的M vM 技术: “纠 错 输 出 码 "(Error Correcting
Output C odes,简称 ECOC).
ECOC [Dietterich and Bakiri, 1995]是将编码的思想引入类别拆分,并尽
可能在解码过程中具有容错性.E C O C 工作过程主要分为两步:
• 编码:对 N 个 类 别 做 河 次 划 分 ,每次划分将一部分类别划为正类,一部
分划为反类,从而形成一个二分类训练集;这样一共产生M 个训练集,可
训 练 出 M 个分类器.
・解码:M 个分类器分别对测试样本进行预测,这些预测标记组成一个编
码.将这个预测编码与每个类别各自的编码进行比较,返回其中距离最小
的类别作为最终预测结果.


3 . 5 多分类学习 65
类 别 划 分 通 过 “编 码 矩 阵 "(coding matrix)指定.编码矩阵有多种形式,
常 见 的 主 要 有 二 元 码 [Dietterich and Bakiri, 1995]和 三 元 码 [Allwein et al.,
2000 .] 前者将每个类别分别指定为正类和反类,后者在正、反类之外,还可指
定 “停用类”. 图 3 .5 给出了一个示意图,在 图 3.5(a)中,分 类 器 h 将 C i 类和
Q 类的样例作为正例,3 类 和 。4 类的样例作为反例;在 图 3.5(b)中,分类器
A 将 Q 类 和 类 的 样 例 作 为 正 例 ,圆类的样例作为反例.在解码阶段,各分
类器的预测结果联合起来形成了测试示例的编码,该编码与各类所对应的编码
进行比较,将距离最小的编码所对应的类别作为预测结果.例如在图3 .5 (a )中,
若基于欧氏距离,预测结果将是圆.
( a ) 二元 ECOC 码 ( b ) 三 元 ECOC码
图 3.5 E C O C 编 码 示 意 图 . 分 别 表 示 学 习 器 力 将 该 类 样 本 作 为 正 、反例;三 元 码 中 “0” 表示力不使用该类样本
为 什 么 称 为 “纠错输出码”呢?这是因为在测试阶段,E C O C 编码对分类
器的错误有一定的容忍和修正能力.例如图3.5(a)中对测试示例的正确预测编
码是(一1 ,+ 1 ,+ 1 ,— 假设在预测时某个分类器出错了,例如力出错从而
导致了错误编码(-1 , - 但基于这个编码仍能产生正确的最终分
类 结 果 一 般 来 说 ,对 同 一 个 学 习 任 务 ,ECO C编码越长,纠错能力越强.然
而 ,编 码 越 长 ,意 味 着 所 需 训 练 的 分 类 器 越 多 ,计 算 、存 储 开 销 都 会 增 大 ;另一
方面,对有限类别数,可能的组合数目是有限的,码长超过一定范围后就失去了
意义.
对同等长度的编码,理论上来说,任意两个类别之间的编码距离越远,则纠
错 能 力 越 强 .因 此 ,在 码 长较小 时可根据 这个原 则计算 出理论最 优编码 .然 而,
码长稍大一些就难以有效地确定最优编码,事实上这是N P 难问题.不过,通常
我们并不需获得理论最优编码,因为非最优编码在实践中往往已能产生足够好
的分类器.另一方面,并不是编码的理论性质越好,分类性能就越好,因为机器


66 第 3 章 线 性 模 型
学习问题涉及很多因素,例 如 将 多 个 类 拆 解 为 两 个 “类别子集”,不同拆解方
式所形成的两个类别子集的区分难度往往不同,即其导致的二分类问题的难度
不 同 ;于 是 ,一 个 理 论 纠 错 性 质 很 好 、但 导 致 的 二 分 类 问 题 较 难 的 编 码 ,与另一
个理论纠错性质差一些、但导致的二分类问题较简单的编码,最终产生的模型
性能孰强孰弱很难说.
对 O v R 、M v M 来说,由 于对每个类进行了相同的 处理,其拆解出的二分类 任务中类别不平衡的影响 会 相 互 抵 消 ,因此通常不 需专门处理.
3 .6 类别不平衡问题
前面介绍的分类学习方法都有一个共同的基本假设,即不同类别的训练样
例数目相当.如果不同类别的训练样例数目稍有差别,通常影响不大,但若差别
很大,则会对学习过程造成困扰.例如有998个反例,但 正 例 只 有 2 个 ,那么学
习方法只需返回一个永远将新样本预测为反例的学习器,就 能 达 到 99.8% 的精
度;然而这样的学习器往往没有价值,因为它不能预测出任何正例.
类 别 不 平 衡 (class-imbalance)就 是 指 分 类 任 务 中 不 同 类 别 的 训 练 样 例 数
目 差 别 很 大 的 情 况 .不 失 一 般 性 ,本 节 假 定 正 类 样 例 较 少 ,反类样例较多.
在 现 实 的 分 类 学 习 任 务 中 ,我 们 经 常 会 遇 到 类 别 不 平 衡 ,例 如 在 通 过 拆 分
法 解 决 多 分 类 问 题 时 ,即 使 原 始 问 题 中 不 同 类 别 的 训 练 样 例 数 目 相 当 ,在使
用 O v R 、MvM策 略 后 产 生 的 二 分 类 任 务 仍 可 能 出 现 类 别 不 平 衡 现 象 ,因此有
必要了解类别不平衡性处理的基本方法.
从线性分类器的角度讨论容易理解,在 我 们 用 y = w T x ^ b 对新样本7
进 行 分类时,事 实 上 是 在 用 预 测 出 的 g 值与一个阈值进行比较,例如通常在
y > 0 .5 时判别为正例,否 则 为 反 例 .y 实际上表达了正例的可能性,几 率 击
则反映了正例可能性与反例可能性之比值,阈值设置为0 .5 恰表明分类器认为
真 实 正 、反例可能性 相同 ,即分类器决策规则为
若 -^ ― > 1 贝IJ预测为正例. (3.46) 1 —,
无偏采样意味着真实样 本总体的类别比例在训练 集中得以保持.
然而,当训练集中正、反例的数目不同时,令 团 +表 示 正 例 数 目 ,皿一表示 反例数目,则 观 测 几 率 是 冬 ,由于我们通常假设训练集是真实样本总体的无偏
采样,因此观测几率就代表了真实几率.于是,只要分类器的预测几率高于观测
几率就应判定为正例,即
若 兰 — > 贮则预测为正例.
1—y m~ (3.47)


3 . 7 阅读材料 67
但 是 ,我 们 的 分 类 器 是 基 于 式 (3.46)进 行 决 策 ,因此,需 对其预测值进行调
整,使其在基于式(3.46)决策时,实际是在执行式(3 .4 7 ).要做到这一点很容易,
只需令 _ yf y m~ 公 ,小
1 / 一 1 义 + , (3.48)
1—yf 1 —1/ Tn+
亦 称 “再平衡” (rebal
ance). 这就是类别不平衡学习的一个基本策略— “再 缩 放 "(rescaling).
再缩放的思想虽简单,但实际操作却并不平凡,主 要 因 为 “训练集是真实
样本总体的 无 偏 采 样 ”这个假设往往并不成立,也就是说,我们未必能有效
地 基 于 训 练 集 观 测 几 率 来 推 断 出 真 实 几 率 .现 有 技 术 大 体 上 有 三 类 做 法 :第
一 类 是 直 接 对 训 练 集 里 的 反 类 样 例 进 行 “欠采样”(undersam pling),即去除 欠 采 样 亦 称 “下采样” (downsampling), 过 采 样 亦 称 " 上 采 样 " (upsam pling).
一些反例 使 得 正 、反例数目接近,然后再进行学习;第二类是对训练集里的
正 类 样 例 进 行 “过采样" (oversampling),即增加一些正例使得正、反例数目
接近,然后 再 进 行 学 习 ;第 三 类 则 是 直 接 基 于 原 始 训 练 集 进 行 学 习 ,但在用
训练好的分类器进行预测时,将式(3.48)嵌入到其决策过程中,称 为 “阈值移
动 ”(threshold-moving).
欠采样法的时间开销通常远小于过采样法,因为前者丢弃了很多反例,使
得 分 类 器 训 练 集 远 小 于 初 始 训 练 集 ,而 过 采 样 法 增 加 了 很 多 正 例 ,其 训 练 集
大 于 初 始 训 练 集 .需 注 意 的 是 ,过采样法不能简单地对初始正例样本进行重
复采样,否则会招致严重的过拟合;过采样法的代 表 性 算 法 SMOTE [Chawla
et al., 2002]是通过对训练集里的正例进行插值来产生额外的正例.另一方面,
欠 采 样 法 若 随 机 丢 弃 反 例 ,可 能 丢 失 一 些 重 要 信 息 ;欠 采 样 法 的 代 表 性 算 法
EasyEnsemble [Liu et al., 2009]则是利用集成学习机制,将反例划分为若干个
集合供不同学习器使用,这样对每个学习器来看都进行了欠采样,但在全局来
看却不会丢失重要信息.
值 得一提的是, "再 缩 放 "也 是 "代 价 敏 感 学 习 ”(cost-sensitive leam代价敏感学习研究非 均等代价下的学习.参见 2.3.4 节.
ing)的基础.在代价敏感学习中将式(3.48)中 的m~/m+ 用 co〃+/co5厂代替即
可 ,其 中 cost+ 是将正例误分为反例的代价,cost-是将反例误分为正例的代价.
3 .7 阅读材料
“稀疏表示" (sparse representation)近年来很受关注,但即便对多元线性
回归这样简单的模型,获 得 具 有 最 优 “稀疏性”(sparsity)的解也并不容易.稀
疏性问题本质上对应了 Lo 范数的优化,这在通常条件下是N P 难问题.LASSO
参见第11章. [Tibshirani, 1996]通 过 J 范数来近似Lo 范数,是求取稀疏解的重要技术.


68 第 3 章 线 性 模 型
可以证明,O vO 和 O vR 都 是 E C O C 的 特 例 [Allwein et al., 2000 .]人们以
往希望设计通用的编码法"C ram m er and Singer, 2002]提出要考虑问题本身
的特点,设 计 “问题依赖”的编码法,并证明寻找最优的离散编码矩阵是一个
N P 完全问题.此后,有多种问题 依 赖 的 E C O C 编码法被提出,通常是通过找
出具有代表性的二分类问题来进行编码 P[ujol et aL, 2006, 2008 .] E[scalera et
al., 2010卜开发了一个开源E C O C 库.
M v M 除了 E C O C 还 可 有 其 他 实 现 方 式 ,例 如 DAG (Directed Acyclic
G raph)拆 分 法 P[latt et al., 2000]将类别划分表达成树形结构,每个结点对应
于一个二类分类器.还有一些工作是致力于直接求解多分类问题,例如多类支
持向量机方面的一些研究[Crammer and Singer, 2001; Lee et al., 2004 .]
代 价 敏 感 学 习 中 研 究 得 最 多 的 是 基 于 类 别 的 “误 分 类 代
价 ”(misclassifcation c o s t),代 价 矩 阵 如 表 2 .2 所 示 ;本 书 在 提 及 代 价 敏 感
学习时,默 认 指 此 类 情 形 .已 经 证 明 ,对 二 分 类 任 务 可 通 过 “再 缩 放 ”获得理论
最 优 解 E[lkan, 2001 ,]但对多分类任务,仅在某些特殊情形下存在闭式解[Zhou
and Liu, 2006a .] 非 均等代价和类别不平衡性虽然都可借助“再缩 放 ”技术,
但 两 者 本 质 不 同 [Zhou and Liu, 2006b .] 需注意的是,类别不平衡学习中通常
是较小类的代价更高,否则无需进行特殊处理.
多分类学习中虽然有多个类别,但每个样本仅属于一个类别.如果希望为
一个样本同时预测出多个类别标记,例 如 一 幅 图 像 可 同 时 标 注 为 “蓝 天 ”、
“白云”、 “羊 群 ”、 “自然场景”,这样的任务就不再是多分类学习,而是
“多标记学习“(multi-label learning),这是机器学习中近年来相当活跃的一个
研究领域.对多标记学习感兴趣的读者可参阅[Zhang and Zhou, 2014 .]


习题 69
习题
3.1 试析在什么情形下式(3.2)中不必考虑偏置项b.
3.2 试证明,对 于 参 数 犯 对 率 回 归 的 目 标 函 数 (3.18)是非凸的,但其对数
似然函数(3.27)是凸的.
西瓜数据集3 .0 a 见 p.89
的 表 4 5 3.3 编程实现对率回归,并给出西瓜数据集3 .0 a 上的结果.
U C I数据集见
http://archive.ics.uci.edu/ml/. 3.4 选 择 两 个 U C I数据集,比 较 1 0 折交叉验证法和留一法所估计出的对 率回归的错误率.
3.5 编程实现线性判别分析,并给出西瓜数据集3 .0 a 上的结果.
线性可分是指存在线性 超平面能将不同类的样本 点 分 开 .参 见 6 .3 节.
3.6 线性判别分析仅在线性可分数据上能获得理想结果,试设计一个改进
方法,使其能较好地用于非线性可分数据
3.7 令 码 长 为 9 , 类 别 数 为 4 , 试给出海明距离意义下理论最优的ECOC
二元码并证明之.
3.8* E C O C 编码能起到理想纠错作用的重要条件是:在每一位编码上出错
的 概率相当且独立.试析多分类任务经E C O C 编码后产生的二类分
类器满足该条件的可能性及由此产生的影响.
3.9 使 用 O vR和 MvM将多分类任务分解为二分类任务求解时,试述为何
无需专门针对类别不平衡性进行处理.
3.10* 试推导出多分类代价敏感学习(仅考虑基于类别的误分类代价)使用
“再缩放”能获得理论最优解的条件.


70 第 3 章 线 性 模 型
参考文献
Allwein, E. L., R. E. Schapire, and Y. Singer. (2000). ^Reducing multiclass
to binary: A unifying approach for margin classifiers.55 Journal of Machine
Learning Research, 1:113-141.
Boyd, S. and L. Vandenberghe. (2004). Convex Optimization. Cambridge Uni
versity Press, Cambridge, UK.
Chawla, N. V., K. W. Bowyer, L. O. Hall, and W. P. Kegelmeyer. (2002).
“SMOTE: Synthetic minority over-sampling technique.5, Journal of Artificial
Intelligence Research^ 16:321-357.
Crammer, K. and Y. Singer. (2001), “On the algorithmic implementation of
multiclass kernel-based vector machines.,, Journal of Machine Learning Re
search, 2:265-292.
Crammer, K. and Y. Singer. (2002). “On the learnability and design of output
codes for multiclass problems." Machine Learning^ 47(2-3):201-233.
Dietterich, T. G. and G. Bakiri. (1995). “Solving multiclass learning problems
via error-correcting output codes." Journal of Artificial Intelligence Re
search^ 2:263-286.
Elkan, C. (2001). “The foundations of cost-sensitive learning.5, In Proceedings
of the 17th International Joint Conference on Artificial Intelligence (IJCAI)1
973-978, Seattle, WA.
Escalera, S., O. Pujol, and P. Radeva. (2010). “Error-correcting ouput codes
library.5, Journal of Machine Learning Research^ 11:661-664.
Fisher, R. A. (1936). “The use of multiple measurements in taxonomic prob
lems.55 Annals of Eugenics1 7(2):179-188.
Lee, Y., Y. Lin, and G. Wahba. (2004). “Multicategory support vector ma
chines, theory, and application to the classification of microarray data and
satellite radiance data." Journal of the American Statistical Association^ 99
(465):67-81.
Liu, X.-Y., J. Wu, and Z.-H. Zhou. (2009). ^Exploratory undersamping for
class-imbalance learning.^^ IEEE Transactions on Systems, Man, and Cyber
netic^ - Part B: Cybernetics1 39(2):539-550.
Platt, J. C., N. Cristianini, and J. Shawe-Taylor. (2000). “Large margin DAGs


参考文献 71
for multiclass classification? In Advances in Neural Information Processing
Systems 12 (NIPS) (S. A. Solla, T. K. Leen, and K.-R. Muller, eds.), MIT
Press, Cambridge, MA.
Pujol, 0., S. Escalera, and P. Radeva. (2008). “An incremental node embedding
technique for error correcting output codes." Pattern Recognition, 41(2):713
725.
Pujol, O., P. Radeva, and J. Vitria. (2006). ^Discriminant ECOC: A heuristic
method for application dependent design of error correcting output codes.,5
IEEE Transactions on Pattern Analysis and Machine Intelligence^ 28(6):
1007-1012.
Tibshirani, R. (1996). ^Regression shrinkage and selection via the LASSO.”
Journal of the Royal Statistical Society: Series 58(1):267-288.
Zhang, M.-L. and Z.-H. Zhou. (2014). “A review on multi-label learning al
gorithms.5, IEEE Transactions on Knowledge and Data Engineering1 26(8):
1819-1837.
Zhou, Z.-H. and X.-Y. Liu. (2006a). “On multi-class cost-sensitive learn in g .In
Proceeding of the 21st National Conference on Artificial Intelligence (AAAI)^
567-572, Boston, WA.
Zhou, Z.-H. and X.-Y. Liu. (2006b). “Training cost-sensitive neural networks
with methods addressing the class imbalance problem.^^ IEEE Transactions
on Knowledge and Data Engineering^ 18(1):63-77.


72 第 3 章 线 性 模 型
休息一会儿
小故事:关 于 “最小二乘法”
1 8 0 1 年 ,意 大 利 天 文 学 家 皮 亚 齐
发现了 1 号 小 行 星 “谷神星”,但在跟
踪观测了 4 0 天后,因谷神星转至太阳
的背后,皮亚齐失去了谷神星的位置.
许多天文学家试图重新找到谷神星,但 (1993年版德国10马克纸币上的高斯像)
都徒劳无获.这引起了伟大的德国数
学 家 高 斯 (1777— 1855)的注意,他发明了一种方法,根据皮亚齐的观测数据计
算出了谷神星的轨道,后来德国天文学家奥伯斯在高斯预言的时间和星空领域
重新找到了谷神星. 1809年,高 斯 在 他 的 著 作 《天体运动论》 中发表了这种方
法,即最小二乘法.
另两位是拉格朗日和拉 普 拉 斯 ,三 人 姓 氏 首 字 母 相 同 ,时 称 “ 3L” .
1 8 0 5 年 ,在 椭 圆 积 分 、数论和 几 何 方 面 都 有 重 大 贡 献 的 法 国 大 数 学 家 勒 让
德 (1752— 1833)发 表 了 《计算彗星轨道的新方法》,其附录中描述了最小二乘
法 .勒 让 德 是 法 国 18— 1 9 世纪数学界的三驾马车之一,早已是法国科学院院
士.但勒让德的书中没有涉及最小二乘法的误差分析,高 斯 1809年的著作中包
括了这方面的内容,这对最小二乘法用于数理统计、乃至今天的机器学习有极
为 重 要 的 意 义 .由 于 高 斯 的 这 一 重 大 贡 献 ,以 及 他 声 称 自 己 1 7 9 9 年就已开始使
用这个方法,因此很多人将最小二乘法的发明优先权归之为高斯.当时这两位
大数学家发生了著名的优先权之争,此后有许多数学史家专门进行研究,但至
今也没弄清到底是谁最先发明了最小二乘法.


第4章 决 策 树
4 .1 基本流程
亦 称 “判定树”.根 据 上下文,本 书 中 的 “决策 树 ”有时是指学习方法, 有时是指学得的树.
决 策树(decision tr e e ) 是 一 类 常 见 的 机 器 学 习 方 法 .以 二 分 类 任 务 为 例 ,我
们 希 望 从 给 定 训 练 数 据 集 学 得 一 个 模 型 用 以 对 新 示 例 进 行 分 类 ,这 个 把 样 本
分 类 的 任 务 ,可 看 作 对 “当 前 样 本 属 于 正 类 吗 ?”这 个 问 题 的 “决 策 ”或 “判
定 ”过 程 .顾 名 思 义 ,决策树是基于树结构来进行决策的,这恰是人类在面临决
策 问 题 时 一 种 很 自 然 的 处 理 机 制 .例 如 ,我 们 要 对 “这 是 好 瓜 吗 ?”这样的问题
进 行 决 策 时 ,通 常 会 进 行 一 系 列 的 判 断 或 “子 决 策 ”:我 们 先 看 “它是什么颜
色 ?”,如 果 是 “青 绿 色 ”,则 我 们 再 看 “它 的 根 蒂是什么形态?”,如 果 是 “蜷
缩 ”,我 们 再 判 断 “它敲起来是什么声音?”,最 后 ,我们得出最终决策:这是个
好 瓜 .这 个 决 策 过 程 如 图 4 .1 所示.
图 4 . 1 西瓜问题的一棵决策树
显 然 ,决 策 过 程 的 最 终 结 论 对 应 了 我 们 所 希 望 的 判 定 结 果 ,例 如 “是 ”或
“不 是 ”好 瓜 ;决 策 过 程 中 提 出 的 每 个 判 定 问 题 都 是 对 某 个 属 性 的 “测 试 ”,
例 如 “色 泽 = ? ” “根 蒂 = ? ”;每 个 测 试 的 结 果 或 是 导 出 最 终 结 论 ,或是导出
进 一 步 的 判 定 问 题 ,其 考 虑 范 围 是 在 上 次 决 策 结 果 的 限 定 范 围 之 内 ,例如若在
“色 泽 = 青 绿 ”之 后 再 判 断 “根蒂= ? ”,则仅在考虑青绿色瓜的根蒂.
一 般 的 ,一 棵 决 策 树 包 含 一 个 根 结 点 、若 干 个 内 部 结 点 和若干个叶结点;


74 第4 章 决 策 树
叶结点对应于决策结果,其他每个结点则对应于一个属性测试;每个结点包含
的 样 本 集 合 根 据 属 性 测 试 的 结 果 被 划 分 到 子 结 点 中 ;根 结 点 包 含 样 本 全 集 .从
根结点到每个叶结点的路径对应了一个判定测试序列.决策树学习的目的是为
了产生一棵泛化能力强,即处理未见示例能力强的决策树,其基本流程遵循简
单 且 直 观 的 “分 而 治 之 "(divide-and-conquer)策略,如 图 4.2所示.
递归返回,情形(1).
递归返回,情形(2).
我们将在下一节讨论如 何获得最优划分属性.
递归返回,情形(3).
从 4 中去掉a*.
输入:训练集。 = {(Xi, 7/i),(CC2 ,2/2), .•., 2/m)}; 属性集 4 = {。1, 过程:函数 TreeGenerate(Z), A) 1:生成结点node; 2:if D 中样本全属于同一类别C then 3: 将 n o d e 标记为。类叶结点;return
4:end if
5:ifA = 0 O R P 中样本在A 上取值相同then 6: 将 n o d e 标记为叶结点,其类别标记为D 中样本数最多的类;return 7:end if
8:从 4 中选择最优划分属性a*; 9:for a * 的每一个值a;do 10: 为 n o d e 生成一个分支;令 D v 表 示 D 中在a * 上取值为磴的样本子集;
11: if D y 为空 then 12: 将分支结点标记为叶结点,其类别标记为D 中样本最多的类;return 13: else 14: 以 TreeGenerate(Bv , A \ {a*})为分支结点 15: end if 16: end for
输出:以 n o d e 为根结点的一棵决策树
图 4 . 2 决策树学习基本算法
显然,决策树的生成是一个递归过程.在决策树基本算法中,有三种情形会
导致递归返回:( 1 ) 当前结点包含的样本全属于同一类别,无需划分;( 2 ) 当前
属性集为空,或是所有样本在所有属性上取值相同,无法划分;( 3 ) 当前结点包
含的样本集合为空,不能划分.
在 第 (2) 种 情 形 下 ,我 们 把 当 前 结 点 标 记 为 叶 结 点 ,并将其类别设定为该结
点所含样本最多的类别;在 第 (3) 种 情 形 下 ,同样把当前结点标记为叶结点,但
将其类别设定为其父结点所含样本最多的类别.注意这两种情形的处理实质不
同:情形(2)是在利用当前结点的后验分布,而情形(3)则是把父结点的样本分布
作为当前结点的先验分布.


4 . 2 划分选择 75
计 算 信 息 嫡 时 约 定 :若 p = 0,则 P log2 P = 0
E n t(L > )的 最 小 值 为 0,
最大底为log2 3 .
ID 3 名 字 中 的 I D 是 It erative Dichotomiser (迭代 二分器)的简称.
4 .2 划分选择
由 算法4 .2 可看出,决策树学习的关键是第8 行,即如何选择最优划分属
性 . 一 般 而 言 ,随着划分过程不断进行,我们希望决策树的分支结点所包含的样
本尽可能属于同一类别,即 结 点 的 “纯度”(purity)越来越高.
4 .2 .1 信息增益
“信 息 病 " (information entropy)是度量样本集合纯度最常用的一种指标.
假定当前样本集合。 中 第 k 类 样 本 所 占 的 比 例 为 也 (k = 1 ,2 ,... ,3 ) , 则 D
的信息嫡定义为
3
E nt(P ) = - £ p k log2 Pfc . (4.1) k=l
E n t(D )的值越小,则 D 的纯度越高.
假定离散属性a 有 V 个 可 能 的 取 值 谓 , ... , 若使用a 来对样本集
D 进行划分,则会产生V 个分支结点,其 中 第v 个分支结点包含了 D 中所有在
属 性 a 上 取 值 为 淤 的 样 本 ,记 为 D \ 我们可根据式(4 .1 )计 算 出D - 的信息嫡,
再考虑到不同的分支结点所包含的样本数不同,给分支结点赋予权重\DV \/\D\,
即样本数越多的分支结点的影响越大,于是可计算出用属性a 对样本 集D 进行
划 分 所 获 得 的 “信息增益”(information gain)
Gain(Z), a) = E nt(P ) - £ 鲁 . (4.2)
V=1 I I
一般而言,信息增益越大,则意味着使用属性a 来 进 行 划 分 所 获 得 的 “纯
度 提 升 ”越 大 .因 此 ,我们可用信息增 益 来 进 行 决 策 树 的 划 分 属 性 选 择 ,即在图
4 .2 算 法 第 8 行 选 择 属 性 a* = a rg m a x G a in (P ,a ).著 名 的 ID 3 决策树学习算
aeA 法 [Quinlan, 1986]就是以信息增益为准则来选择划分属性.
以 表 4 .1 中的西瓜数据集2 .0 为例,该 数 据 集 包 含 1 7 个训练样例,用以学
习一棵能预测没剖开的是不是好瓜的决策树.显然,|川= 2 . 在决策树学习开
始时,根 结 点 包 含 。 中的所有样例,其中正例占m = 备,反 例 占 次 = 告 .于
是,根据式(4.1)可计算出根结点的信息熠为
、 / g & 9 9\
E nt(P ) = —f p k log2 pfe = ~ (正 l°g2 记 + 诉 10g2 17 ) = °-9 9 8 •
I?— 1 \ '


76 第 4 章 决 策 树
表 4 . 1 西 瓜 数 据 集 2.0
是师
滑硬 感触 滑粘粘滑滑
硬软软硬硬
凹凹凹陷陷陷陷陷部
稍稍稍凹凹凹凹凹脐
清晰 稍糊 晰清 晰清 晰清 晰清 晰清 晰清 理纹
否否否否否否否否否
滑滑粘滑滑粘滑粘滑
硬硬软硬硬软硬软硬
凹坦凹陷陷坦坦坦凹
稍平稍凹凹平平平稍
糊稍 糊模 晰清 糊稍 糊稍 糊模 糊模 晰清 糊稍
"
1 2 3
4 5 6 7 8 9
10n
12 13 14 15 16 17
响响响响闷响闷响声
浊浊浊浊沉浊沉浊敲
色 泽 根蒂 青 乌 乌 青
青浅
乌 乌
绿 黑 黑 绿 白 绿 黑 黑
蜷 蜷 蜷 蜷 蜷 稍 稍 稍
缩 缩 缩 缩 缩 蜷 蜷 蜷 乌 青 浅 浅 青 浅 乌 浅 青
黑 绿 白 白 绿 白 黑
白. 绿
稍 硬 硬 蜷 稍 稍 稍 蜷 蜷
蜷 挺 挺 缩 蜷 蜷 蜷 缩 缩
沉闷 浊响 浊响 沉闷 浊响 浊响 清脆 清脆 沉闷
是是是是是是是
滑硬
滑硬
然后,我 们 要 计 算 出当前属性集合{色泽,根蒂,敲声,纹理,脐部,触感}
中每个属性的信息增益.以属性"色泽”为例,它 有 3 个可能的取值:{青绿,乌
黑,浅白}.若 使 用 该 属 性 对D 进行划分,则 可 得 到 3 个子集,分别记为:D 1 (色 泽 =青 绿 ),。2 (色泽= 乌黑),。3 (色 泽 =浅 白 ).
子 集 加 包含编号为口,4, 6, 10, 13, 17}的 6 个样例,其中正例占pi =
反 例 占 次 = | ;D 2 包含编号为{2, 3, 7, 8, 9, 15)的 6 个样例,其中正、反例分
别 占 01 = 柒 P2 = |;P 3 包 含 编 号 为 {5, 11, 12, 14, 16)的 5 个样例,其中正、
反例分别占0 = 第 P2 = " 根 据 式 (4.1)可 计 算 出 用 “色 泽 ”划分之后所获得
的 3 个分支结点的信息嫡为
E n t S = - ( 1 1 0 g 2 l + 1 10g2
= 1.000 ,
Ent(P2 ) = - 俱嗝+ 62 1 O1S 2 62\;= 0.918 ,
E n t ( D 3 ) 三 - ( 5 1 O g 2 15 4 1 4\
+ 5 1 O g 2 5j = 0.722 ,
于是,根据式(4.2)可 计 算 出 属 性 “色泽”的信息增益为


4 . 2 划分选择 77
G ain(B , 色泽)= E n t(P )- £ ^ E n t (P v )
V=1 ' I
= 0.998 - g x 1.000 + 盘 x 0.918 x 0.722)
=0.109 .
类似的,我们可计算出其他属性的信息增益:
G ain j(D,根蒂)= 0.143; G ain(P , 敲声)= 0.141;
G ain(D , 纹理)= 0.381; G ain(P , 脐部)= 0.289;
G ain(D ,触感)= 0.006.
显然,属 性 “纹理”的信息增益最大,于是它被选为划分属性.图4 .3 给出
了 基 于 “纹理”对根结点进行划分的结果,各分支结点所包含的样例子集显示
在结点中.
[纹理= ? )
“纹 理 ” 划分属性.
[{1,2, 3,4, 5,6, 8, 10,15})[{7, 9 ,1 3 ,14,17})[{1 1 J 2 J 6 }]
图 4 . 3 基 于 “纹理”属性对根结点划分
然后,决策树学习算法将对每个分支结点做进一步划分.以图4 .3 中第一
个分支结点(“纹 理 =清 晰 ”)为例,该结点包含的样例集合。1 中有编号为{1,
2, 3, 4, 5, 6, 8, 10, 15)的 9 个样例,可用属性集合为{色泽,根蒂,敲声,脐部, 不 再 作 为 候 选 触感}. 基 于 p i 计算出各属性的信息增益:
G ain I()1 , 色泽)= 0.043; G ain(A , 根蒂)= 0.458;
G ain(Z)1 , 敲声)= 0.331; 脐部)= 0.458;
G ain(A , 触感)= 0.458.
“根蒂”、 “脐部”、 “触感” 3 个属性均取得了最大的信息增益,可任
选其中之一作为划分属性.类似的,对每个分支结点进行上述操作,最终得到的
决策树如图4 .4 所示.
4 .2 .2 增益率
在上面的介绍中,我们有意忽略了表4 .1 中 的 “编 号 ”这 一 列 .若 把 “编


78 第 4 章 决 策 树
图 4 . 4 在西瓜数据集2.0上基于信息增益生成的决策树
号 ”也作为一个候选划分属性,则根据式(4.2)可计算出它的信息增益为0.998,
远大于其他候选划分属性.这很容易理解: “编号”将产 生 17个分支,每个分
支结点仅包含一个样本,这些分支结点的纯度已达最大.然而,这样的决策树显 然不具有泛化能力,无法对新样本进行有效预测.
实际上,信息增益准则对可取值数目较多的属性有所偏好,为减少这种
偏好可能带来的不利影响,著名的C 4.5决策树算法[Quinlan, 1993]不直接使
用信息增益,而 是 使 用 “增益率”(gain r a tio )来选择最优划分属性.采用与
式(4.2)相同的符号表示,增益率定义为
Gain_ratio(D, a) = G :黑 砂 , (4.3)
其中 1 V (4) = 一 宫 即 g2耨 (44)
称 为 属 性 a 的 “固有值" (intrinsic value) [Quinlan, 1 9 9 3 ].属 性 a 的可能
取值数目越多(即V 越大),则 I V ( a ) 的值通常会越大.例如,对 表 4 .1 的西
瓜数据集 2 .0 ,有 IV(触感) = 0.874 (V = 2), IV(色泽)= 1.580 (V = 3),
IV(编号) =4.088 (V = 17).
需注意的是,增益率准则对可取值数目较少的属性有所偏好,因 此 C4.5
算法并不是直接选择增益率最大的候选划分属性,而是使用了一个启发式


4 . 3 剪枝处理 79
CART 是 Classification and Regression Tree 的简 称 ,这是一种著名的决策 树学习算 法,分类和回归 任务都可用.
关于过拟合,参见2.1节.
[Quinlan, 1993]:.先从候选划分属性中找出信息增益高于平均水平的属性,再从
中选择增益率最高的. ’
4 .2 .3 基尼指数
CART 决 策 树 [Breiman et a l, 1984]使 用 “基 尼 指 数 "(Gini index)来选
择划分属性.采用与式(4.1)相同的符号,数 据 集 。 的纯度可用基尼值来度量:
3
G in i(Z ))= E E « k=l kf^k
3
= 1 - £ 落 (43) k=l
直观来说,G in i(P )反映了从数据集D 中随机抽取两个样本,其类别标记
不一致的概率.因此,G ini(D )越小,则数据集D 的纯度越高.
采用与式(4.2)相同的符号表示,属性a 的基尼指数定义为
Gini_iiidex(。,a) = . (4.6) 0=1 I
于是,我们在候选属性集合4 中,选择那个使得划分后基尼指数最小的属
性作为最优划分属性,即 a* = arg min Gmi.index(P, a).
aeA
4 .3 剪枝处理
剪 枝 (pruning)是 决 策 树 学 习 算 法 对 付 “过 拟 合 ”的主要手 段 .在 决 策 树 学
习中,为了尽可能正确分类训练样本,结点划分过程将不断重复,有时会造成决
策树分支过多,这时就可能因训练样本学得“太 好 ”了,以致于把训练集自身
的一些特点当作所有数据都具有的一般性质而导致过拟合.因此,可通过主动
去掉一些分支来降低过拟合的风险.
决 策 树 剪 枝 的 基 本 策 略 有 “预 剪 枝 ”(prepruning)和 “后 剪 枝 " (post
pruning) [Quinlan, 1993].预剪枝是指在决策树生成过程中,对每个结点在划
分前先进行估计,若当前结点的划分不能带来决策树泛化性能提升,则停止划
分并将当前结点标记为叶结点;后剪枝则是先从训练集生成一棵完整的决策树,
然后自底向上地对非叶结点进行考察,若将该结点对应的子树替换为叶结点能


80 第 4 章 决 策 树
带来决策树泛化性能提升,则将该子树替换为叶结点.
如何判断决策树泛化性能是否提升呢?这 可 使 用 2 .2 节 介 绍 的 性 能 评 估 、
方 法 .本 节 假 定 采 用 留 出 法 ,即 预 留 一 部 分 数 据 用 作 “验 证 集 ” 以进行性
能 评 估 . 例 如 对 表 4 . 1 的 西 瓜 数 据 集 2 . 0 ,我 们 将 其 随 机 划 分 为 两 部 分 ,如
表 4 . 2 所示,编 号 为 {1,2,3,6,7,10,14,15,16,17}的样例组成训练集,编号为
{4 ,5 ,8 ,9 ,11,12,13)的样例组成验证集.
表 4 . 2 西瓜数据集2.0划分出的训练集(双线上部)与验证集(双线下部)
瓜
好
感
触
部
理
是
.
是是是是
粘粘滑滑滑
软软硬硬硬
稍凹 稍凹 凹陷 凹陷 凹陷
糊晰晰晰晰
稍清清清清
否否否否否
滑硬 滑硬 粘软 滑硬 粘软
凹坦凹陷坦
稍平稍凹平
T
厂二 
p T1 ;
二
pE
糊稍 糊模 晰清 糊稍 晰清
闷沉 响浊 响浊 闷沉 脆清 响浊 响浊 响浊 闷沉 响浊 声敲
蜷 蜷 缩 缩 缩, 蒂
稍稍蜷蜷蜷根 缩缩蜷蜷挺
蜷蜷稍稍硬
绿青 白浅 黑 乌 白 浅 绿 青 黑 乌 绿 青 黑 乌 黑 乌 绿 青 泽色
居
1 2 3 6 7
10 14 15 16 17
He
He
SC
硬硬硬
凹陷陷
稍凹凹
晰晰晰
清清清
否否否否
滑硬 粘软 滑硬 滑硬
陷坦坦凹
凹平平稍
稍糊 模糊 模糊 稍糊
响响脆闷响响闷声
浊浊清沉浊浊沉敲
蜷缩挺蜷蜷缩缩蒂
稍蜷硬稍 稍蜷蜷 根
绿白白黑黑白绿泽
青浅浅乌乌浅青色
评
4 5 8
9
11 12 13
瓜
好
感
触
部脐
理
纹
是是是
假定我们采用4.2.1节的信息增益准则来进行划分属性选择,则 从 表 4 .2 的
训练集将会生成一棵如图4 .5 所示的决策树.为便于讨论,我们对图中的部分
结点做了编号.
4 .3 .1 预剪枝
我们先讨论预剪枝.基于信息增益准则,我 们 会 选 取 属 性 “脐 部 ”来对训
练集进行划分,并 产 生 3 个分支,如 图 4 .6 所 示 .然 而 ,是否应该进行这个划分
呢?预剪枝要对划分前后的泛化性能进行估计.
在划分之前,所有样例集中在根结点.若不进行划分,则根 据 算 法 4 .2 第 6
行 ,该结点将被标记为叶结点,其类别标记为训练样例数最多的类别,假设我们


4 . 3 剪枝处理 81
图 4 . 5 基 于 表 4.2生成的未剪枝决策树
1 验证集精度
色泽= ? ”划分前:71.4%
划分后:57. 1% 预 剪 枝 决 策 :禁止划分
验证集精度 “根蒂二?” 划分前:71.4%
划 分 后 :71.4% 预 剪 枝 决 策 :禁止划分
图 4 . 6 基 于 表 4 .2 生成的预剪枝决策树
肝 驾 ? 段 不 唯 一 将 这 个 叶 结 点 标 记 为 “好瓜”. 用 表 4 .2 的验证集对这个单结点决策树进行评
时 ,可任选其中一类.
估,则 编 号 为 {4 ,5 ,8 }的样例被分类正确,另 外 4 个样例分类错误,于是,验证
集精度为 x 100% = 42.9%.
在 用 属 性 “脐 部 ”划 分 之 后 ,图 4 . 6 中 的 结 点 2 、3 、@ 分 别 包 含 编
号 为 {1 ,2,3,14}、{6,7,15,17}、{10,16} 的 训 练样例,因 此 这 3 个结点分别
被 标 记 为 叶 结 点 “好 瓜 ”、 “好 瓜 ”、 “坏 瓜 ”. 此 时 ,验证集中编号为
( 4 ,5 ,8 ,1 1 ,1 2 )的样例被分类正确,验证集精度为| x 100% = 71.4% > 42.9%.
于是,用 “脐部”进行划分得以确定.


82 第 4 章 决 策 树
此种情形下验证集精度 虽 无 提 高 ,但 根 据 奥 卡 姆 剃 刀 准 则 ,剪 枝 后 的 模 型 更好.因此,实际的决策树 算法在此种情形下通常要 进行剪枝.本书为妥图的 方 便 ,采 取 了 不 剪 枝 的 保 守策略.
然 后 ,决 策 树 算 法 应 该 对 结 点 2 进 行 划 分 ,基 于 信 息 增 益 准 则 将 挑 选 出 划
分 属 性 “色泽”. 然而,在 使 用 “色 泽 ”划分后,编 号 为 {5}的验证集样本分类
结 果 会 由正确转为错误,使 得 验 证 集 精 度 下 降 为 5 7 . 1 % . 于是,预 剪 枝 策 略 将 禁
止结点2被划分.
对 结 点 3 ,最 优 划 分 属 性 为 “根 蒂 ”,划 分 后 验 证 集 精 度 仍 为 7 1 . 4 % . 这个
划分不能提升验证集精度,于是,预剪枝策略禁止结点3被划分.
对 结 点 4 ,其所 含 训 练 样 例 已 属 于 同 一 类 ,不再进行划分.
于是,基于预剪枝策略从表4.2数据所生成的决策树如图4.6所示,其验证
集精度为71.4%.这是一棵仅有一层划分的决策树,亦称“决 策 树 桩 "(decision
stump).
对 比 图 4.6和 图 4.5可 看出,预 剪 枝 使 得 决 策 树 的 很 多 分 支 都 没 有 “展
开 ”,这不仅降低了过拟合的风险,还显著减少了决策树的训练时间开销和测
试 时 间 开 销 .但 另 一 方 面 ,有 些 分 支 的 当 前 划 分 虽 不 能 提 升 泛 化 性 能 、甚至可
能导致泛化性能暂时下降,但在其基础上进行的后续划分却有可能导致性能显
著提高;预 剪 枝 基 于 “贪 心 ”本质禁止这些分支展开,给预剪枝决策树带来了
欠拟合的风险.
4 3 2 后剪枝
后 剪 枝 先 从 训 练 集 生 成 一 棵 完 整 决 策 树 ,例 如 基 于 表 4 . 2 的数据我们得到
如 图 4.5所示的决策树.易知,该决策树的验证集精度为42.9%.
后 剪 枝 首 先 考 察 图 4.5中 的 结 点 6 .若 将 其 领 衔 的 分 支 剪 除 ,则相当于
把 6 替 换 为 叶 结 点 . 替 换 后 的 叶 结 点 包 含 编 号 为 {7,15}的训练样本,于 是 ,该
叶结点的类别标记为“好 瓜 ”,此时决策树的验证集精度提高至57.1%.于是,
后剪枝策略决定剪枝,如图4.7所示.
然 后 考 察 结 点 5 ,若 将 其 领 衔 的 子 树 替 换 为 叶 结 点 ,则 替 换 后 的 叶 结 点 包
含 编 号 为 {6,7,15}的训练样例,叶 结点类别标记为“好瓜”,此时决策树验证
集 精 度 仍 为 5 7 . 1 % . 于是,可以不进行剪枝.
对 结 点 2 ,若 将 其 领 衔 的 子 树 替 换 为 叶 结 点 ,则替换后的叶结点包含编号
为 {1,2,3,14}的训练样例,叶 结 点 标 记 为 “好瓜”.此时决策树的验证集精度
提 高 至 71.4%.于是,后剪枝策略决定剪枝.
对 结 点 3 和 1 ,若 将 其 领 衔 的 子 树 替 换 为 叶 结 点 ,则 所得决 策树的验证集
精度分别为71.4%与 42.9%,均 未 得 到 提 高 .于 是 它 们 被 保 留 ..


4 . 4 连续与缺失值 83
最终,基于后剪枝策略从表4 .2 数据所生成的决策树如图4 .7 所示,其验证
集 精 度 为 71.4%.
对 比 图 4 .7 和 图 4 .6 可看出,后剪枝决策树通常比预剪枝决策树保留了更
多的分支.一般情形下,后剪枝决策树的欠拟合风险很小,泛化性能往往优于预
剪枝决策树.但后剪枝过程是在生成完全决策树之后进行的,并且要自底向上
地对树中的所有非叶结点进行逐一考察,因此其训练时间开销比未剪枝决策树
和预剪枝决策树都要大得多.
4 .4 连续与缺失值
4 .4 .1 连续值处理
到目前为止我们仅讨论了基于离散属性来生成决策树.现实学习任务中常
会遇到连续属性,有必要讨论如何在决策树学习中使用连续属性.
由于连续属性的可取值数目不再有限,因此,不能直接根据连续属性的可
取值来对结点进行划分.止匕时,连续属性离散化技术可派上用场.最简单的策
略是采用二分法(bi-partition)对连续属性进行处理,这 正 是 C 4.5决策树算法中
采用的机制[Quinlan, 1993].
给定样本集D 和 连 续 属 性 生 假 定 。在 。 上出现了 n 个不同的取值,将这
些值从小到大进行排序,记 为 包 \ Q 2, . 一,〃 } . 基 于 划分点t可 将 D 分为子集
D - 和 D = 其 中 D - 包含那些在属性。上取值不大于t 的样本,而 D + 则包含
那些在属性a 上取值大于t的样本.显然,对相邻的属性取值出与出+ i 来说,t


84 第 4 章 决 策 树
在区间依,d + 1 ) 中取任意值所产生的划分结果相同.因此,对连续属性见 我们
可考察包含n - 1 个元素的候选划分点集合
{号 % " 飞 ” 】卜
(4.7)
可将划分点设为该属性 在训练集中出现的不大 于 中 位 点 的 最 大 值 ,从而 使得最终决策树使用的划 分点都在训练集中出现过 [Quinlan, 1993].
即 把 区 间 依 看 + 1 ) 的 中 位 点 追 料 作 为 候 选 划 分 点 .然 后 ,我们就可像离散
属性值一样来考察这些划分点,选取最优的划分点进行样本集合的划分.例如,
可对式(4.2)稍加改造:
G a in (2?, a) = m ax G ain (B , a, t)
= 跷 E n t ( 0 — 5 2 耨 , (4.8)
其 中 G a i n ( R a 工)是样本集D 基于 划 分 点 t 二分后的信息增益.于是,我们就
可选择使G a in (P , a, t ) 最大化的划分点.
作为一个例子,我 们 在 表 4 . 1 的西瓜数据集2 .0 上 增 加 两 个 连 续 属 性 “密
度 ”和 “含糖率”,得 到 表 4 .3 所示的西瓜数据集3 . 0 . 下面我们用这个数据集
来生成一棵决策树.
表 4 . 3 西瓜数据集3.0
~ i S t o ~ ~ ~ S i w 5 s ~ 含 糖 率 ~m
是
是
是
是
是
是
是
是
否
否
否
否
否
否
否
否
否
0. 0. 0. 0. 0. 0. 0. 0.
46 37 26 31 21 23 14 21
0 6 4 8 5 7 9 1
0. 0. 0. 0. 0. 0. 0. 0. 0.
09 26 05 09 16 19 37 04 10
1 7 7 9. 1 8 0 2 3
0.697 0.774 0.634 0.608 0.556 0.403 0.481 0.437
0.666 0.243 0.245 0.343 0.639 0.657 0.360 0.593 0.719
滑
滑
滑
滑
滑
粘
粘
滑硬
硬
硬
硬
硬
软
软
硬
陷
陷
陷
陷
陷
凹
凹
凹
凹
凹
凹
凹
凹
稍
稍
稍
晰
晰
晰
晰
晰
晰
糊
晰
清
清
清
清
清
清
稍
清
向
M
向
国
向
向
向
向
n
CT n XL

n
nH
口
口浊
沉
浊
沉
浊
浊
浊
浊
缩
缩
缩
缩
缩
蜷
蜷
蜷幡
蜷
蜷
蜷
幡
稍
稍
稍
绿
黑
黑
绿
白
绿
黑
黑
青
乌
乌
青
浅
青
乌
乌
1 2 3 4 5 6 7 8
滑
粘
滑
粘
滑
滑
粘
滑
滑
硬
软
硬
软
硬
硬
软
硬
硬
凹
坦
坦
坦
陷
陷
凹
坦
凹
稍
平
平
平
凹
凹
稍
平
稍
糊
晰
糊
糊
糊
糊
晰
糊
糊稍
清
模
模
稍
稍
清
模
稍
闷
脆
脆
响
响
闷
响
响
闷湎
清
清
御
衡
湎
御
湖
州
蜷
挺
挺
缩
蜷
蜷
蜷
缩
缩
稍
硬
硬
蜷
稍
稍
稍
蜷
蜷
黑
绿
白
白
绿
白
黑
白
绿
乌
青
浅
浅
青
浅
乌
浅
青
3 0 1 2 3 4 5 6 7
c 1 1 1 1 L 1 1 1